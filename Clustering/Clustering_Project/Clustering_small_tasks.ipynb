{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riB6PeJTbKOQ"
   },
   "source": [
    "# 1- Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "dict_keys(['id', 'task_items', 'global_task_description'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dataset = []\n",
    "\n",
    "with open(\"activity_data.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "  for line in f:\n",
    "    if line.strip():\n",
    "      dataset.append(json.loads(line))\n",
    "\n",
    "print(len(dataset))\n",
    "print(dataset[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWHjjq2kcsYx"
   },
   "source": [
    "# 2- EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swgbeqL3cuvp"
   },
   "source": [
    "## EDA STRUCTURAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4X9-DaJczTj"
   },
   "source": [
    "### 1.1 Nombre de task_items par global_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 16, np.float64(9.028), np.float64(9.0))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lens = [len(x[\"task_items\"]) for x in dataset]\n",
    "\n",
    "min(lens), max(lens), np.mean(lens), np.median(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1536', 'task_items': ['\"software_preferences.json, JSON, /home/user/config, Text editor, Configuration file for updating personal software preferences and settings', '\"user_settings_backup.zip, ZIP, /home/user/backups, File manager, Backup of user settings before updating preferences', '\"preferences_backup.bak, BAK, /home/user/backups, File manager, Backup file containing previous software settings for r_'], 'global_task_description': 'Update personal software preferences and settings'}\n"
     ]
    }
   ],
   "source": [
    "for line in dataset:\n",
    "  if len(line[\"task_items\"]) == 3:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UoVbT6NiNOL"
   },
   "source": [
    "### 1.2 Longueur des task_items (tokens)\\\n",
    "* MiniLM a une limite contextuelle\n",
    "* les commandes ultra-courtes sont ambiguës\n",
    "\n",
    "À analyser :\n",
    "\n",
    "min / max / moyenne\n",
    "\n",
    "ratio :\n",
    "\n",
    "< 4 tokens → trop vague\n",
    "40 tokens → trop bruité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325c53a00b8749ff96e32d86a01e36c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b06a724c9604773bf63f29ef2946871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a5785bc5c545bd85fefcb1e600396f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6238e8df9740e086a6a2109a98d927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2e73bd46df4fcb9dfe7631a304c570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2595a3ccb4cf40ba9660f8410c2a6e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dcf3603f8a34bc0bb1831474f0189c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f7bdc85a8b49c8a795025a209e7567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08a9a90206c4d62bf879ea7a8a25ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9bd3719c0cc48b78e0e33470f993c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc78e0dcf864a7db015b15513931712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def tok_len(t):\n",
    "    return len(model.tokenizer.tokenize(t))\n",
    "\n",
    "global_lengths = [\n",
    "    sum(tok_len(t) for t in x[\"task_items\"])\n",
    "    for x in dataset\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(global_lengths, bins=30)\n",
    "plt.xlabel(\"Global token length\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.title(\"Distribution of global token lengths\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50th percentile: 229.0\n",
      "75th percentile: 258.0\n",
      "90th percentile: 284.0\n",
      "95th percentile: 303.0\n",
      "99th percentile: 344.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for p in [50, 75, 90, 95, 99]:\n",
    "    print(f\"{p}th percentile:\", np.percentile(global_lengths, p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFFLYWN3YHHo"
   },
   "source": [
    "## EDA LEXICAL (BRUIT & VARIATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_TSwoJTYLYE"
   },
   "source": [
    "### 1 Vocabulaire global\n",
    "\n",
    "* détecter tokens techniques dominants\n",
    "* identifier tokens génériques (“used”, “opened”, “file”…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 10060),\n",
       " ('to', 10055),\n",
       " ('for', 7407),\n",
       " ('the', 6195),\n",
       " ('used', 4510),\n",
       " ('with', 4080),\n",
       " ('a', 3889),\n",
       " ('in', 2960),\n",
       " ('file,', 2900),\n",
       " ('opened', 2850),\n",
       " ('text', 2608),\n",
       " ('of', 2484),\n",
       " ('application,', 2248),\n",
       " ('editor,', 2142),\n",
       " ('command,', 1803),\n",
       " ('on', 1600),\n",
       " ('file', 1583),\n",
       " ('network', 1572),\n",
       " ('configuration', 1564),\n",
       " ('data', 1398),\n",
       " ('application', 1209),\n",
       " ('browser,', 1189),\n",
       " ('web', 1149),\n",
       " ('system', 1092),\n",
       " ('performance', 1034),\n",
       " ('command', 1029),\n",
       " ('settings', 1012),\n",
       " ('contains', 992),\n",
       " ('logs', 921),\n",
       " ('log', 846),\n",
       " ('security', 830),\n",
       " ('model', 823),\n",
       " ('access', 803),\n",
       " ('stores', 796),\n",
       " ('from', 733),\n",
       " ('/scripts,', 712),\n",
       " ('terminal,', 684),\n",
       " ('provides', 664),\n",
       " ('across', 651),\n",
       " ('website,', 642),\n",
       " ('tool,', 586),\n",
       " ('defines', 586),\n",
       " ('monitor', 581),\n",
       " ('manage', 578),\n",
       " ('python', 572),\n",
       " ('api', 558),\n",
       " ('files', 548),\n",
       " ('status', 537),\n",
       " ('monitoring', 528),\n",
       " ('services', 509)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "for x in dataset:\n",
    "    for t in x[\"task_items\"]:\n",
    "        counter.update(t.lower().split())\n",
    "\n",
    "counter.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LggnmFMObF8i"
   },
   "source": [
    "### 2- Tokens trop fréquents (candidats stop-words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and             10060\n",
      "to              10055\n",
      "for             7407\n",
      "the             6195\n",
      "used            4510\n",
      "with            4080\n",
      "a               3889\n",
      "in              2960\n",
      "file,           2900\n",
      "opened          2850\n",
      "text            2608\n",
      "of              2484\n",
      "application,    2248\n",
      "editor,         2142\n",
      "command,        1803\n",
      "on              1600\n",
      "file            1583\n",
      "network         1572\n",
      "configuration   1564\n",
      "data            1398\n",
      "application     1209\n",
      "browser,        1189\n",
      "web             1149\n",
      "system          1092\n",
      "performance     1034\n",
      "command         1029\n",
      "settings        1012\n",
      "contains        992\n",
      "logs            921\n",
      "log             846\n"
     ]
    }
   ],
   "source": [
    "for tok, freq in counter.most_common(30):\n",
    "    print(f\"{tok:15s} {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZdDhQAVZxlF"
   },
   "source": [
    "### 3- Diversité lexicale intra global_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"\\b\\w+\\b\", text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(tasks):\n",
    "    tokens = []\n",
    "    for t in tasks:\n",
    "        tokens.extend(tokenize(t))\n",
    "    return len(set(tokens)) / len(tokens) if tokens else 0\n",
    "\n",
    "diversities = [\n",
    "    lexical_diversity(x[\"task_items\"])\n",
    "    for x in dataset\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.3333333333333333),\n",
       " np.float64(0.5441238777061056),\n",
       " np.float64(0.5412246369348028),\n",
       " np.float64(0.75))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.min(diversities), np.mean(diversities), np.median(diversities), np.max(diversities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(diversities, bins=30)\n",
    "plt.xlabel(\"Diversité lexicale intra global_task\")\n",
    "plt.ylabel(\"Nombre de global_tasks\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLu4Ee9PcCCL"
   },
   "source": [
    "## EDA SÉMANTIQUE (AVEC UN MODELE BRUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fg0keb62cJzN"
   },
   "source": [
    "### 1 Similarité intra vs inter global_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import random\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "random.shuffle(dataset)\n",
    "\n",
    "intra_sims = []\n",
    "inter_sims = []\n",
    "\n",
    "for x in dataset[:200]:\n",
    "  tasks = x[\"task_items\"]\n",
    "  emb = model.encode(tasks)\n",
    "\n",
    "  for i in range(len(emb)-1):\n",
    "    intra_sims.append(util.cos_sim(emb[i], emb[i+1]).item())\n",
    "\n",
    "for i in range(200):\n",
    "  t1 = dataset[i][\"task_items\"][0]\n",
    "  t2 = dataset[(i+1)%200][\"task_items\"][0]\n",
    "  inter_sims.append(\n",
    "      util.cos_sim(\n",
    "          model.encode(t1),\n",
    "          model.encode(t2)\n",
    "      ).item()\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne intra : 0.5060002790031167\n",
      "Moyenne inter : 0.19157822135370225\n",
      "Std intra : 0.1532739396130872\n",
      "Std inter : 0.11686875516254769\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Moyenne intra :\", np.mean(intra_sims))\n",
    "print(\"Moyenne inter :\", np.mean(inter_sims))\n",
    "\n",
    "print(\"Std intra :\", np.std(intra_sims))\n",
    "print(\"Std inter :\", np.std(inter_sims))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intra > Inter (%): 97.38124238733252\n"
     ]
    }
   ],
   "source": [
    "print(\"Intra > Inter (%):\",\n",
    "      np.mean(np.array(intra_sims) > np.mean(inter_sims)) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chevauchement estimé : 0.06942752740560293\n"
     ]
    }
   ],
   "source": [
    "overlap = np.mean(\n",
    "    np.array(intra_sims) < np.percentile(inter_sims, 75)\n",
    ")\n",
    "print(\"Chevauchement estimé :\", overlap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(intra_sims, bins=30, alpha=0.6, label=\"intra\")\n",
    "plt.hist(inter_sims, bins=30, alpha=0.6, label=\"inter\")\n",
    "plt.legend()\n",
    "plt.title(\"Distribution des similarités sémantiques\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPWWFIfzhVZe"
   },
   "source": [
    "### Global_task overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_embeddings = []\n",
    "global_labels = []\n",
    "\n",
    "for x in dataset[:200]:   # EDA → 200 suffit\n",
    "    tasks = x[\"task_items\"]\n",
    "    emb = model.encode(tasks)\n",
    "\n",
    "    # embedding du global_task = moyenne\n",
    "    global_emb = np.mean(emb, axis=0)\n",
    "\n",
    "    global_embeddings.append(global_emb)\n",
    "    global_labels.append(x[\"global_task_description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QftWVN_ziDOc"
   },
   "source": [
    "### Calculer les similarités ENTRE global_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-490317937.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
      "  G = torch.tensor(global_embeddings)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "G = torch.tensor(global_embeddings)\n",
    "sim_matrix = util.cos_sim(G, G)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIjxaMcQiKpv"
   },
   "source": [
    "### Extraire les paires dangereuses (cosine > 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangerous_pairs = []\n",
    "\n",
    "threshold = 0.75\n",
    "\n",
    "for i in range(len(global_labels)):\n",
    "    for j in range(i+1, len(global_labels)):  # i != j\n",
    "        score = sim_matrix[i][j].item()\n",
    "        if score > threshold:\n",
    "            dangerous_pairs.append(\n",
    "                (global_labels[i], global_labels[j], score)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSXa14NaiRfn"
   },
   "source": [
    "### Inspecter concrètement (le plus important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.903 | Implement feature flags to manage feature rollouts safely  <-->  Implement feature flags to gradually release new features\n",
      "0.893 | Validate network routing and interface configurations  <-->  Audit host network configurations for security gaps\n",
      "0.889 | Debug and resolve memory leaks in production services  <-->  Monitor memory leak trends across critical applications\n",
      "0.852 | Implement logging aggregation for multi-service applications  <-->  Set up log aggregation to centralize error and access logs\n",
      "0.843 | Assess impact of network segmentation on application traffic  <-->  Assess network segmentation and traffic flow configurations for vulnerabilities\n",
      "0.842 | Assess network segmentation and traffic flow configurations for vulnerabilities  <-->  Assess network segmentation effectiveness for security zones\n",
      "0.835 | Test authentication mechanisms under authorization  <-->  Integrate authentication and authorization mechanisms securely\n",
      "0.828 | Maintain VPN concentrators and remote access policies  <-->  Audit cloud VPN connections for security compliance\n",
      "0.821 | Profile network traffic and optimize communication between services  <-->  Monitor network latency and interface errors on hosts\n",
      "0.817 | Assess network segmentation and traffic flow configurations for vulnerabilities  <-->  Coordinate network segmentation for security compliance\n"
     ]
    }
   ],
   "source": [
    "# Trier par similarité décroissante\n",
    "dangerous_pairs = sorted(dangerous_pairs, key=lambda x: -x[2])\n",
    "\n",
    "for g1, g2, s in dangerous_pairs[:10]:\n",
    "    print(f\"{s:.3f} | {g1}  <-->  {g2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjzrIi4myBkO"
   },
   "source": [
    "# Structuration du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGGOFYa3yIdB"
   },
   "source": [
    "## 1 Nettoyage minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_task(text):\n",
    "    \"\"\"\n",
    "    Nettoyage minimal d'un task_item ou global_task\n",
    "    \"\"\"\n",
    "    # enlever les guillemets et les backslashes\n",
    "    text = text.replace('\\\\\"', '').replace('\"', '')\n",
    "    # passer en minuscules et strip\n",
    "    text = text.lower().strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSp2H-6CJCrg"
   },
   "source": [
    "## Structuration à deux niveaux\n",
    "Niveau A — petits tasks unitaires\n",
    "→ Liste de task_items nettoyés\n",
    "\n",
    "Niveau B — bloc global\n",
    "→ Concaténation de tous les task_items de la ligne, forme un seul texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_dataset = []\n",
    "\n",
    "for entry in dataset:\n",
    "  task_items = entry[\"task_items\"]\n",
    "\n",
    "  # Niveau A : petits tasks unitaires\n",
    "  small_tasks = [normalize_task(t) for t in task_items]\n",
    "\n",
    "  # Niveau B : bloc global\n",
    "  global_block = \" \".join(small_tasks)\n",
    "\n",
    "  # Ajouter au dataset structuré\n",
    "  structured_dataset.append({\n",
    "      \"id\": entry[\"id\"],\n",
    "      \"small_tasks\": small_tasks,\n",
    "      \"global_block\": global_block,\n",
    "      \"global_task_description\": normalize_task(entry[\"global_task_description\"])\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "dict_keys(['id', 'small_tasks', 'global_block', 'global_task_description'])\n",
      "['index.html file in /var/www/project opened with visual studio code to structure the website content', 'style.css file in /var/www/project/css opened with sublime text to define responsive styles for desktop and mobile', 'app.js file in /var/www/project/js opened with webstorm to implement interactive website features', 'bootstrap application used to quickly design responsive layouts and components', 'google chrome application used to test website responsiveness across different screen sizes', 'firefox developer tools application used to inspect and debug css media queries', 'git init command to initialize a version control repository for the project', 'npm install command to add necessary frontend dependencies and frameworks', 'git commit -m command to save incremental changes in the website development', 'ping command to test server connectivity and responsiveness', 'curl command to check http responses of the website endpoints', 'npm run build command to compile and optimize the website for production']\n",
      "index.html file in /var/www/project opened with visual studio code to structure the website content style.css file in /var/www/project/css opened with sublime text to define responsive styles for desktop and mobile app.js file in /var/www/project/js opened with webstorm to implement interactive website features bootstrap application used to quickly design responsive layouts and components google chrome application used to test website responsiveness across different screen sizes firefox developer tools application used to inspect and debug css media queries git init command to initialize a version control repository for the project npm install command to add necessary frontend dependencies and frameworks git commit -m command to save incremental changes in the website development ping command to test server connectivity and responsiveness curl command to check http responses of the website endpoints npm run build command to compile and optimize the website for production\n",
      "develop and maintain responsive websites for desktop and mobile devices\n"
     ]
    }
   ],
   "source": [
    "print(len(structured_dataset))\n",
    "print(structured_dataset[0].keys())\n",
    "\n",
    "# Exemple de premier élément\n",
    "print(structured_dataset[0][\"small_tasks\"])\n",
    "print(structured_dataset[0][\"global_block\"])\n",
    "print(structured_dataset[0][\"global_task_description\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1JfpjLfSwAY"
   },
   "source": [
    "# Construction du dataset d’entraînement (CLÉ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0Y1258MU26i"
   },
   "source": [
    "Le but : apprendre au modèle que chaque petit task appartient à son bloc global, et que les autres blocs servent de négatifs implicites grâce au MultipleNegativesRankingLoss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOupfFjjVnsN"
   },
   "source": [
    "### construction du dataset contrastif\n",
    "- Pas besoin de générer de négatifs explicites\n",
    "\n",
    "- Très stable pour grandes datasets\n",
    "\n",
    "- Séparation fine des embeddings sémantiques\n",
    "\n",
    "Cette loss va rapprocher le petit task et son global_block, et repousser automatiquement les autres blocs du batch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import MultipleNegativesRankingLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NRJ0riNYXD1"
   },
   "source": [
    "### Création des exemples d’entraînement pour l’apprentissage de représentations sémantiques hiérarchiques\n",
    "\n",
    "Les exemples d’entraînement sont construits de manière à apprendre des représentations sémantiques structurées autour d’une **tâche globale** et de ses **sous-tâches constitutives**, en exploitant la `MultipleNegativesRankingLoss` sans nécessiter de négatifs explicites.\n",
    "\n",
    "#### 1. Absence de négatifs explicites et exploitation des négatifs implicites\n",
    "\n",
    "La `MultipleNegativesRankingLoss` considère automatiquement les autres exemples du batch comme des négatifs implicites.\n",
    "Ainsi, chaque paire positive est contrastée avec un grand nombre de paires non correspondantes, ce qui :\n",
    "\n",
    "* simplifie la préparation des données,\n",
    "* favorise une séparation sémantique efficace dans l’espace des embeddings,\n",
    "* améliore la discrimination entre tâches globales distinctes.\n",
    "\n",
    "L’efficacité de cette approche augmente avec la taille du batch, car le nombre de négatifs implicites croît proportionnellement.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Apprentissage hiérarchique : sous-tâche → tâche globale\n",
    "\n",
    "Pour chaque sous-tâche élémentaire (`small_task`), une paire positive est créée avec le bloc représentant la tâche globale (`global_block`).\n",
    "Ce mécanisme apprend au modèle que :\n",
    "\n",
    "* chaque sous-tâche est une composante sémantique du même objectif global,\n",
    "* la tâche globale agit comme un **point d’attraction sémantique** dans l’espace des embeddings.\n",
    "\n",
    "Cette relation renforce la structuration hiérarchique des représentations.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Renforcement de la cohésion intra-cluster : sous-tâche ↔ sous-tâche\n",
    "\n",
    "Des paires positives sont également générées entre toutes les sous-tâches appartenant à une même tâche globale.\n",
    "Ce choix vise à :\n",
    "\n",
    "* densifier localement l’espace embedding autour d’un même concept,\n",
    "* renforcer la cohésion interne des sous-tâches,\n",
    "* éviter que les sous-tâches ne soient reliées uniquement via le bloc global.\n",
    "\n",
    "Ainsi, les sous-tâches forment un cluster compact et sémantiquement cohérent.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Apprentissage compositionnel par augmentation de données\n",
    "\n",
    "Une stratégie d’augmentation de données consiste à créer des sous-ensembles partiels de sous-tâches, concaténés en un seul texte, puis associés à la tâche globale.\n",
    "Cette approche permet au modèle d’apprendre que :\n",
    "\n",
    "* différentes combinaisons partielles de sous-tâches peuvent représenter le même objectif global,\n",
    "* le sens de la tâche globale est invariant face à la suppression de certaines sous-composantes,\n",
    "* la représentation est robuste aux variations et à l’incomplétude des informations.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Effet global sur l’espace de représentation\n",
    "\n",
    "La combinaison de ces trois types de paires positives (sous-tâche ↔ global, sous-tâche ↔ sous-tâche, sous-ensemble ↔ global), couplée aux négatifs implicites du batching, conduit à :\n",
    "\n",
    "* une structuration hiérarchique claire de l’espace sémantique,\n",
    "* des clusters centrés sur des tâches globales interprétables,\n",
    "* une meilleure robustesse et stabilité des embeddings pour des tâches de regroupement orientées objectifs.\n",
    "\n",
    "Cette stratégie est particulièrement adaptée aux scénarios où l’interprétabilité des clusters et leur correspondance avec des tâches globales sont prioritaires.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total d'exemples : 94790\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import InputExample\n",
    "\n",
    "train_examples = []\n",
    "\n",
    "for obj in structured_dataset:\n",
    "    small_tasks = obj[\"small_tasks\"]   # déjà normalisés\n",
    "    global_block = obj[\"global_block\"]\n",
    "\n",
    "    # 1️ POSITIFS : petit task ↔ bloc global\n",
    "    for task in small_tasks:\n",
    "        train_examples.append(\n",
    "            InputExample(texts=[task, global_block])\n",
    "        )\n",
    "\n",
    "    # 2️ POSITIFS : task ↔ task (même global_task)\n",
    "    for i in range(len(small_tasks)):\n",
    "        for j in range(i + 1, len(small_tasks)):\n",
    "            train_examples.append(\n",
    "                InputExample(texts=[small_tasks[i], small_tasks[j]])\n",
    "            )\n",
    "\n",
    "    # 3️ POSITIFS : bloc ↔ sous-bloc (data augmentation)\n",
    "    if len(small_tasks) > 1:\n",
    "        subset = small_tasks[:int(len(small_tasks) * 0.7)]\n",
    "        train_examples.append(\n",
    "            InputExample(texts=[\" \".join(subset), global_block])\n",
    "        )\n",
    "\n",
    "print(f\"Nombre total d'exemples : {len(train_examples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "save_dir = \"/content/drive/MyDrive/global_task_model\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(save_dir, \"train_examples.pkl\")\n",
    "\n",
    "with open(save_path, \"wb\") as f:\n",
    "    pickle.dump(train_examples, f)\n",
    "\n",
    "print(f\" train_examples sauvegardé dans {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lycEy1a2b1z5"
   },
   "source": [
    "# Entraînement de l’encodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, losses\n",
    "from torch.utils.data import DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/content/drive/MyDrive/global_task_model\"\n",
    "\n",
    "CHECKPOINT_DIR = f\"{BASE_DIR}/checkpoints\"\n",
    "FINAL_MODEL_DIR = f\"{BASE_DIR}/final_model\"\n",
    "\n",
    "import os\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(FINAL_MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClQqkdl8cQtq"
   },
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3de87e81c2423cb9e22c8db19e4117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42758ec47e44b6ba4f65ba06a25c70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32cf275539b040cfb61c4c9d60c1d155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac8d45b79e0403dbf1bb1c609073440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1f3e6ece3946898b42d9f4167f7f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d532548a70c48feaa6e468a2b34bdee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e13ba18cf90404b8b99404df109ae00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a784a6061cf544a8aa1461db039f499e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad08e1db79e49f19ac343aebdf59995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f1c66946a44376bbb2077a533d1bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad7dc230e924885abba1ed44f8e696b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePIaC2IncXMd"
   },
   "source": [
    "### Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 8\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_examples,\n",
    "    shuffle=True,\n",
    "    batch_size=train_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36B4tgtfcdfC"
   },
   "source": [
    "### Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = losses.MultipleNegativesRankingLoss(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-CXc4geclEV"
   },
   "source": [
    "### Définir le nombre d’epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)  # 10% warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajJ3kQInc1ao"
   },
   "source": [
    "### Lancer l’entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937d51666fc64f989b975f37ea7e1399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/content/wandb/offline-run-20260111_132541-krhg3j4b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3669' max='35547' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3669/35547 4:29:38 < 39:04:04, 0.23 it/s, Epoch 0.31/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.317300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.171600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.133700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.134900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.118900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.100300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    show_progress_bar=True,\n",
    "    checkpoint_path=CHECKPOINT_DIR,\n",
    "    checkpoint_save_steps=2000,\n",
    "    checkpoint_save_total_limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tBtnb8tc7tS"
   },
   "source": [
    "### Sauvegarder le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-10000  checkpoint-6000  checkpoint-8000  runs\n"
     ]
    }
   ],
   "source": [
    "!ls /content/drive/MyDrive/global_task_model/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(FINAL_MODEL_DIR)\n",
    "print(f\"Modèle sauvegardé dans : {FINAL_MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, losses\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/content/drive/MyDrive/global_task_model/train_examples.pkl\", \"rb\") as f:\n",
    "    train_examples = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_batch_size = 8\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_examples,\n",
    "    shuffle=False,      # important pour reprise\n",
    "    batch_size=train_batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b3243806b54e5ea1f0efeeacef05e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/content/wandb/offline-run-20260113_165145-vhzb990v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35547' max='35547' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35547/35547 45:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.019600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.015800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.013400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.008300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.015300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.010600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.012700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.007200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.017600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.009400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.009700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.025800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.025800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.023300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.019600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.019900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.022700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.021100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.019500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.018300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.018100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.018100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.017900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.015300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.013200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.007600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.014300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.009600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>0.012700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>0.011000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import losses\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    \"/content/drive/MyDrive/global_task_model/checkpoints/checkpoint-10000\"\n",
    ")\n",
    "\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "num_epochs = 3   #  souvent moins que la phase initiale\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    show_progress_bar=True,\n",
    "    checkpoint_path=\"/content/drive/MyDrive/global_task_model/checkpoints\",\n",
    "    checkpoint_save_steps=2000,\n",
    "    checkpoint_save_total_limit=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_path = \"/content/drive/MyDrive/global_task_model/final_model\"\n",
    "model.save(final_path)\n",
    "\n",
    "print(f\" Modèle sauvegardé dans {final_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_Pooling\t\t\t   README.md\n",
      "2_Normalize\t\t\t   sentence_bert_config.json\n",
      "config.json\t\t\t   special_tokens_map.json\n",
      "config_sentence_transformers.json  tokenizer_config.json\n",
      "model.safetensors\t\t   tokenizer.json\n",
      "modules.json\t\t\t   vocab.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /content/drive/MyDrive/global_task_model/final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYIXsCdNwNpQ"
   },
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCHWDYvhwRYJ"
   },
   "source": [
    "## Load the encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    \"/content/drive/MyDrive/global_task_model/final_model\"\n",
    ")\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFc7k1P6wsTj"
   },
   "source": [
    "### 1- Évaluation de la similarité intra-tâches pour chaque global_task\n",
    "\n",
    "Cette fonction calcule la similarité cosinus entre toutes les petites tâches (small_tasks) d’une global_task donnée dans ton dataset structuré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import util\n",
    "\n",
    "def intra_global_similarity(model, structured_dataset):\n",
    "    results = []\n",
    "\n",
    "    for obj in structured_dataset:\n",
    "        tasks = obj[\"small_tasks\"]\n",
    "        if len(tasks) < 2:\n",
    "            continue\n",
    "\n",
    "        emb = model.encode(tasks, convert_to_tensor=True)\n",
    "        sims = util.cos_sim(emb, emb).cpu().numpy()\n",
    "\n",
    "        # enlever diagonale\n",
    "        values = sims[np.triu_indices(len(tasks), k=1)]\n",
    "\n",
    "        results.append({\n",
    "            \"id\": obj[\"id\"],\n",
    "            \"mean\": float(values.mean()),\n",
    "            \"min\": float(values.min()),\n",
    "            \"max\": float(values.max()),\n",
    "            \"std\": float(values.std())\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08IBEwexxBzv"
   },
   "source": [
    "## 2- Mesure de chevauchement sémantique entre deux global_tasks\n",
    "\n",
    "Cette fonction calcule la similarité entre deux global_tasks différentes (obj_a et obj_b) afin de détecter d’éventuels chevauchements ou redondances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_global_overlap(model, obj_a, obj_b):\n",
    "    emb_a = model.encode(obj_a[\"small_tasks\"], convert_to_tensor=True)\n",
    "    emb_b = model.encode(obj_b[\"small_tasks\"], convert_to_tensor=True)\n",
    "\n",
    "    sims = util.cos_sim(emb_a, emb_b).cpu().numpy()\n",
    "    return sims.mean(), sims.max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91kFAka2xaDw"
   },
   "source": [
    "## 3- Évaluation de la capacité de récupération (retrieval) des global_tasks\n",
    "\n",
    "Cette fonction mesure à quel point le modèle peut associer correctement chaque petite tâche à son global_task parent dans le dataset. C’est une métrique de précision du modèle sur la structuration des tâches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval_accuracy(model, structured_dataset, k=1):\n",
    "    global_blocks = [o[\"global_block\"] for o in structured_dataset]\n",
    "    global_ids = [o[\"id\"] for o in structured_dataset]\n",
    "\n",
    "    global_emb = model.encode(global_blocks, convert_to_tensor=True)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for obj in structured_dataset:\n",
    "        for task in obj[\"small_tasks\"]:\n",
    "            q = model.encode(task, convert_to_tensor=True)\n",
    "            sims = util.cos_sim(q, global_emb)[0]\n",
    "            topk = sims.topk(k).indices.tolist()\n",
    "\n",
    "            if global_ids.index(obj[\"id\"]) in topk:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2U3CZN7jxrdq"
   },
   "source": [
    "## 4- Comparaison des modèles SBERT pour la récupération des tâches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base: 0.6356889676561808\n",
      "Fine-tuned: 0.8803167922020381\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "base = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "acc_base = retrieval_accuracy(base, structured_dataset)\n",
    "acc_finetuned = retrieval_accuracy(model, structured_dataset)\n",
    "\n",
    "print(\"Base:\", acc_base)\n",
    "print(\"Fine-tuned:\", acc_finetuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "ID 265: mean=0.710, min=0.569, max=0.869, std=0.073\n",
      "ID 266: mean=0.767, min=0.530, max=0.937, std=0.106\n",
      "ID 267: mean=0.792, min=0.582, max=0.928, std=0.085\n",
      "ID 268: mean=0.797, min=0.602, max=0.938, std=0.103\n",
      "ID 269: mean=0.771, min=0.585, max=0.870, std=0.062\n",
      "ID 270: mean=0.705, min=0.476, max=0.949, std=0.137\n",
      "ID 271: mean=0.695, min=0.553, max=0.909, std=0.097\n",
      "ID 272: mean=0.686, min=0.516, max=0.858, std=0.088\n",
      "ID 273: mean=0.724, min=0.579, max=0.880, std=0.093\n",
      "ID 274: mean=0.799, min=0.700, max=0.897, std=0.064\n",
      "ID 275: mean=0.628, min=0.402, max=0.854, std=0.108\n",
      "ID 276: mean=0.755, min=0.580, max=0.848, std=0.074\n",
      "ID 277: mean=0.821, min=0.658, max=0.927, std=0.076\n",
      "ID 278: mean=0.683, min=0.494, max=0.873, std=0.120\n",
      "ID 279: mean=0.681, min=0.532, max=0.879, std=0.103\n",
      "ID 280: mean=0.870, min=0.757, max=0.958, std=0.050\n",
      "ID 281: mean=0.789, min=0.643, max=0.940, std=0.081\n",
      "ID 282: mean=0.799, min=0.671, max=0.918, std=0.057\n",
      "ID 283: mean=0.801, min=0.641, max=0.939, std=0.078\n",
      "ID 284: mean=0.817, min=0.584, max=0.925, std=0.089\n",
      "ID 285: mean=0.723, min=0.533, max=0.922, std=0.104\n",
      "ID 286: mean=0.781, min=0.497, max=0.931, std=0.099\n",
      "ID 287: mean=0.807, min=0.605, max=0.947, std=0.084\n",
      "ID 288: mean=0.845, min=0.710, max=0.930, std=0.055\n",
      "ID 289: mean=0.837, min=0.758, max=0.968, std=0.046\n",
      "ID 290: mean=0.826, min=0.681, max=0.950, std=0.073\n",
      "ID 291: mean=0.769, min=0.500, max=0.927, std=0.111\n",
      "ID 292: mean=0.810, min=0.569, max=0.931, std=0.072\n",
      "ID 293: mean=0.801, min=0.586, max=0.944, std=0.087\n",
      "ID 294: mean=0.800, min=0.629, max=0.921, std=0.096\n",
      "ID 295: mean=0.730, min=0.561, max=0.848, std=0.073\n",
      "ID 296: mean=0.862, min=0.782, max=0.935, std=0.047\n",
      "ID 297: mean=0.756, min=0.619, max=0.886, std=0.081\n",
      "ID 298: mean=0.756, min=0.527, max=0.934, std=0.105\n",
      "ID 299: mean=0.690, min=0.449, max=0.901, std=0.108\n",
      "ID 300: mean=0.657, min=0.413, max=0.858, std=0.109\n",
      "ID 301: mean=0.633, min=0.425, max=0.835, std=0.108\n",
      "ID 302: mean=0.682, min=0.474, max=0.848, std=0.102\n",
      "ID 303: mean=0.700, min=0.446, max=0.866, std=0.086\n",
      "ID 304: mean=0.678, min=0.473, max=0.830, std=0.089\n",
      "ID 305: mean=0.783, min=0.553, max=0.956, std=0.083\n",
      "ID 306: mean=0.795, min=0.619, max=0.941, std=0.071\n",
      "ID 307: mean=0.689, min=0.518, max=0.965, std=0.117\n",
      "ID 308: mean=0.792, min=0.642, max=0.946, std=0.072\n",
      "ID 309: mean=0.755, min=0.517, max=0.929, std=0.099\n",
      "ID 310: mean=0.687, min=0.556, max=0.942, std=0.084\n",
      "ID 311: mean=0.693, min=0.477, max=0.821, std=0.086\n",
      "ID 312: mean=0.715, min=0.582, max=0.890, std=0.086\n",
      "ID 313: mean=0.677, min=0.469, max=0.880, std=0.119\n",
      "ID 314: mean=0.661, min=0.394, max=0.878, std=0.123\n",
      "ID 315: mean=0.761, min=0.639, max=0.938, std=0.074\n",
      "ID 316: mean=0.759, min=0.526, max=0.907, std=0.095\n",
      "ID 317: mean=0.771, min=0.620, max=0.948, std=0.104\n",
      "ID 318: mean=0.697, min=0.449, max=0.919, std=0.107\n",
      "ID 319: mean=0.700, min=0.489, max=0.901, std=0.079\n",
      "ID 320: mean=0.726, min=0.533, max=0.895, std=0.121\n",
      "ID 321: mean=0.695, min=0.504, max=0.885, std=0.105\n",
      "ID 322: mean=0.742, min=0.492, max=0.894, std=0.106\n",
      "ID 323: mean=0.703, min=0.466, max=0.883, std=0.134\n",
      "ID 324: mean=0.709, min=0.466, max=0.879, std=0.109\n",
      "ID 325: mean=0.777, min=0.594, max=0.914, std=0.079\n",
      "ID 326: mean=0.666, min=0.512, max=0.843, std=0.093\n",
      "ID 327: mean=0.762, min=0.622, max=0.930, std=0.069\n",
      "ID 328: mean=0.683, min=0.558, max=0.831, std=0.082\n",
      "ID 329: mean=0.785, min=0.653, max=0.903, std=0.060\n",
      "ID 330: mean=0.619, min=0.481, max=0.824, std=0.103\n",
      "ID 331: mean=0.769, min=0.620, max=0.920, std=0.069\n",
      "ID 332: mean=0.826, min=0.670, max=0.926, std=0.065\n",
      "ID 333: mean=0.703, min=0.515, max=0.896, std=0.098\n",
      "ID 334: mean=0.743, min=0.516, max=0.911, std=0.106\n",
      "ID 335: mean=0.725, min=0.495, max=0.910, std=0.097\n",
      "ID 336: mean=0.826, min=0.687, max=0.926, std=0.059\n",
      "ID 337: mean=0.685, min=0.427, max=0.854, std=0.092\n",
      "ID 338: mean=0.792, min=0.596, max=0.967, std=0.085\n",
      "ID 339: mean=0.803, min=0.727, max=0.894, std=0.042\n",
      "ID 340: mean=0.795, min=0.503, max=0.956, std=0.131\n",
      "ID 341: mean=0.764, min=0.535, max=0.948, std=0.135\n",
      "ID 342: mean=0.826, min=0.730, max=0.926, std=0.050\n",
      "ID 343: mean=0.805, min=0.516, max=0.935, std=0.092\n",
      "ID 344: mean=0.831, min=0.645, max=0.938, std=0.077\n",
      "ID 345: mean=0.768, min=0.566, max=0.918, std=0.085\n",
      "ID 346: mean=0.790, min=0.564, max=0.937, std=0.093\n",
      "ID 347: mean=0.787, min=0.515, max=0.917, std=0.093\n",
      "ID 348: mean=0.709, min=0.524, max=0.916, std=0.097\n",
      "ID 349: mean=0.816, min=0.673, max=0.902, std=0.063\n",
      "ID 350: mean=0.660, min=0.445, max=0.823, std=0.089\n",
      "ID 351: mean=0.729, min=0.577, max=0.868, std=0.082\n",
      "ID 352: mean=0.697, min=0.535, max=0.879, std=0.097\n",
      "ID 353: mean=0.698, min=0.551, max=0.878, std=0.085\n",
      "ID 354: mean=0.772, min=0.620, max=0.959, std=0.084\n",
      "ID 355: mean=0.781, min=0.519, max=0.915, std=0.095\n",
      "ID 356: mean=0.761, min=0.610, max=0.944, std=0.086\n",
      "ID 357: mean=0.774, min=0.581, max=0.909, std=0.079\n",
      "ID 358: mean=0.858, min=0.723, max=0.958, std=0.064\n",
      "ID 359: mean=0.749, min=0.461, max=0.956, std=0.122\n",
      "ID 360: mean=0.831, min=0.677, max=0.976, std=0.076\n",
      "ID 361: mean=0.765, min=0.609, max=0.926, std=0.082\n",
      "ID 362: mean=0.862, min=0.717, max=0.948, std=0.060\n",
      "ID 363: mean=0.709, min=0.557, max=0.839, std=0.077\n",
      "ID 364: mean=0.704, min=0.421, max=0.931, std=0.145\n",
      "ID 365: mean=0.722, min=0.503, max=0.913, std=0.116\n",
      "ID 366: mean=0.751, min=0.594, max=0.916, std=0.093\n",
      "ID 367: mean=0.779, min=0.487, max=0.916, std=0.093\n",
      "ID 368: mean=0.826, min=0.728, max=0.927, std=0.061\n",
      "ID 369: mean=0.689, min=0.495, max=0.872, std=0.102\n",
      "ID 370: mean=0.746, min=0.505, max=0.892, std=0.093\n",
      "ID 371: mean=0.689, min=0.499, max=0.887, std=0.098\n",
      "ID 372: mean=0.691, min=0.490, max=0.898, std=0.091\n",
      "ID 373: mean=0.711, min=0.591, max=0.894, std=0.065\n",
      "ID 374: mean=0.725, min=0.489, max=0.908, std=0.084\n",
      "ID 375: mean=0.701, min=0.508, max=0.881, std=0.089\n",
      "ID 376: mean=0.763, min=0.529, max=0.943, std=0.096\n",
      "ID 377: mean=0.736, min=0.528, max=0.919, std=0.102\n",
      "ID 378: mean=0.724, min=0.537, max=0.905, std=0.090\n",
      "ID 379: mean=0.716, min=0.508, max=0.921, std=0.085\n",
      "ID 380: mean=0.810, min=0.723, max=0.918, std=0.054\n",
      "ID 381: mean=0.725, min=0.596, max=0.836, std=0.065\n",
      "ID 382: mean=0.834, min=0.746, max=0.941, std=0.045\n",
      "ID 383: mean=0.845, min=0.668, max=0.942, std=0.079\n",
      "ID 384: mean=0.770, min=0.540, max=0.945, std=0.107\n",
      "ID 385: mean=0.711, min=0.527, max=0.823, std=0.064\n",
      "ID 386: mean=0.733, min=0.533, max=0.918, std=0.079\n",
      "ID 387: mean=0.708, min=0.578, max=0.829, std=0.059\n",
      "ID 388: mean=0.724, min=0.574, max=0.916, std=0.078\n",
      "ID 389: mean=0.654, min=0.494, max=0.819, std=0.066\n",
      "ID 390: mean=0.712, min=0.532, max=0.906, std=0.072\n",
      "ID 391: mean=0.780, min=0.647, max=0.967, std=0.071\n",
      "ID 392: mean=0.829, min=0.667, max=0.911, std=0.060\n",
      "ID 393: mean=0.712, min=0.542, max=0.933, std=0.084\n",
      "ID 394: mean=0.809, min=0.578, max=0.954, std=0.084\n",
      "ID 395: mean=0.816, min=0.620, max=0.933, std=0.073\n",
      "ID 396: mean=0.701, min=0.458, max=0.888, std=0.118\n",
      "ID 397: mean=0.733, min=0.556, max=0.891, std=0.076\n",
      "ID 398: mean=0.796, min=0.621, max=0.916, std=0.054\n",
      "ID 399: mean=0.746, min=0.592, max=0.886, std=0.066\n",
      "ID 400: mean=0.756, min=0.547, max=0.940, std=0.084\n",
      "ID 401: mean=0.770, min=0.519, max=0.918, std=0.084\n",
      "ID 402: mean=0.695, min=0.558, max=0.844, std=0.068\n",
      "ID 403: mean=0.834, min=0.684, max=0.947, std=0.057\n",
      "ID 404: mean=0.808, min=0.583, max=0.957, std=0.101\n",
      "ID 405: mean=0.767, min=0.503, max=0.908, std=0.093\n",
      "ID 406: mean=0.793, min=0.586, max=0.923, std=0.078\n",
      "ID 407: mean=0.719, min=0.505, max=0.945, std=0.097\n",
      "ID 408: mean=0.782, min=0.647, max=0.907, std=0.064\n",
      "ID 409: mean=0.781, min=0.578, max=0.927, std=0.085\n",
      "ID 410: mean=0.730, min=0.383, max=0.916, std=0.132\n",
      "ID 411: mean=0.790, min=0.680, max=0.942, std=0.059\n",
      "ID 412: mean=0.728, min=0.541, max=0.902, std=0.106\n",
      "ID 413: mean=0.775, min=0.620, max=0.913, std=0.092\n",
      "ID 414: mean=0.770, min=0.504, max=0.920, std=0.089\n",
      "ID 415: mean=0.732, min=0.482, max=0.965, std=0.109\n",
      "ID 416: mean=0.835, min=0.749, max=0.939, std=0.045\n",
      "ID 417: mean=0.768, min=0.582, max=0.935, std=0.091\n",
      "ID 418: mean=0.858, min=0.728, max=0.963, std=0.051\n",
      "ID 419: mean=0.745, min=0.501, max=0.907, std=0.102\n",
      "ID 420: mean=0.855, min=0.708, max=0.948, std=0.062\n",
      "ID 421: mean=0.802, min=0.633, max=0.937, std=0.066\n",
      "ID 422: mean=0.765, min=0.526, max=0.938, std=0.138\n",
      "ID 423: mean=0.811, min=0.609, max=0.942, std=0.077\n",
      "ID 424: mean=0.701, min=0.529, max=0.876, std=0.087\n",
      "ID 425: mean=0.760, min=0.608, max=0.904, std=0.075\n",
      "ID 426: mean=0.784, min=0.697, max=0.924, std=0.059\n",
      "ID 427: mean=0.761, min=0.587, max=0.926, std=0.099\n",
      "ID 428: mean=0.853, min=0.709, max=0.942, std=0.063\n",
      "ID 429: mean=0.747, min=0.425, max=0.924, std=0.112\n",
      "ID 430: mean=0.664, min=0.483, max=0.888, std=0.107\n",
      "ID 431: mean=0.769, min=0.533, max=0.922, std=0.086\n",
      "ID 432: mean=0.803, min=0.696, max=0.926, std=0.051\n",
      "ID 433: mean=0.843, min=0.708, max=0.963, std=0.062\n",
      "ID 434: mean=0.826, min=0.649, max=0.955, std=0.079\n",
      "ID 435: mean=0.810, min=0.637, max=0.969, std=0.079\n",
      "ID 436: mean=0.807, min=0.711, max=0.953, std=0.058\n",
      "ID 437: mean=0.860, min=0.739, max=0.961, std=0.064\n",
      "ID 438: mean=0.835, min=0.600, max=0.954, std=0.093\n",
      "ID 439: mean=0.844, min=0.578, max=0.960, std=0.120\n",
      "ID 440: mean=0.728, min=0.483, max=0.915, std=0.121\n",
      "ID 441: mean=0.758, min=0.570, max=0.891, std=0.080\n",
      "ID 442: mean=0.748, min=0.505, max=0.928, std=0.108\n",
      "ID 443: mean=0.809, min=0.633, max=0.936, std=0.085\n",
      "ID 444: mean=0.801, min=0.666, max=0.907, std=0.063\n",
      "ID 445: mean=0.827, min=0.656, max=0.944, std=0.064\n",
      "ID 446: mean=0.854, min=0.738, max=0.920, std=0.053\n",
      "ID 447: mean=0.843, min=0.764, max=0.932, std=0.055\n",
      "ID 448: mean=0.845, min=0.650, max=0.951, std=0.082\n",
      "ID 449: mean=0.853, min=0.661, max=0.919, std=0.063\n",
      "ID 450: mean=0.704, min=0.530, max=0.868, std=0.082\n",
      "ID 451: mean=0.828, min=0.676, max=0.921, std=0.063\n",
      "ID 452: mean=0.796, min=0.620, max=0.920, std=0.074\n",
      "ID 453: mean=0.754, min=0.586, max=0.884, std=0.070\n",
      "ID 454: mean=0.832, min=0.624, max=0.936, std=0.062\n",
      "ID 455: mean=0.675, min=0.455, max=0.887, std=0.102\n",
      "ID 456: mean=0.760, min=0.602, max=0.915, std=0.073\n",
      "ID 457: mean=0.845, min=0.569, max=0.965, std=0.097\n",
      "ID 458: mean=0.829, min=0.558, max=0.951, std=0.115\n",
      "ID 459: mean=0.826, min=0.631, max=0.928, std=0.065\n",
      "ID 460: mean=0.756, min=0.504, max=0.936, std=0.092\n",
      "ID 461: mean=0.794, min=0.677, max=0.923, std=0.058\n",
      "ID 462: mean=0.837, min=0.712, max=0.912, std=0.044\n",
      "ID 463: mean=0.884, min=0.727, max=0.969, std=0.057\n",
      "ID 464: mean=0.857, min=0.730, max=0.968, std=0.055\n",
      "ID 465: mean=0.849, min=0.764, max=0.948, std=0.044\n",
      "ID 466: mean=0.806, min=0.673, max=0.967, std=0.087\n",
      "ID 467: mean=0.863, min=0.741, max=0.966, std=0.064\n",
      "ID 468: mean=0.857, min=0.686, max=0.922, std=0.051\n",
      "ID 469: mean=0.848, min=0.753, max=0.933, std=0.049\n",
      "ID 470: mean=0.594, min=0.443, max=0.798, std=0.114\n",
      "ID 471: mean=0.909, min=0.873, max=0.971, std=0.029\n",
      "ID 472: mean=0.681, min=0.497, max=0.921, std=0.127\n",
      "ID 473: mean=0.897, min=0.841, max=0.944, std=0.029\n",
      "ID 474: mean=0.775, min=0.538, max=0.893, std=0.094\n",
      "ID 475: mean=0.800, min=0.568, max=0.944, std=0.110\n",
      "ID 476: mean=0.852, min=0.765, max=0.931, std=0.045\n",
      "ID 477: mean=0.768, min=0.578, max=0.903, std=0.095\n",
      "ID 478: mean=0.848, min=0.628, max=0.948, std=0.085\n",
      "ID 479: mean=0.928, min=0.880, max=0.962, std=0.026\n",
      "ID 480: mean=0.745, min=0.577, max=0.936, std=0.107\n",
      "ID 481: mean=0.776, min=0.608, max=0.895, std=0.086\n",
      "ID 482: mean=0.789, min=0.565, max=0.921, std=0.090\n",
      "ID 483: mean=0.758, min=0.569, max=0.932, std=0.102\n",
      "ID 484: mean=0.686, min=0.414, max=0.901, std=0.146\n",
      "ID 485: mean=0.712, min=0.467, max=0.883, std=0.106\n",
      "ID 486: mean=0.792, min=0.560, max=0.936, std=0.086\n",
      "ID 487: mean=0.763, min=0.627, max=0.936, std=0.064\n",
      "ID 488: mean=0.719, min=0.534, max=0.907, std=0.096\n",
      "ID 489: mean=0.838, min=0.663, max=0.969, std=0.076\n",
      "ID 490: mean=0.757, min=0.538, max=0.916, std=0.102\n",
      "ID 491: mean=0.726, min=0.500, max=0.914, std=0.110\n",
      "ID 492: mean=0.701, min=0.516, max=0.864, std=0.091\n",
      "ID 493: mean=0.800, min=0.544, max=0.914, std=0.088\n",
      "ID 494: mean=0.779, min=0.540, max=0.956, std=0.103\n",
      "ID 495: mean=0.813, min=0.632, max=0.954, std=0.076\n",
      "ID 496: mean=0.831, min=0.657, max=0.965, std=0.069\n",
      "ID 497: mean=0.720, min=0.440, max=0.922, std=0.116\n",
      "ID 498: mean=0.769, min=0.554, max=0.933, std=0.091\n",
      "ID 499: mean=0.792, min=0.586, max=0.939, std=0.088\n",
      "ID 500: mean=0.701, min=0.515, max=0.953, std=0.090\n",
      "ID 501: mean=0.778, min=0.580, max=0.937, std=0.083\n",
      "ID 502: mean=0.813, min=0.499, max=0.959, std=0.116\n",
      "ID 503: mean=0.716, min=0.569, max=0.879, std=0.084\n",
      "ID 504: mean=0.763, min=0.603, max=0.935, std=0.077\n",
      "ID 505: mean=0.827, min=0.659, max=0.958, std=0.067\n",
      "ID 506: mean=0.727, min=0.460, max=0.902, std=0.117\n",
      "ID 507: mean=0.771, min=0.447, max=0.945, std=0.106\n",
      "ID 508: mean=0.761, min=0.615, max=0.913, std=0.073\n",
      "ID 509: mean=0.834, min=0.674, max=0.939, std=0.062\n",
      "ID 510: mean=0.732, min=0.552, max=0.908, std=0.089\n",
      "ID 511: mean=0.687, min=0.555, max=0.885, std=0.080\n",
      "ID 512: mean=0.692, min=0.500, max=0.984, std=0.103\n",
      "ID 513: mean=0.727, min=0.494, max=0.943, std=0.116\n",
      "ID 514: mean=0.751, min=0.590, max=0.960, std=0.093\n",
      "ID 515: mean=0.724, min=0.574, max=0.876, std=0.070\n",
      "ID 516: mean=0.777, min=0.534, max=0.949, std=0.102\n",
      "ID 517: mean=0.778, min=0.563, max=0.930, std=0.080\n",
      "ID 518: mean=0.911, min=0.840, max=0.967, std=0.029\n",
      "ID 519: mean=0.839, min=0.555, max=0.955, std=0.092\n",
      "ID 520: mean=0.772, min=0.666, max=0.913, std=0.067\n",
      "ID 521: mean=0.729, min=0.447, max=0.956, std=0.133\n",
      "ID 522: mean=0.715, min=0.446, max=0.938, std=0.121\n",
      "ID 523: mean=0.747, min=0.489, max=0.921, std=0.100\n",
      "ID 524: mean=0.835, min=0.688, max=0.939, std=0.066\n",
      "ID 525: mean=0.787, min=0.494, max=0.942, std=0.105\n",
      "ID 526: mean=0.751, min=0.424, max=0.913, std=0.107\n",
      "ID 527: mean=0.750, min=0.597, max=0.952, std=0.090\n",
      "ID 528: mean=0.790, min=0.585, max=0.943, std=0.083\n",
      "ID 529: mean=0.717, min=0.419, max=0.941, std=0.155\n",
      "ID 530: mean=0.789, min=0.422, max=0.955, std=0.121\n",
      "ID 531: mean=0.728, min=0.555, max=0.915, std=0.090\n",
      "ID 532: mean=0.797, min=0.622, max=0.930, std=0.085\n",
      "ID 533: mean=0.772, min=0.530, max=0.926, std=0.100\n",
      "ID 534: mean=0.760, min=0.438, max=0.940, std=0.103\n",
      "ID 535: mean=0.806, min=0.483, max=0.965, std=0.103\n",
      "ID 536: mean=0.761, min=0.562, max=0.924, std=0.082\n",
      "ID 537: mean=0.848, min=0.739, max=0.965, std=0.051\n",
      "ID 538: mean=0.774, min=0.577, max=0.930, std=0.097\n",
      "ID 539: mean=0.730, min=0.456, max=0.916, std=0.096\n",
      "ID 540: mean=0.718, min=0.490, max=0.889, std=0.110\n",
      "ID 541: mean=0.764, min=0.511, max=0.910, std=0.110\n",
      "ID 542: mean=0.801, min=0.436, max=0.972, std=0.153\n",
      "ID 543: mean=0.766, min=0.617, max=0.918, std=0.087\n",
      "ID 544: mean=0.766, min=0.601, max=0.976, std=0.094\n",
      "ID 545: mean=0.682, min=0.572, max=0.955, std=0.099\n",
      "ID 546: mean=0.735, min=0.585, max=0.915, std=0.097\n",
      "ID 547: mean=0.783, min=0.523, max=0.926, std=0.102\n",
      "ID 548: mean=0.727, min=0.523, max=0.931, std=0.118\n",
      "ID 549: mean=0.759, min=0.590, max=0.941, std=0.117\n",
      "ID 550: mean=0.656, min=0.455, max=0.854, std=0.096\n",
      "ID 551: mean=0.640, min=0.473, max=0.857, std=0.087\n",
      "ID 552: mean=0.705, min=0.500, max=0.909, std=0.093\n",
      "ID 553: mean=0.755, min=0.543, max=0.952, std=0.111\n",
      "ID 554: mean=0.801, min=0.682, max=0.956, std=0.075\n",
      "ID 555: mean=0.794, min=0.624, max=0.929, std=0.075\n",
      "ID 556: mean=0.719, min=0.543, max=0.886, std=0.091\n",
      "ID 557: mean=0.739, min=0.562, max=0.885, std=0.082\n",
      "ID 558: mean=0.727, min=0.510, max=0.950, std=0.105\n",
      "ID 559: mean=0.763, min=0.532, max=0.941, std=0.102\n",
      "ID 560: mean=0.720, min=0.429, max=0.949, std=0.111\n",
      "ID 561: mean=0.839, min=0.784, max=0.912, std=0.036\n",
      "ID 562: mean=0.795, min=0.689, max=0.964, std=0.053\n",
      "ID 563: mean=0.783, min=0.604, max=0.942, std=0.094\n",
      "ID 564: mean=0.731, min=0.563, max=0.929, std=0.099\n",
      "ID 565: mean=0.712, min=0.463, max=0.906, std=0.102\n",
      "ID 566: mean=0.662, min=0.433, max=0.907, std=0.104\n",
      "ID 567: mean=0.774, min=0.586, max=0.958, std=0.091\n",
      "ID 568: mean=0.690, min=0.513, max=0.903, std=0.102\n",
      "ID 569: mean=0.823, min=0.560, max=0.972, std=0.100\n",
      "ID 570: mean=0.819, min=0.479, max=0.971, std=0.125\n",
      "ID 571: mean=0.784, min=0.450, max=0.957, std=0.109\n",
      "ID 572: mean=0.815, min=0.587, max=0.948, std=0.089\n",
      "ID 573: mean=0.750, min=0.554, max=0.926, std=0.089\n",
      "ID 574: mean=0.750, min=0.507, max=0.915, std=0.090\n",
      "ID 575: mean=0.847, min=0.711, max=0.976, std=0.059\n",
      "ID 576: mean=0.787, min=0.634, max=0.922, std=0.072\n",
      "ID 577: mean=0.714, min=0.549, max=0.872, std=0.079\n",
      "ID 578: mean=0.829, min=0.631, max=0.961, std=0.079\n",
      "ID 579: mean=0.727, min=0.481, max=0.923, std=0.115\n",
      "ID 580: mean=0.813, min=0.668, max=0.917, std=0.063\n",
      "ID 581: mean=0.848, min=0.726, max=0.944, std=0.052\n",
      "ID 582: mean=0.695, min=0.479, max=0.865, std=0.093\n",
      "ID 583: mean=0.754, min=0.510, max=0.971, std=0.118\n",
      "ID 584: mean=0.750, min=0.544, max=0.943, std=0.106\n",
      "ID 585: mean=0.745, min=0.553, max=0.887, std=0.097\n",
      "ID 586: mean=0.855, min=0.768, max=0.931, std=0.039\n",
      "ID 587: mean=0.795, min=0.563, max=0.966, std=0.109\n",
      "ID 588: mean=0.756, min=0.556, max=0.885, std=0.078\n",
      "ID 589: mean=0.752, min=0.462, max=0.920, std=0.110\n",
      "ID 590: mean=0.769, min=0.607, max=0.955, std=0.097\n",
      "ID 591: mean=0.695, min=0.527, max=0.942, std=0.077\n",
      "ID 592: mean=0.748, min=0.583, max=0.932, std=0.075\n",
      "ID 593: mean=0.822, min=0.617, max=0.966, std=0.084\n",
      "ID 594: mean=0.768, min=0.456, max=0.989, std=0.130\n",
      "ID 595: mean=0.729, min=0.383, max=0.941, std=0.140\n",
      "ID 596: mean=0.851, min=0.585, max=0.969, std=0.081\n",
      "ID 597: mean=0.776, min=0.607, max=0.931, std=0.082\n",
      "ID 598: mean=0.740, min=0.517, max=0.970, std=0.102\n",
      "ID 599: mean=0.811, min=0.611, max=0.941, std=0.070\n",
      "ID 600: mean=0.767, min=0.581, max=0.951, std=0.097\n",
      "ID 601: mean=0.739, min=0.593, max=0.862, std=0.079\n",
      "ID 602: mean=0.761, min=0.601, max=0.892, std=0.088\n",
      "ID 603: mean=0.806, min=0.504, max=0.952, std=0.134\n",
      "ID 604: mean=0.650, min=0.507, max=0.835, std=0.090\n",
      "ID 605: mean=0.764, min=0.602, max=0.962, std=0.093\n",
      "ID 606: mean=0.814, min=0.648, max=0.937, std=0.082\n",
      "ID 607: mean=0.856, min=0.712, max=0.935, std=0.061\n",
      "ID 608: mean=0.845, min=0.752, max=0.918, std=0.043\n",
      "ID 609: mean=0.719, min=0.558, max=0.868, std=0.079\n",
      "ID 610: mean=0.680, min=0.490, max=0.933, std=0.101\n",
      "ID 611: mean=0.815, min=0.453, max=0.960, std=0.128\n",
      "ID 612: mean=0.820, min=0.529, max=0.943, std=0.107\n",
      "ID 613: mean=0.866, min=0.722, max=0.947, std=0.072\n",
      "ID 614: mean=0.816, min=0.677, max=0.939, std=0.077\n",
      "ID 615: mean=0.697, min=0.556, max=0.878, std=0.074\n",
      "ID 616: mean=0.811, min=0.551, max=0.964, std=0.104\n",
      "ID 617: mean=0.778, min=0.532, max=0.963, std=0.102\n",
      "ID 618: mean=0.772, min=0.601, max=0.945, std=0.079\n",
      "ID 619: mean=0.751, min=0.576, max=0.871, std=0.076\n",
      "ID 620: mean=0.726, min=0.538, max=0.909, std=0.083\n",
      "ID 621: mean=0.711, min=0.583, max=0.960, std=0.097\n",
      "ID 622: mean=0.751, min=0.554, max=0.914, std=0.093\n",
      "ID 623: mean=0.742, min=0.507, max=0.970, std=0.151\n",
      "ID 624: mean=0.703, min=0.546, max=0.856, std=0.090\n",
      "ID 625: mean=0.836, min=0.593, max=0.965, std=0.099\n",
      "ID 626: mean=0.841, min=0.581, max=0.959, std=0.096\n",
      "ID 627: mean=0.831, min=0.544, max=0.946, std=0.098\n",
      "ID 628: mean=0.805, min=0.569, max=0.943, std=0.114\n",
      "ID 629: mean=0.879, min=0.765, max=0.963, std=0.046\n",
      "ID 630: mean=0.717, min=0.503, max=0.876, std=0.093\n",
      "ID 631: mean=0.769, min=0.490, max=0.921, std=0.145\n",
      "ID 632: mean=0.796, min=0.549, max=0.939, std=0.117\n",
      "ID 633: mean=0.660, min=0.454, max=0.861, std=0.121\n",
      "ID 634: mean=0.886, min=0.701, max=0.977, std=0.073\n",
      "ID 635: mean=0.829, min=0.636, max=0.927, std=0.067\n",
      "ID 636: mean=0.812, min=0.631, max=0.943, std=0.086\n",
      "ID 637: mean=0.818, min=0.727, max=0.933, std=0.058\n",
      "ID 638: mean=0.788, min=0.521, max=0.934, std=0.110\n",
      "ID 639: mean=0.733, min=0.547, max=0.929, std=0.111\n",
      "ID 640: mean=0.794, min=0.481, max=0.969, std=0.114\n",
      "ID 641: mean=0.729, min=0.487, max=0.941, std=0.111\n",
      "ID 642: mean=0.841, min=0.706, max=0.960, std=0.083\n",
      "ID 643: mean=0.788, min=0.575, max=0.955, std=0.093\n",
      "ID 644: mean=0.866, min=0.700, max=0.935, std=0.050\n",
      "ID 645: mean=0.683, min=0.514, max=0.850, std=0.086\n",
      "ID 646: mean=0.729, min=0.465, max=0.929, std=0.146\n",
      "ID 647: mean=0.755, min=0.481, max=0.911, std=0.095\n",
      "ID 648: mean=0.694, min=0.541, max=0.893, std=0.083\n",
      "ID 649: mean=0.758, min=0.503, max=0.914, std=0.097\n",
      "ID 650: mean=0.680, min=0.550, max=0.804, std=0.073\n",
      "ID 651: mean=0.738, min=0.513, max=0.949, std=0.112\n",
      "ID 652: mean=0.750, min=0.507, max=0.948, std=0.092\n",
      "ID 653: mean=0.774, min=0.556, max=0.924, std=0.094\n",
      "ID 654: mean=0.743, min=0.539, max=0.933, std=0.095\n",
      "ID 655: mean=0.817, min=0.546, max=0.959, std=0.110\n",
      "ID 656: mean=0.688, min=0.468, max=0.847, std=0.080\n",
      "ID 657: mean=0.791, min=0.564, max=0.944, std=0.095\n",
      "ID 658: mean=0.853, min=0.746, max=0.972, std=0.066\n",
      "ID 659: mean=0.791, min=0.610, max=0.964, std=0.110\n",
      "ID 660: mean=0.754, min=0.464, max=0.931, std=0.119\n",
      "ID 661: mean=0.874, min=0.708, max=0.976, std=0.071\n",
      "ID 662: mean=0.921, min=0.858, max=0.963, std=0.027\n",
      "ID 663: mean=0.815, min=0.715, max=0.945, std=0.067\n",
      "ID 664: mean=0.723, min=0.509, max=0.899, std=0.112\n",
      "ID 665: mean=0.711, min=0.566, max=0.869, std=0.076\n",
      "ID 666: mean=0.826, min=0.640, max=0.924, std=0.078\n",
      "ID 667: mean=0.734, min=0.575, max=0.917, std=0.091\n",
      "ID 668: mean=0.849, min=0.704, max=0.947, std=0.057\n",
      "ID 669: mean=0.739, min=0.380, max=0.965, std=0.154\n",
      "ID 670: mean=0.734, min=0.558, max=0.965, std=0.100\n",
      "ID 671: mean=0.638, min=0.501, max=0.808, std=0.069\n",
      "ID 672: mean=0.692, min=0.515, max=0.860, std=0.080\n",
      "ID 673: mean=0.645, min=0.463, max=0.900, std=0.105\n",
      "ID 674: mean=0.722, min=0.530, max=0.955, std=0.110\n",
      "ID 675: mean=0.761, min=0.644, max=0.926, std=0.082\n",
      "ID 676: mean=0.736, min=0.539, max=0.923, std=0.085\n",
      "ID 677: mean=0.653, min=0.502, max=0.771, std=0.069\n",
      "ID 678: mean=0.685, min=0.499, max=0.896, std=0.112\n",
      "ID 679: mean=0.686, min=0.490, max=0.836, std=0.091\n",
      "ID 680: mean=0.717, min=0.511, max=0.948, std=0.119\n",
      "ID 681: mean=0.742, min=0.592, max=0.959, std=0.091\n",
      "ID 682: mean=0.853, min=0.744, max=0.959, std=0.052\n",
      "ID 683: mean=0.862, min=0.586, max=0.957, std=0.093\n",
      "ID 684: mean=0.801, min=0.665, max=0.980, std=0.079\n",
      "ID 685: mean=0.726, min=0.503, max=0.940, std=0.123\n",
      "ID 686: mean=0.773, min=0.551, max=0.900, std=0.083\n",
      "ID 687: mean=0.870, min=0.699, max=0.975, std=0.079\n",
      "ID 688: mean=0.760, min=0.559, max=0.907, std=0.081\n",
      "ID 689: mean=0.745, min=0.430, max=0.953, std=0.135\n",
      "ID 690: mean=0.782, min=0.613, max=0.938, std=0.072\n",
      "ID 691: mean=0.809, min=0.702, max=0.945, std=0.066\n",
      "ID 692: mean=0.783, min=0.583, max=0.894, std=0.075\n",
      "ID 693: mean=0.726, min=0.527, max=0.925, std=0.110\n",
      "ID 694: mean=0.856, min=0.667, max=0.941, std=0.064\n",
      "ID 695: mean=0.786, min=0.575, max=0.965, std=0.100\n",
      "ID 696: mean=0.715, min=0.514, max=0.932, std=0.111\n",
      "ID 697: mean=0.891, min=0.805, max=0.962, std=0.037\n",
      "ID 698: mean=0.809, min=0.674, max=0.951, std=0.072\n",
      "ID 699: mean=0.783, min=0.622, max=0.921, std=0.077\n",
      "ID 700: mean=0.711, min=0.514, max=0.932, std=0.124\n",
      "ID 701: mean=0.632, min=0.452, max=0.930, std=0.144\n",
      "ID 702: mean=0.825, min=0.712, max=0.947, std=0.067\n",
      "ID 703: mean=0.805, min=0.664, max=0.945, std=0.074\n",
      "ID 704: mean=0.739, min=0.512, max=0.959, std=0.108\n",
      "ID 705: mean=0.703, min=0.508, max=0.904, std=0.113\n",
      "ID 706: mean=0.760, min=0.538, max=0.935, std=0.134\n",
      "ID 707: mean=0.683, min=0.486, max=0.880, std=0.092\n",
      "ID 708: mean=0.819, min=0.585, max=0.941, std=0.109\n",
      "ID 709: mean=0.767, min=0.639, max=0.938, std=0.062\n",
      "ID 710: mean=0.772, min=0.537, max=0.964, std=0.117\n",
      "ID 711: mean=0.841, min=0.611, max=0.943, std=0.085\n",
      "ID 712: mean=0.751, min=0.583, max=0.878, std=0.077\n",
      "ID 713: mean=0.709, min=0.449, max=0.937, std=0.126\n",
      "ID 714: mean=0.871, min=0.787, max=0.968, std=0.049\n",
      "ID 715: mean=0.783, min=0.504, max=0.926, std=0.088\n",
      "ID 716: mean=0.800, min=0.669, max=0.932, std=0.075\n",
      "ID 717: mean=0.816, min=0.628, max=0.958, std=0.069\n",
      "ID 718: mean=0.784, min=0.561, max=0.966, std=0.107\n",
      "ID 719: mean=0.745, min=0.507, max=0.938, std=0.115\n",
      "ID 720: mean=0.799, min=0.659, max=0.950, std=0.066\n",
      "ID 721: mean=0.848, min=0.698, max=0.977, std=0.077\n",
      "ID 722: mean=0.742, min=0.545, max=0.919, std=0.100\n",
      "ID 723: mean=0.834, min=0.562, max=0.954, std=0.089\n",
      "ID 724: mean=0.799, min=0.515, max=0.949, std=0.107\n",
      "ID 725: mean=0.879, min=0.732, max=0.952, std=0.053\n",
      "ID 726: mean=0.776, min=0.648, max=0.902, std=0.076\n",
      "ID 727: mean=0.780, min=0.590, max=0.958, std=0.087\n",
      "ID 728: mean=0.809, min=0.563, max=0.948, std=0.106\n",
      "ID 729: mean=0.785, min=0.629, max=0.976, std=0.093\n",
      "ID 730: mean=0.712, min=0.502, max=0.921, std=0.132\n",
      "ID 731: mean=0.751, min=0.593, max=0.932, std=0.075\n",
      "ID 732: mean=0.920, min=0.845, max=0.967, std=0.026\n",
      "ID 733: mean=0.826, min=0.699, max=0.963, std=0.061\n",
      "ID 734: mean=0.797, min=0.564, max=0.951, std=0.112\n",
      "ID 735: mean=0.792, min=0.453, max=0.967, std=0.123\n",
      "ID 736: mean=0.773, min=0.617, max=0.946, std=0.088\n",
      "ID 737: mean=0.776, min=0.625, max=0.919, std=0.076\n",
      "ID 738: mean=0.736, min=0.544, max=0.889, std=0.097\n",
      "ID 739: mean=0.888, min=0.774, max=0.972, std=0.053\n",
      "ID 740: mean=0.752, min=0.456, max=0.945, std=0.111\n",
      "ID 741: mean=0.769, min=0.553, max=0.960, std=0.136\n",
      "ID 742: mean=0.834, min=0.725, max=0.951, std=0.062\n",
      "ID 743: mean=0.802, min=0.617, max=0.931, std=0.067\n",
      "ID 744: mean=0.796, min=0.670, max=0.944, std=0.064\n",
      "ID 745: mean=0.729, min=0.593, max=0.883, std=0.058\n",
      "ID 746: mean=0.820, min=0.685, max=0.936, std=0.064\n",
      "ID 747: mean=0.816, min=0.490, max=0.952, std=0.133\n",
      "ID 748: mean=0.805, min=0.489, max=0.920, std=0.101\n",
      "ID 749: mean=0.822, min=0.656, max=0.929, std=0.074\n",
      "ID 750: mean=0.675, min=0.494, max=0.856, std=0.096\n",
      "ID 751: mean=0.754, min=0.586, max=0.922, std=0.079\n",
      "ID 752: mean=0.747, min=0.552, max=0.936, std=0.139\n",
      "ID 753: mean=0.723, min=0.472, max=0.920, std=0.118\n",
      "ID 754: mean=0.763, min=0.605, max=0.860, std=0.072\n",
      "ID 755: mean=0.768, min=0.571, max=0.919, std=0.097\n",
      "ID 756: mean=0.787, min=0.709, max=0.917, std=0.051\n",
      "ID 757: mean=0.749, min=0.505, max=0.944, std=0.114\n",
      "ID 758: mean=0.696, min=0.451, max=0.914, std=0.138\n",
      "ID 759: mean=0.809, min=0.524, max=0.956, std=0.100\n",
      "ID 760: mean=0.695, min=0.407, max=0.947, std=0.141\n",
      "ID 761: mean=0.771, min=0.557, max=0.926, std=0.093\n",
      "ID 762: mean=0.678, min=0.502, max=0.919, std=0.090\n",
      "ID 763: mean=0.756, min=0.594, max=0.843, std=0.070\n",
      "ID 764: mean=0.710, min=0.553, max=0.941, std=0.099\n",
      "ID 765: mean=0.822, min=0.586, max=0.958, std=0.081\n",
      "ID 766: mean=0.704, min=0.489, max=0.929, std=0.109\n",
      "ID 767: mean=0.778, min=0.614, max=0.890, std=0.075\n",
      "ID 768: mean=0.796, min=0.654, max=0.910, std=0.070\n",
      "ID 769: mean=0.756, min=0.593, max=0.866, std=0.070\n",
      "ID 770: mean=0.731, min=0.527, max=0.952, std=0.135\n",
      "ID 771: mean=0.696, min=0.452, max=0.866, std=0.109\n",
      "ID 772: mean=0.769, min=0.590, max=0.908, std=0.082\n",
      "ID 773: mean=0.776, min=0.534, max=0.953, std=0.099\n",
      "ID 774: mean=0.795, min=0.500, max=0.966, std=0.127\n",
      "ID 775: mean=0.833, min=0.701, max=0.939, std=0.068\n",
      "ID 776: mean=0.876, min=0.739, max=0.960, std=0.055\n",
      "ID 777: mean=0.826, min=0.469, max=0.971, std=0.122\n",
      "ID 778: mean=0.732, min=0.481, max=0.943, std=0.104\n",
      "ID 779: mean=0.870, min=0.766, max=0.954, std=0.039\n",
      "ID 780: mean=0.679, min=0.439, max=0.879, std=0.116\n",
      "ID 781: mean=0.817, min=0.583, max=0.946, std=0.091\n",
      "ID 782: mean=0.663, min=0.445, max=0.902, std=0.113\n",
      "ID 783: mean=0.723, min=0.536, max=0.893, std=0.096\n",
      "ID 784: mean=0.834, min=0.701, max=0.934, std=0.058\n",
      "ID 785: mean=0.735, min=0.503, max=0.902, std=0.109\n",
      "ID 786: mean=0.709, min=0.535, max=0.929, std=0.096\n",
      "ID 787: mean=0.738, min=0.575, max=0.876, std=0.081\n",
      "ID 788: mean=0.814, min=0.704, max=0.972, std=0.080\n",
      "ID 789: mean=0.776, min=0.540, max=0.925, std=0.097\n",
      "ID 790: mean=0.790, min=0.566, max=0.945, std=0.096\n",
      "ID 791: mean=0.793, min=0.584, max=0.938, std=0.100\n",
      "ID 792: mean=0.707, min=0.519, max=0.933, std=0.109\n",
      "ID 793: mean=0.745, min=0.600, max=0.901, std=0.082\n",
      "ID 794: mean=0.788, min=0.641, max=0.950, std=0.073\n",
      "ID 795: mean=0.750, min=0.517, max=0.914, std=0.120\n",
      "ID 796: mean=0.711, min=0.490, max=0.866, std=0.105\n",
      "ID 797: mean=0.719, min=0.542, max=0.906, std=0.098\n",
      "ID 798: mean=0.762, min=0.637, max=0.900, std=0.077\n",
      "ID 799: mean=0.749, min=0.527, max=0.923, std=0.101\n",
      "ID 800: mean=0.827, min=0.653, max=0.952, std=0.079\n",
      "ID 801: mean=0.858, min=0.731, max=0.964, std=0.055\n",
      "ID 802: mean=0.836, min=0.597, max=0.977, std=0.130\n",
      "ID 803: mean=0.819, min=0.549, max=0.953, std=0.106\n",
      "ID 804: mean=0.802, min=0.479, max=0.964, std=0.096\n",
      "ID 805: mean=0.870, min=0.697, max=0.968, std=0.066\n",
      "ID 806: mean=0.801, min=0.678, max=0.930, std=0.074\n",
      "ID 807: mean=0.830, min=0.698, max=0.958, std=0.059\n",
      "ID 808: mean=0.786, min=0.507, max=0.956, std=0.116\n",
      "ID 809: mean=0.843, min=0.561, max=0.977, std=0.105\n",
      "ID 810: mean=0.816, min=0.631, max=0.958, std=0.067\n",
      "ID 811: mean=0.720, min=0.445, max=0.924, std=0.141\n",
      "ID 812: mean=0.725, min=0.591, max=0.936, std=0.081\n",
      "ID 813: mean=0.803, min=0.561, max=0.960, std=0.134\n",
      "ID 814: mean=0.774, min=0.640, max=0.922, std=0.068\n",
      "ID 815: mean=0.793, min=0.638, max=0.959, std=0.079\n",
      "ID 816: mean=0.819, min=0.672, max=0.930, std=0.055\n",
      "ID 817: mean=0.811, min=0.698, max=0.946, std=0.066\n",
      "ID 818: mean=0.802, min=0.622, max=0.918, std=0.082\n",
      "ID 819: mean=0.819, min=0.616, max=0.965, std=0.112\n",
      "ID 820: mean=0.728, min=0.483, max=0.911, std=0.108\n",
      "ID 821: mean=0.793, min=0.620, max=0.932, std=0.084\n",
      "ID 822: mean=0.740, min=0.599, max=0.861, std=0.066\n",
      "ID 823: mean=0.765, min=0.641, max=0.940, std=0.085\n",
      "ID 824: mean=0.869, min=0.693, max=0.977, std=0.083\n",
      "ID 825: mean=0.760, min=0.451, max=0.983, std=0.143\n",
      "ID 826: mean=0.780, min=0.548, max=0.960, std=0.102\n",
      "ID 827: mean=0.748, min=0.531, max=0.943, std=0.113\n",
      "ID 828: mean=0.817, min=0.604, max=0.965, std=0.096\n",
      "ID 829: mean=0.776, min=0.518, max=0.901, std=0.101\n",
      "ID 830: mean=0.670, min=0.433, max=0.901, std=0.140\n",
      "ID 831: mean=0.767, min=0.556, max=0.924, std=0.098\n",
      "ID 832: mean=0.816, min=0.567, max=0.971, std=0.097\n",
      "ID 833: mean=0.748, min=0.522, max=0.937, std=0.116\n",
      "ID 834: mean=0.796, min=0.552, max=0.950, std=0.093\n",
      "ID 835: mean=0.828, min=0.526, max=0.988, std=0.102\n",
      "ID 836: mean=0.779, min=0.536, max=0.969, std=0.119\n",
      "ID 837: mean=0.812, min=0.491, max=0.981, std=0.099\n",
      "ID 838: mean=0.763, min=0.550, max=0.969, std=0.116\n",
      "ID 839: mean=0.839, min=0.641, max=0.956, std=0.087\n",
      "ID 840: mean=0.707, min=0.547, max=0.930, std=0.100\n",
      "ID 841: mean=0.784, min=0.612, max=0.939, std=0.080\n",
      "ID 842: mean=0.748, min=0.589, max=0.929, std=0.087\n",
      "ID 843: mean=0.844, min=0.608, max=0.955, std=0.083\n",
      "ID 844: mean=0.799, min=0.522, max=0.968, std=0.097\n",
      "ID 845: mean=0.809, min=0.624, max=0.945, std=0.082\n",
      "ID 846: mean=0.791, min=0.471, max=0.965, std=0.102\n",
      "ID 847: mean=0.677, min=0.496, max=0.879, std=0.100\n",
      "ID 848: mean=0.743, min=0.522, max=0.936, std=0.106\n",
      "ID 849: mean=0.797, min=0.602, max=0.968, std=0.081\n",
      "ID 850: mean=0.723, min=0.553, max=0.842, std=0.085\n",
      "ID 851: mean=0.741, min=0.548, max=0.923, std=0.090\n",
      "ID 852: mean=0.794, min=0.647, max=0.922, std=0.086\n",
      "ID 853: mean=0.819, min=0.702, max=0.955, std=0.071\n",
      "ID 854: mean=0.753, min=0.591, max=0.932, std=0.106\n",
      "ID 855: mean=0.871, min=0.737, max=0.933, std=0.048\n",
      "ID 856: mean=0.778, min=0.512, max=0.956, std=0.138\n",
      "ID 857: mean=0.810, min=0.592, max=0.963, std=0.093\n",
      "ID 858: mean=0.754, min=0.567, max=0.948, std=0.110\n",
      "ID 859: mean=0.814, min=0.627, max=0.929, std=0.075\n",
      "ID 860: mean=0.695, min=0.508, max=0.884, std=0.128\n",
      "ID 861: mean=0.870, min=0.790, max=0.946, std=0.051\n",
      "ID 862: mean=0.766, min=0.657, max=0.887, std=0.071\n",
      "ID 863: mean=0.805, min=0.693, max=0.940, std=0.075\n",
      "ID 864: mean=0.803, min=0.654, max=0.911, std=0.079\n",
      "ID 865: mean=0.714, min=0.521, max=0.866, std=0.095\n",
      "ID 866: mean=0.675, min=0.485, max=0.863, std=0.110\n",
      "ID 867: mean=0.865, min=0.712, max=0.960, std=0.085\n",
      "ID 868: mean=0.840, min=0.719, max=0.906, std=0.050\n",
      "ID 869: mean=0.819, min=0.657, max=0.939, std=0.092\n",
      "ID 870: mean=0.771, min=0.563, max=0.891, std=0.077\n",
      "ID 871: mean=0.736, min=0.551, max=0.946, std=0.098\n",
      "ID 872: mean=0.723, min=0.550, max=0.939, std=0.095\n",
      "ID 873: mean=0.835, min=0.631, max=0.976, std=0.089\n",
      "ID 874: mean=0.854, min=0.716, max=0.952, std=0.050\n",
      "ID 875: mean=0.836, min=0.708, max=0.934, std=0.057\n",
      "ID 876: mean=0.832, min=0.599, max=0.953, std=0.101\n",
      "ID 877: mean=0.766, min=0.594, max=0.967, std=0.116\n",
      "ID 878: mean=0.820, min=0.520, max=0.967, std=0.125\n",
      "ID 879: mean=0.829, min=0.602, max=0.946, std=0.074\n",
      "ID 880: mean=0.780, min=0.547, max=0.948, std=0.095\n",
      "ID 881: mean=0.851, min=0.789, max=0.904, std=0.034\n",
      "ID 882: mean=0.692, min=0.432, max=0.919, std=0.149\n",
      "ID 883: mean=0.605, min=0.505, max=0.844, std=0.074\n",
      "ID 884: mean=0.803, min=0.719, max=0.939, std=0.072\n",
      "ID 885: mean=0.836, min=0.732, max=0.963, std=0.051\n",
      "ID 886: mean=0.855, min=0.726, max=0.941, std=0.062\n",
      "ID 887: mean=0.741, min=0.627, max=0.874, std=0.069\n",
      "ID 888: mean=0.768, min=0.596, max=0.953, std=0.081\n",
      "ID 889: mean=0.703, min=0.458, max=0.840, std=0.104\n",
      "ID 890: mean=0.707, min=0.544, max=0.821, std=0.067\n",
      "ID 891: mean=0.789, min=0.437, max=0.916, std=0.118\n",
      "ID 892: mean=0.801, min=0.586, max=0.947, std=0.104\n",
      "ID 893: mean=0.840, min=0.707, max=0.954, std=0.063\n",
      "ID 894: mean=0.794, min=0.604, max=0.911, std=0.084\n",
      "ID 895: mean=0.766, min=0.615, max=0.903, std=0.079\n",
      "ID 896: mean=0.920, min=0.865, max=0.955, std=0.023\n",
      "ID 897: mean=0.836, min=0.699, max=0.929, std=0.056\n",
      "ID 898: mean=0.896, min=0.790, max=0.973, std=0.055\n",
      "ID 899: mean=0.799, min=0.625, max=0.958, std=0.103\n",
      "ID 900: mean=0.725, min=0.428, max=0.909, std=0.119\n",
      "ID 901: mean=0.742, min=0.492, max=0.921, std=0.109\n",
      "ID 902: mean=0.723, min=0.591, max=0.880, std=0.076\n",
      "ID 903: mean=0.728, min=0.565, max=0.920, std=0.103\n",
      "ID 904: mean=0.818, min=0.630, max=0.949, std=0.093\n",
      "ID 905: mean=0.833, min=0.674, max=0.903, std=0.057\n",
      "ID 906: mean=0.799, min=0.666, max=0.937, std=0.072\n",
      "ID 907: mean=0.760, min=0.533, max=0.945, std=0.095\n",
      "ID 908: mean=0.854, min=0.730, max=0.951, std=0.058\n",
      "ID 909: mean=0.719, min=0.505, max=0.843, std=0.075\n",
      "ID 910: mean=0.791, min=0.622, max=0.911, std=0.084\n",
      "ID 911: mean=0.840, min=0.715, max=0.943, std=0.067\n",
      "ID 912: mean=0.875, min=0.753, max=0.948, std=0.065\n",
      "ID 913: mean=0.849, min=0.719, max=0.957, std=0.080\n",
      "ID 914: mean=0.680, min=0.439, max=0.882, std=0.133\n",
      "ID 915: mean=0.859, min=0.718, max=0.966, std=0.068\n",
      "ID 916: mean=0.904, min=0.833, max=0.963, std=0.043\n",
      "ID 917: mean=0.833, min=0.698, max=0.960, std=0.070\n",
      "ID 918: mean=0.841, min=0.648, max=0.960, std=0.122\n",
      "ID 919: mean=0.847, min=0.694, max=0.934, std=0.062\n",
      "ID 920: mean=0.804, min=0.603, max=0.948, std=0.085\n",
      "ID 921: mean=0.793, min=0.614, max=0.938, std=0.086\n",
      "ID 922: mean=0.766, min=0.467, max=0.959, std=0.133\n",
      "ID 923: mean=0.770, min=0.646, max=0.856, std=0.054\n",
      "ID 924: mean=0.835, min=0.737, max=0.932, std=0.053\n",
      "ID 925: mean=0.786, min=0.549, max=0.921, std=0.089\n",
      "ID 926: mean=0.773, min=0.500, max=0.898, std=0.105\n",
      "ID 927: mean=0.719, min=0.502, max=0.908, std=0.091\n",
      "ID 928: mean=0.712, min=0.338, max=0.907, std=0.150\n",
      "ID 929: mean=0.801, min=0.666, max=0.917, std=0.064\n",
      "ID 930: mean=0.791, min=0.629, max=0.915, std=0.082\n",
      "ID 931: mean=0.726, min=0.528, max=0.893, std=0.090\n",
      "ID 932: mean=0.779, min=0.619, max=0.937, std=0.091\n",
      "ID 933: mean=0.919, min=0.862, max=0.978, std=0.027\n",
      "ID 934: mean=0.860, min=0.722, max=0.942, std=0.056\n",
      "ID 935: mean=0.818, min=0.561, max=0.969, std=0.110\n",
      "ID 936: mean=0.787, min=0.640, max=0.906, std=0.056\n",
      "ID 937: mean=0.764, min=0.546, max=0.960, std=0.115\n",
      "ID 938: mean=0.792, min=0.540, max=0.953, std=0.093\n",
      "ID 939: mean=0.745, min=0.501, max=0.951, std=0.106\n",
      "ID 940: mean=0.832, min=0.717, max=0.962, std=0.073\n",
      "ID 941: mean=0.797, min=0.709, max=0.960, std=0.063\n",
      "ID 942: mean=0.797, min=0.488, max=0.928, std=0.110\n",
      "ID 943: mean=0.853, min=0.631, max=0.969, std=0.082\n",
      "ID 944: mean=0.815, min=0.652, max=0.948, std=0.085\n",
      "ID 945: mean=0.891, min=0.778, max=0.972, std=0.040\n",
      "ID 946: mean=0.774, min=0.515, max=0.941, std=0.111\n",
      "ID 947: mean=0.841, min=0.665, max=0.980, std=0.067\n",
      "ID 948: mean=0.799, min=0.699, max=0.950, std=0.048\n",
      "ID 949: mean=0.758, min=0.613, max=0.915, std=0.089\n",
      "ID 950: mean=0.811, min=0.590, max=0.966, std=0.100\n",
      "ID 951: mean=0.757, min=0.604, max=0.949, std=0.087\n",
      "ID 952: mean=0.791, min=0.683, max=0.945, std=0.073\n",
      "ID 953: mean=0.802, min=0.551, max=0.917, std=0.082\n",
      "ID 954: mean=0.837, min=0.674, max=0.955, std=0.078\n",
      "ID 955: mean=0.873, min=0.770, max=0.971, std=0.055\n",
      "ID 956: mean=0.761, min=0.546, max=0.933, std=0.079\n",
      "ID 957: mean=0.748, min=0.522, max=0.927, std=0.101\n",
      "ID 958: mean=0.825, min=0.750, max=0.967, std=0.055\n",
      "ID 959: mean=0.870, min=0.749, max=0.951, std=0.055\n",
      "ID 960: mean=0.732, min=0.466, max=0.883, std=0.080\n",
      "ID 961: mean=0.868, min=0.682, max=0.967, std=0.066\n",
      "ID 962: mean=0.830, min=0.605, max=0.950, std=0.090\n",
      "ID 963: mean=0.818, min=0.620, max=0.929, std=0.094\n",
      "ID 964: mean=0.877, min=0.752, max=0.952, std=0.055\n",
      "ID 965: mean=0.852, min=0.724, max=0.965, std=0.065\n",
      "ID 966: mean=0.780, min=0.613, max=0.931, std=0.078\n",
      "ID 967: mean=0.917, min=0.816, max=0.992, std=0.034\n",
      "ID 968: mean=0.801, min=0.553, max=0.980, std=0.130\n",
      "ID 969: mean=0.820, min=0.659, max=0.939, std=0.075\n",
      "ID 970: mean=0.657, min=0.457, max=0.864, std=0.114\n",
      "ID 971: mean=0.682, min=0.436, max=0.925, std=0.117\n",
      "ID 972: mean=0.740, min=0.500, max=0.926, std=0.106\n",
      "ID 973: mean=0.781, min=0.554, max=0.919, std=0.082\n",
      "ID 974: mean=0.724, min=0.595, max=0.949, std=0.093\n",
      "ID 975: mean=0.783, min=0.623, max=0.928, std=0.080\n",
      "ID 976: mean=0.817, min=0.644, max=0.932, std=0.071\n",
      "ID 977: mean=0.775, min=0.575, max=0.921, std=0.079\n",
      "ID 978: mean=0.761, min=0.594, max=0.944, std=0.085\n",
      "ID 979: mean=0.764, min=0.565, max=0.954, std=0.097\n",
      "ID 980: mean=0.707, min=0.508, max=0.934, std=0.106\n",
      "ID 981: mean=0.787, min=0.598, max=0.955, std=0.090\n",
      "ID 982: mean=0.831, min=0.744, max=0.959, std=0.050\n",
      "ID 983: mean=0.726, min=0.535, max=0.899, std=0.113\n",
      "ID 984: mean=0.842, min=0.670, max=0.955, std=0.065\n",
      "ID 985: mean=0.822, min=0.664, max=0.951, std=0.085\n",
      "ID 986: mean=0.785, min=0.579, max=0.936, std=0.101\n",
      "ID 987: mean=0.819, min=0.581, max=0.967, std=0.095\n",
      "ID 988: mean=0.801, min=0.672, max=0.971, std=0.087\n",
      "ID 989: mean=0.810, min=0.489, max=0.948, std=0.173\n",
      "ID 990: mean=0.771, min=0.549, max=0.943, std=0.102\n",
      "ID 991: mean=0.783, min=0.618, max=0.959, std=0.072\n",
      "ID 992: mean=0.890, min=0.822, max=0.977, std=0.033\n",
      "ID 993: mean=0.876, min=0.802, max=0.931, std=0.030\n",
      "ID 994: mean=0.749, min=0.577, max=0.909, std=0.080\n",
      "ID 995: mean=0.868, min=0.658, max=0.957, std=0.073\n",
      "ID 996: mean=0.917, min=0.858, max=0.965, std=0.024\n",
      "ID 997: mean=0.761, min=0.616, max=0.881, std=0.065\n",
      "ID 998: mean=0.860, min=0.754, max=0.951, std=0.059\n",
      "ID 999: mean=0.865, min=0.702, max=0.970, std=0.080\n",
      "ID 1000: mean=0.680, min=0.463, max=0.923, std=0.132\n",
      "ID 1001: mean=0.787, min=0.516, max=0.953, std=0.123\n",
      "ID 1002: mean=0.810, min=0.658, max=0.957, std=0.085\n",
      "ID 1003: mean=0.761, min=0.591, max=0.946, std=0.087\n",
      "ID 1004: mean=0.856, min=0.739, max=0.946, std=0.054\n",
      "ID 1005: mean=0.817, min=0.596, max=0.931, std=0.101\n",
      "ID 1006: mean=0.777, min=0.558, max=0.951, std=0.116\n",
      "ID 1007: mean=0.815, min=0.664, max=0.911, std=0.066\n",
      "ID 1008: mean=0.830, min=0.662, max=0.954, std=0.092\n",
      "ID 1009: mean=0.818, min=0.647, max=0.915, std=0.069\n",
      "ID 1010: mean=0.836, min=0.656, max=0.955, std=0.079\n",
      "ID 1011: mean=0.848, min=0.785, max=0.941, std=0.038\n",
      "ID 1012: mean=0.859, min=0.727, max=0.968, std=0.077\n",
      "ID 1013: mean=0.756, min=0.619, max=0.922, std=0.075\n",
      "ID 1014: mean=0.901, min=0.862, max=0.961, std=0.025\n",
      "ID 1015: mean=0.809, min=0.600, max=0.971, std=0.101\n",
      "ID 1016: mean=0.780, min=0.570, max=0.949, std=0.139\n",
      "ID 1017: mean=0.878, min=0.788, max=0.934, std=0.041\n",
      "ID 1018: mean=0.733, min=0.634, max=0.897, std=0.069\n",
      "ID 1019: mean=0.854, min=0.692, max=0.975, std=0.098\n",
      "ID 1020: mean=0.763, min=0.594, max=0.944, std=0.086\n",
      "ID 1021: mean=0.798, min=0.627, max=0.951, std=0.080\n",
      "ID 1022: mean=0.799, min=0.617, max=0.938, std=0.102\n",
      "ID 1023: mean=0.711, min=0.474, max=0.887, std=0.111\n",
      "ID 1024: mean=0.722, min=0.508, max=0.969, std=0.125\n",
      "ID 1025: mean=0.752, min=0.623, max=0.939, std=0.081\n",
      "ID 1026: mean=0.831, min=0.638, max=0.950, std=0.085\n",
      "ID 1027: mean=0.858, min=0.741, max=0.953, std=0.055\n",
      "ID 1028: mean=0.825, min=0.713, max=0.930, std=0.050\n",
      "ID 1029: mean=0.834, min=0.649, max=0.952, std=0.066\n",
      "ID 1030: mean=0.723, min=0.570, max=0.939, std=0.106\n",
      "ID 1031: mean=0.741, min=0.518, max=0.904, std=0.102\n",
      "ID 1032: mean=0.705, min=0.577, max=0.903, std=0.072\n",
      "ID 1033: mean=0.734, min=0.534, max=0.889, std=0.093\n",
      "ID 1034: mean=0.838, min=0.569, max=0.949, std=0.109\n",
      "ID 1035: mean=0.836, min=0.763, max=0.937, std=0.049\n",
      "ID 1036: mean=0.717, min=0.571, max=0.933, std=0.080\n",
      "ID 1037: mean=0.824, min=0.564, max=0.972, std=0.110\n",
      "ID 1038: mean=0.866, min=0.808, max=0.936, std=0.037\n",
      "ID 1039: mean=0.722, min=0.518, max=0.908, std=0.115\n",
      "ID 1040: mean=0.792, min=0.621, max=0.957, std=0.093\n",
      "ID 1041: mean=0.807, min=0.650, max=0.975, std=0.079\n",
      "ID 1042: mean=0.798, min=0.597, max=0.926, std=0.078\n",
      "ID 1043: mean=0.789, min=0.581, max=0.921, std=0.093\n",
      "ID 1044: mean=0.815, min=0.674, max=0.927, std=0.064\n",
      "ID 1045: mean=0.757, min=0.577, max=0.953, std=0.082\n",
      "ID 1046: mean=0.739, min=0.560, max=0.917, std=0.099\n",
      "ID 1047: mean=0.836, min=0.534, max=0.983, std=0.128\n",
      "ID 1048: mean=0.785, min=0.620, max=0.935, std=0.078\n",
      "ID 1049: mean=0.834, min=0.751, max=0.941, std=0.057\n",
      "ID 1050: mean=0.736, min=0.603, max=0.869, std=0.067\n",
      "ID 1051: mean=0.745, min=0.636, max=0.891, std=0.067\n",
      "ID 1052: mean=0.801, min=0.488, max=0.969, std=0.099\n",
      "ID 1053: mean=0.794, min=0.625, max=0.982, std=0.084\n",
      "ID 1054: mean=0.770, min=0.586, max=0.937, std=0.082\n",
      "ID 1055: mean=0.770, min=0.519, max=0.921, std=0.093\n",
      "ID 1056: mean=0.703, min=0.431, max=0.876, std=0.099\n",
      "ID 1057: mean=0.782, min=0.657, max=0.887, std=0.057\n",
      "ID 1058: mean=0.647, min=0.518, max=0.832, std=0.074\n",
      "ID 1059: mean=0.730, min=0.492, max=0.932, std=0.124\n",
      "ID 1060: mean=0.769, min=0.587, max=0.913, std=0.097\n",
      "ID 1061: mean=0.786, min=0.651, max=0.948, std=0.079\n",
      "ID 1062: mean=0.733, min=0.613, max=0.893, std=0.075\n",
      "ID 1063: mean=0.785, min=0.606, max=0.952, std=0.098\n",
      "ID 1064: mean=0.782, min=0.586, max=0.912, std=0.101\n",
      "ID 1065: mean=0.753, min=0.439, max=0.931, std=0.116\n",
      "ID 1066: mean=0.783, min=0.582, max=0.893, std=0.065\n",
      "ID 1067: mean=0.736, min=0.439, max=0.922, std=0.111\n",
      "ID 1068: mean=0.811, min=0.696, max=0.919, std=0.071\n",
      "ID 1069: mean=0.842, min=0.753, max=0.946, std=0.047\n",
      "ID 1070: mean=0.732, min=0.623, max=0.929, std=0.097\n",
      "ID 1071: mean=0.765, min=0.577, max=0.954, std=0.095\n",
      "ID 1072: mean=0.801, min=0.647, max=0.950, std=0.084\n",
      "ID 1073: mean=0.785, min=0.495, max=0.911, std=0.104\n",
      "ID 1074: mean=0.762, min=0.579, max=0.942, std=0.089\n",
      "ID 1075: mean=0.766, min=0.575, max=0.890, std=0.083\n",
      "ID 1076: mean=0.686, min=0.462, max=0.932, std=0.107\n",
      "ID 1077: mean=0.814, min=0.550, max=0.930, std=0.081\n",
      "ID 1078: mean=0.746, min=0.562, max=0.905, std=0.088\n",
      "ID 1079: mean=0.767, min=0.572, max=0.949, std=0.104\n",
      "ID 1080: mean=0.783, min=0.576, max=0.949, std=0.114\n",
      "ID 1081: mean=0.730, min=0.472, max=0.899, std=0.105\n",
      "ID 1082: mean=0.815, min=0.669, max=0.937, std=0.065\n",
      "ID 1083: mean=0.847, min=0.596, max=0.974, std=0.081\n",
      "ID 1084: mean=0.763, min=0.672, max=0.887, std=0.060\n",
      "ID 1085: mean=0.741, min=0.548, max=0.914, std=0.091\n",
      "ID 1086: mean=0.844, min=0.664, max=0.955, std=0.066\n",
      "ID 1087: mean=0.836, min=0.648, max=0.956, std=0.079\n",
      "ID 1088: mean=0.758, min=0.539, max=0.937, std=0.123\n",
      "ID 1089: mean=0.846, min=0.721, max=0.977, std=0.070\n",
      "ID 1090: mean=0.778, min=0.633, max=0.909, std=0.077\n",
      "ID 1091: mean=0.861, min=0.755, max=0.956, std=0.040\n",
      "ID 1092: mean=0.793, min=0.618, max=0.970, std=0.085\n",
      "ID 1093: mean=0.738, min=0.572, max=0.902, std=0.080\n",
      "ID 1094: mean=0.791, min=0.622, max=0.974, std=0.090\n",
      "ID 1095: mean=0.756, min=0.587, max=0.926, std=0.085\n",
      "ID 1096: mean=0.737, min=0.535, max=0.898, std=0.083\n",
      "ID 1097: mean=0.789, min=0.623, max=0.913, std=0.069\n",
      "ID 1098: mean=0.777, min=0.514, max=0.909, std=0.113\n",
      "ID 1099: mean=0.783, min=0.645, max=0.940, std=0.072\n",
      "ID 1100: mean=0.840, min=0.692, max=0.966, std=0.057\n",
      "ID 1101: mean=0.847, min=0.672, max=0.950, std=0.069\n",
      "ID 1102: mean=0.855, min=0.703, max=0.965, std=0.060\n",
      "ID 1103: mean=0.837, min=0.669, max=0.933, std=0.066\n",
      "ID 1104: mean=0.834, min=0.678, max=0.941, std=0.063\n",
      "ID 1105: mean=0.787, min=0.628, max=0.902, std=0.072\n",
      "ID 1106: mean=0.790, min=0.645, max=0.918, std=0.071\n",
      "ID 1107: mean=0.745, min=0.603, max=0.943, std=0.081\n",
      "ID 1108: mean=0.773, min=0.602, max=0.957, std=0.096\n",
      "ID 1109: mean=0.819, min=0.654, max=0.956, std=0.066\n",
      "ID 1110: mean=0.788, min=0.583, max=0.949, std=0.072\n",
      "ID 1111: mean=0.869, min=0.716, max=0.979, std=0.064\n",
      "ID 1112: mean=0.824, min=0.622, max=0.973, std=0.083\n",
      "ID 1113: mean=0.811, min=0.601, max=0.971, std=0.105\n",
      "ID 1114: mean=0.797, min=0.650, max=0.958, std=0.088\n",
      "ID 1115: mean=0.796, min=0.601, max=0.929, std=0.071\n",
      "ID 1116: mean=0.869, min=0.792, max=0.965, std=0.047\n",
      "ID 1117: mean=0.808, min=0.673, max=0.917, std=0.061\n",
      "ID 1118: mean=0.764, min=0.633, max=0.909, std=0.072\n",
      "ID 1119: mean=0.793, min=0.618, max=0.944, std=0.081\n",
      "ID 1120: mean=0.819, min=0.594, max=0.961, std=0.092\n",
      "ID 1121: mean=0.743, min=0.455, max=0.955, std=0.134\n",
      "ID 1122: mean=0.839, min=0.734, max=0.971, std=0.069\n",
      "ID 1123: mean=0.830, min=0.713, max=0.946, std=0.070\n",
      "ID 1124: mean=0.842, min=0.721, max=0.941, std=0.061\n",
      "ID 1125: mean=0.805, min=0.691, max=0.911, std=0.057\n",
      "ID 1126: mean=0.738, min=0.479, max=0.917, std=0.097\n",
      "ID 1127: mean=0.783, min=0.597, max=0.933, std=0.092\n",
      "ID 1128: mean=0.761, min=0.628, max=0.894, std=0.074\n",
      "ID 1129: mean=0.771, min=0.646, max=0.910, std=0.079\n",
      "ID 1130: mean=0.703, min=0.433, max=0.932, std=0.132\n",
      "ID 1131: mean=0.883, min=0.789, max=0.975, std=0.044\n",
      "ID 1132: mean=0.853, min=0.783, max=0.977, std=0.048\n",
      "ID 1133: mean=0.836, min=0.745, max=0.950, std=0.046\n",
      "ID 1134: mean=0.690, min=0.523, max=0.866, std=0.085\n",
      "ID 1135: mean=0.718, min=0.512, max=0.918, std=0.115\n",
      "ID 1136: mean=0.770, min=0.436, max=0.940, std=0.113\n",
      "ID 1137: mean=0.792, min=0.579, max=0.960, std=0.089\n",
      "ID 1138: mean=0.780, min=0.652, max=0.945, std=0.066\n",
      "ID 1139: mean=0.843, min=0.734, max=0.927, std=0.049\n",
      "ID 1140: mean=0.789, min=0.650, max=0.935, std=0.077\n",
      "ID 1141: mean=0.808, min=0.620, max=0.948, std=0.082\n",
      "ID 1142: mean=0.813, min=0.670, max=0.965, std=0.084\n",
      "ID 1143: mean=0.835, min=0.744, max=0.926, std=0.048\n",
      "ID 1144: mean=0.748, min=0.497, max=0.879, std=0.074\n",
      "ID 1145: mean=0.803, min=0.581, max=0.954, std=0.101\n",
      "ID 1146: mean=0.737, min=0.584, max=0.953, std=0.097\n",
      "ID 1147: mean=0.877, min=0.778, max=0.957, std=0.048\n",
      "ID 1148: mean=0.758, min=0.542, max=0.933, std=0.113\n",
      "ID 1149: mean=0.729, min=0.537, max=0.917, std=0.078\n",
      "ID 1150: mean=0.690, min=0.490, max=0.932, std=0.113\n",
      "ID 1151: mean=0.712, min=0.578, max=0.915, std=0.064\n",
      "ID 1152: mean=0.811, min=0.640, max=0.954, std=0.073\n",
      "ID 1153: mean=0.793, min=0.684, max=0.918, std=0.067\n",
      "ID 1154: mean=0.723, min=0.484, max=0.904, std=0.094\n",
      "ID 1155: mean=0.764, min=0.509, max=0.933, std=0.114\n",
      "ID 1156: mean=0.811, min=0.676, max=0.951, std=0.056\n",
      "ID 1157: mean=0.900, min=0.809, max=0.979, std=0.042\n",
      "ID 1158: mean=0.808, min=0.577, max=0.941, std=0.080\n",
      "ID 1159: mean=0.757, min=0.537, max=0.943, std=0.090\n",
      "ID 1160: mean=0.800, min=0.623, max=0.944, std=0.073\n",
      "ID 1161: mean=0.769, min=0.527, max=0.911, std=0.076\n",
      "ID 1162: mean=0.795, min=0.625, max=0.933, std=0.073\n",
      "ID 1163: mean=0.808, min=0.602, max=0.946, std=0.089\n",
      "ID 1164: mean=0.836, min=0.670, max=0.979, std=0.065\n",
      "ID 1165: mean=0.795, min=0.580, max=0.928, std=0.087\n",
      "ID 1166: mean=0.754, min=0.547, max=0.914, std=0.087\n",
      "ID 1167: mean=0.759, min=0.514, max=0.894, std=0.094\n",
      "ID 1168: mean=0.791, min=0.511, max=0.928, std=0.086\n",
      "ID 1169: mean=0.817, min=0.661, max=0.967, std=0.071\n",
      "ID 1170: mean=0.838, min=0.677, max=0.961, std=0.074\n",
      "ID 1171: mean=0.828, min=0.634, max=0.966, std=0.084\n",
      "ID 1172: mean=0.689, min=0.490, max=0.924, std=0.108\n",
      "ID 1173: mean=0.780, min=0.591, max=0.960, std=0.091\n",
      "ID 1174: mean=0.717, min=0.535, max=0.899, std=0.088\n",
      "ID 1175: mean=0.805, min=0.540, max=0.940, std=0.086\n",
      "ID 1176: mean=0.835, min=0.709, max=0.937, std=0.058\n",
      "ID 1177: mean=0.767, min=0.550, max=0.927, std=0.105\n",
      "ID 1178: mean=0.764, min=0.514, max=0.947, std=0.095\n",
      "ID 1179: mean=0.762, min=0.620, max=0.901, std=0.074\n",
      "ID 1180: mean=0.757, min=0.563, max=0.927, std=0.118\n",
      "ID 1181: mean=0.779, min=0.666, max=0.913, std=0.061\n",
      "ID 1182: mean=0.827, min=0.682, max=0.964, std=0.069\n",
      "ID 1183: mean=0.730, min=0.623, max=0.905, std=0.073\n",
      "ID 1184: mean=0.771, min=0.592, max=0.926, std=0.099\n",
      "ID 1185: mean=0.842, min=0.663, max=0.944, std=0.079\n",
      "ID 1186: mean=0.724, min=0.554, max=0.957, std=0.088\n",
      "ID 1187: mean=0.800, min=0.676, max=0.916, std=0.052\n",
      "ID 1188: mean=0.786, min=0.582, max=0.931, std=0.102\n",
      "ID 1189: mean=0.766, min=0.568, max=0.941, std=0.099\n",
      "ID 1190: mean=0.748, min=0.532, max=0.936, std=0.104\n",
      "ID 1191: mean=0.688, min=0.535, max=0.848, std=0.084\n",
      "ID 1192: mean=0.690, min=0.482, max=0.874, std=0.098\n",
      "ID 1193: mean=0.821, min=0.632, max=0.982, std=0.088\n",
      "ID 1194: mean=0.739, min=0.525, max=0.907, std=0.101\n",
      "ID 1195: mean=0.747, min=0.536, max=0.963, std=0.156\n",
      "ID 1196: mean=0.776, min=0.424, max=0.971, std=0.130\n",
      "ID 1197: mean=0.771, min=0.562, max=0.929, std=0.083\n",
      "ID 1198: mean=0.808, min=0.683, max=0.929, std=0.068\n",
      "ID 1199: mean=0.722, min=0.561, max=0.935, std=0.095\n",
      "ID 1200: mean=0.748, min=0.593, max=0.894, std=0.072\n",
      "ID 1201: mean=0.785, min=0.609, max=0.954, std=0.108\n",
      "ID 1202: mean=0.856, min=0.638, max=0.950, std=0.073\n",
      "ID 1203: mean=0.849, min=0.710, max=0.975, std=0.070\n",
      "ID 1204: mean=0.720, min=0.442, max=0.956, std=0.127\n",
      "ID 1205: mean=0.714, min=0.447, max=0.894, std=0.108\n",
      "ID 1206: mean=0.814, min=0.635, max=0.927, std=0.068\n",
      "ID 1207: mean=0.769, min=0.550, max=0.965, std=0.091\n",
      "ID 1208: mean=0.812, min=0.654, max=0.936, std=0.091\n",
      "ID 1209: mean=0.809, min=0.601, max=0.958, std=0.097\n",
      "ID 1210: mean=0.736, min=0.562, max=0.871, std=0.087\n",
      "ID 1211: mean=0.831, min=0.656, max=0.964, std=0.067\n",
      "ID 1212: mean=0.778, min=0.576, max=0.926, std=0.084\n",
      "ID 1213: mean=0.759, min=0.521, max=0.957, std=0.140\n",
      "ID 1214: mean=0.777, min=0.596, max=0.957, std=0.080\n",
      "ID 1215: mean=0.760, min=0.623, max=0.920, std=0.075\n",
      "ID 1216: mean=0.748, min=0.627, max=0.903, std=0.062\n",
      "ID 1217: mean=0.797, min=0.574, max=0.933, std=0.089\n",
      "ID 1218: mean=0.787, min=0.596, max=0.934, std=0.079\n",
      "ID 1219: mean=0.711, min=0.510, max=0.901, std=0.094\n",
      "ID 1220: mean=0.815, min=0.678, max=0.938, std=0.067\n",
      "ID 1221: mean=0.754, min=0.531, max=0.969, std=0.093\n",
      "ID 1222: mean=0.746, min=0.600, max=0.971, std=0.096\n",
      "ID 1223: mean=0.736, min=0.544, max=0.923, std=0.102\n",
      "ID 1224: mean=0.790, min=0.681, max=0.950, std=0.067\n",
      "ID 1225: mean=0.811, min=0.649, max=0.946, std=0.056\n",
      "ID 1226: mean=0.780, min=0.589, max=0.939, std=0.094\n",
      "ID 1227: mean=0.836, min=0.708, max=0.962, std=0.060\n",
      "ID 1228: mean=0.814, min=0.672, max=0.956, std=0.060\n",
      "ID 1229: mean=0.812, min=0.677, max=0.937, std=0.069\n",
      "ID 1230: mean=0.768, min=0.517, max=0.954, std=0.127\n",
      "ID 1231: mean=0.816, min=0.526, max=0.968, std=0.124\n",
      "ID 1232: mean=0.697, min=0.540, max=0.876, std=0.081\n",
      "ID 1233: mean=0.832, min=0.643, max=0.958, std=0.069\n",
      "ID 1234: mean=0.781, min=0.547, max=0.928, std=0.123\n",
      "ID 1235: mean=0.804, min=0.645, max=0.897, std=0.055\n",
      "ID 1236: mean=0.695, min=0.504, max=0.848, std=0.096\n",
      "ID 1237: mean=0.809, min=0.657, max=0.941, std=0.078\n",
      "ID 1238: mean=0.804, min=0.673, max=0.919, std=0.066\n",
      "ID 1239: mean=0.749, min=0.534, max=0.952, std=0.099\n",
      "ID 1240: mean=0.782, min=0.507, max=0.956, std=0.115\n",
      "ID 1241: mean=0.755, min=0.533, max=0.940, std=0.114\n",
      "ID 1242: mean=0.781, min=0.578, max=0.963, std=0.104\n",
      "ID 1243: mean=0.838, min=0.698, max=0.962, std=0.063\n",
      "ID 1244: mean=0.807, min=0.668, max=0.947, std=0.076\n",
      "ID 1245: mean=0.794, min=0.616, max=0.956, std=0.118\n",
      "ID 1246: mean=0.746, min=0.491, max=0.924, std=0.106\n",
      "ID 1247: mean=0.847, min=0.699, max=0.939, std=0.061\n",
      "ID 1248: mean=0.801, min=0.636, max=0.924, std=0.072\n",
      "ID 1249: mean=0.834, min=0.714, max=0.966, std=0.061\n",
      "ID 1250: mean=0.840, min=0.689, max=0.961, std=0.072\n",
      "ID 1251: mean=0.756, min=0.581, max=0.926, std=0.086\n",
      "ID 1252: mean=0.764, min=0.519, max=0.945, std=0.101\n",
      "ID 1253: mean=0.793, min=0.633, max=0.914, std=0.065\n",
      "ID 1254: mean=0.789, min=0.633, max=0.953, std=0.074\n",
      "ID 1255: mean=0.730, min=0.496, max=0.965, std=0.121\n",
      "ID 1256: mean=0.825, min=0.673, max=0.952, std=0.069\n",
      "ID 1257: mean=0.699, min=0.536, max=0.907, std=0.107\n",
      "ID 1258: mean=0.763, min=0.611, max=0.928, std=0.080\n",
      "ID 1259: mean=0.813, min=0.644, max=0.929, std=0.074\n",
      "ID 1260: mean=0.807, min=0.550, max=0.957, std=0.097\n",
      "ID 1261: mean=0.761, min=0.547, max=0.927, std=0.084\n",
      "ID 1262: mean=0.731, min=0.385, max=0.956, std=0.121\n",
      "ID 1263: mean=0.852, min=0.712, max=0.936, std=0.056\n",
      "ID 1264: mean=0.863, min=0.737, max=0.964, std=0.055\n",
      "ID 1265: mean=0.870, min=0.779, max=0.970, std=0.051\n",
      "ID 1266: mean=0.832, min=0.686, max=0.966, std=0.069\n",
      "ID 1267: mean=0.851, min=0.702, max=0.962, std=0.070\n",
      "ID 1268: mean=0.719, min=0.546, max=0.927, std=0.089\n",
      "ID 1269: mean=0.724, min=0.459, max=0.893, std=0.084\n",
      "ID 1270: mean=0.735, min=0.513, max=0.916, std=0.086\n",
      "ID 1271: mean=0.686, min=0.473, max=0.978, std=0.097\n",
      "ID 1272: mean=0.683, min=0.554, max=0.912, std=0.086\n",
      "ID 1273: mean=0.706, min=0.470, max=0.916, std=0.107\n",
      "ID 1274: mean=0.798, min=0.651, max=0.948, std=0.065\n",
      "ID 1275: mean=0.703, min=0.507, max=0.939, std=0.096\n",
      "ID 1276: mean=0.724, min=0.471, max=0.906, std=0.109\n",
      "ID 1277: mean=0.743, min=0.583, max=0.858, std=0.077\n",
      "ID 1278: mean=0.714, min=0.585, max=0.874, std=0.080\n",
      "ID 1279: mean=0.719, min=0.515, max=0.913, std=0.095\n",
      "ID 1280: mean=0.806, min=0.588, max=0.956, std=0.090\n",
      "ID 1281: mean=0.759, min=0.483, max=0.942, std=0.107\n",
      "ID 1282: mean=0.681, min=0.489, max=0.813, std=0.085\n",
      "ID 1283: mean=0.633, min=0.464, max=0.799, std=0.080\n",
      "ID 1284: mean=0.730, min=0.590, max=0.924, std=0.076\n",
      "ID 1285: mean=0.745, min=0.493, max=0.955, std=0.108\n",
      "ID 1286: mean=0.742, min=0.549, max=0.905, std=0.089\n",
      "ID 1287: mean=0.725, min=0.403, max=0.937, std=0.110\n",
      "ID 1288: mean=0.788, min=0.642, max=0.910, std=0.060\n",
      "ID 1289: mean=0.702, min=0.568, max=0.892, std=0.081\n",
      "ID 1290: mean=0.712, min=0.429, max=0.917, std=0.111\n",
      "ID 1291: mean=0.754, min=0.564, max=0.925, std=0.090\n",
      "ID 1292: mean=0.725, min=0.567, max=0.859, std=0.090\n",
      "ID 1293: mean=0.785, min=0.607, max=0.960, std=0.091\n",
      "ID 1294: mean=0.718, min=0.454, max=0.986, std=0.128\n",
      "ID 1295: mean=0.698, min=0.544, max=0.907, std=0.093\n",
      "ID 1296: mean=0.812, min=0.687, max=0.948, std=0.068\n",
      "ID 1297: mean=0.793, min=0.608, max=0.942, std=0.095\n",
      "ID 1298: mean=0.753, min=0.557, max=0.945, std=0.101\n",
      "ID 1299: mean=0.794, min=0.676, max=0.918, std=0.068\n",
      "ID 1300: mean=0.816, min=0.558, max=0.966, std=0.123\n",
      "ID 1301: mean=0.817, min=0.692, max=0.921, std=0.062\n",
      "ID 1302: mean=0.723, min=0.513, max=0.931, std=0.099\n",
      "ID 1303: mean=0.744, min=0.540, max=0.906, std=0.099\n",
      "ID 1304: mean=0.788, min=0.614, max=0.943, std=0.077\n",
      "ID 1305: mean=0.696, min=0.521, max=0.885, std=0.096\n",
      "ID 1306: mean=0.827, min=0.561, max=0.970, std=0.095\n",
      "ID 1307: mean=0.774, min=0.583, max=0.936, std=0.098\n",
      "ID 1308: mean=0.816, min=0.610, max=0.972, std=0.080\n",
      "ID 1309: mean=0.849, min=0.736, max=0.953, std=0.053\n",
      "ID 1310: mean=0.747, min=0.459, max=0.980, std=0.106\n",
      "ID 1311: mean=0.883, min=0.784, max=0.980, std=0.051\n",
      "ID 1312: mean=0.774, min=0.533, max=0.972, std=0.117\n",
      "ID 1313: mean=0.780, min=0.487, max=0.955, std=0.099\n",
      "ID 1314: mean=0.870, min=0.597, max=0.988, std=0.081\n",
      "ID 1315: mean=0.781, min=0.550, max=0.964, std=0.098\n",
      "ID 1316: mean=0.800, min=0.570, max=0.967, std=0.108\n",
      "ID 1317: mean=0.736, min=0.516, max=0.950, std=0.101\n",
      "ID 1318: mean=0.772, min=0.436, max=0.973, std=0.154\n",
      "ID 1319: mean=0.831, min=0.633, max=0.957, std=0.073\n",
      "ID 1320: mean=0.825, min=0.614, max=0.974, std=0.077\n",
      "ID 1321: mean=0.813, min=0.593, max=0.969, std=0.092\n",
      "ID 1322: mean=0.866, min=0.763, max=0.966, std=0.055\n",
      "ID 1323: mean=0.837, min=0.699, max=0.961, std=0.060\n",
      "ID 1324: mean=0.767, min=0.575, max=0.963, std=0.093\n",
      "ID 1325: mean=0.822, min=0.566, max=0.961, std=0.117\n",
      "ID 1326: mean=0.820, min=0.621, max=0.950, std=0.078\n",
      "ID 1327: mean=0.819, min=0.694, max=0.962, std=0.064\n",
      "ID 1328: mean=0.791, min=0.519, max=0.960, std=0.133\n",
      "ID 1329: mean=0.784, min=0.513, max=0.968, std=0.140\n",
      "ID 1330: mean=0.722, min=0.535, max=0.830, std=0.071\n",
      "ID 1331: mean=0.744, min=0.565, max=0.896, std=0.094\n",
      "ID 1332: mean=0.818, min=0.594, max=0.938, std=0.098\n",
      "ID 1333: mean=0.720, min=0.634, max=0.881, std=0.069\n",
      "ID 1334: mean=0.775, min=0.629, max=0.919, std=0.067\n",
      "ID 1335: mean=0.782, min=0.617, max=0.942, std=0.089\n",
      "ID 1336: mean=0.825, min=0.605, max=0.942, std=0.092\n",
      "ID 1337: mean=0.750, min=0.629, max=0.892, std=0.064\n",
      "ID 1338: mean=0.828, min=0.666, max=0.939, std=0.068\n",
      "ID 1339: mean=0.745, min=0.630, max=0.850, std=0.060\n",
      "ID 1340: mean=0.753, min=0.615, max=0.909, std=0.079\n",
      "ID 1341: mean=0.847, min=0.728, max=0.927, std=0.056\n",
      "ID 1342: mean=0.809, min=0.694, max=0.895, std=0.055\n",
      "ID 1343: mean=0.799, min=0.577, max=0.959, std=0.086\n",
      "ID 1344: mean=0.779, min=0.657, max=0.950, std=0.086\n",
      "ID 1345: mean=0.738, min=0.546, max=0.897, std=0.100\n",
      "ID 1346: mean=0.754, min=0.593, max=0.902, std=0.087\n",
      "ID 1347: mean=0.853, min=0.787, max=0.939, std=0.043\n",
      "ID 1348: mean=0.847, min=0.689, max=0.957, std=0.073\n",
      "ID 1349: mean=0.768, min=0.595, max=0.921, std=0.085\n",
      "ID 1350: mean=0.776, min=0.635, max=0.882, std=0.066\n",
      "ID 1351: mean=0.648, min=0.381, max=0.886, std=0.107\n",
      "ID 1352: mean=0.760, min=0.386, max=0.906, std=0.128\n",
      "ID 1353: mean=0.764, min=0.576, max=0.954, std=0.080\n",
      "ID 1354: mean=0.775, min=0.618, max=0.924, std=0.067\n",
      "ID 1355: mean=0.730, min=0.559, max=0.907, std=0.085\n",
      "ID 1356: mean=0.786, min=0.575, max=0.940, std=0.099\n",
      "ID 1357: mean=0.841, min=0.746, max=0.954, std=0.049\n",
      "ID 1358: mean=0.690, min=0.486, max=0.893, std=0.101\n",
      "ID 1359: mean=0.755, min=0.583, max=0.944, std=0.093\n",
      "ID 1360: mean=0.742, min=0.462, max=0.934, std=0.100\n",
      "ID 1361: mean=0.761, min=0.484, max=0.924, std=0.099\n",
      "ID 1362: mean=0.764, min=0.629, max=0.951, std=0.076\n",
      "ID 1363: mean=0.776, min=0.449, max=0.987, std=0.103\n",
      "ID 1364: mean=0.843, min=0.754, max=0.949, std=0.047\n",
      "ID 1365: mean=0.775, min=0.559, max=0.927, std=0.105\n",
      "ID 1366: mean=0.740, min=0.510, max=0.951, std=0.104\n",
      "ID 1367: mean=0.758, min=0.651, max=0.927, std=0.071\n",
      "ID 1368: mean=0.743, min=0.502, max=0.947, std=0.113\n",
      "ID 1369: mean=0.706, min=0.477, max=0.911, std=0.113\n",
      "ID 1370: mean=0.817, min=0.520, max=0.950, std=0.115\n",
      "ID 1371: mean=0.697, min=0.542, max=0.838, std=0.079\n",
      "ID 1372: mean=0.796, min=0.646, max=0.892, std=0.056\n",
      "ID 1373: mean=0.773, min=0.595, max=0.900, std=0.073\n",
      "ID 1374: mean=0.760, min=0.604, max=0.898, std=0.073\n",
      "ID 1375: mean=0.707, min=0.542, max=0.919, std=0.081\n",
      "ID 1376: mean=0.765, min=0.628, max=0.944, std=0.074\n",
      "ID 1377: mean=0.768, min=0.558, max=0.981, std=0.108\n",
      "ID 1378: mean=0.705, min=0.576, max=0.865, std=0.074\n",
      "ID 1379: mean=0.792, min=0.603, max=0.952, std=0.081\n",
      "ID 1380: mean=0.799, min=0.678, max=0.916, std=0.055\n",
      "ID 1381: mean=0.764, min=0.608, max=0.967, std=0.080\n",
      "ID 1382: mean=0.720, min=0.579, max=0.861, std=0.076\n",
      "ID 1383: mean=0.744, min=0.572, max=0.914, std=0.088\n",
      "ID 1384: mean=0.768, min=0.593, max=0.956, std=0.095\n",
      "ID 1385: mean=0.709, min=0.572, max=0.890, std=0.066\n",
      "ID 1386: mean=0.839, min=0.712, max=0.953, std=0.056\n",
      "ID 1387: mean=0.810, min=0.597, max=0.970, std=0.097\n",
      "ID 1388: mean=0.780, min=0.592, max=0.912, std=0.079\n",
      "ID 1389: mean=0.655, min=0.491, max=0.874, std=0.085\n",
      "ID 1390: mean=0.798, min=0.679, max=0.950, std=0.060\n",
      "ID 1391: mean=0.763, min=0.520, max=0.914, std=0.088\n",
      "ID 1392: mean=0.762, min=0.567, max=0.934, std=0.115\n",
      "ID 1393: mean=0.795, min=0.692, max=0.930, std=0.054\n",
      "ID 1394: mean=0.821, min=0.654, max=0.924, std=0.064\n",
      "ID 1395: mean=0.798, min=0.621, max=0.947, std=0.076\n",
      "ID 1396: mean=0.849, min=0.654, max=0.935, std=0.076\n",
      "ID 1397: mean=0.776, min=0.568, max=0.915, std=0.083\n",
      "ID 1398: mean=0.787, min=0.658, max=0.915, std=0.065\n",
      "ID 1399: mean=0.773, min=0.636, max=0.928, std=0.077\n",
      "ID 1400: mean=0.760, min=0.631, max=0.912, std=0.078\n",
      "ID 1401: mean=0.729, min=0.477, max=0.935, std=0.119\n",
      "ID 1402: mean=0.776, min=0.595, max=0.948, std=0.085\n",
      "ID 1403: mean=0.805, min=0.600, max=0.955, std=0.076\n",
      "ID 1404: mean=0.754, min=0.564, max=0.890, std=0.080\n",
      "ID 1405: mean=0.775, min=0.549, max=0.969, std=0.101\n",
      "ID 1406: mean=0.811, min=0.708, max=0.967, std=0.069\n",
      "ID 1407: mean=0.785, min=0.663, max=0.903, std=0.063\n",
      "ID 1408: mean=0.867, min=0.780, max=0.946, std=0.047\n",
      "ID 1409: mean=0.809, min=0.562, max=0.972, std=0.104\n",
      "ID 1410: mean=0.803, min=0.582, max=0.964, std=0.098\n",
      "ID 1411: mean=0.822, min=0.604, max=0.948, std=0.117\n",
      "ID 1412: mean=0.767, min=0.551, max=0.942, std=0.101\n",
      "ID 1413: mean=0.804, min=0.561, max=0.951, std=0.092\n",
      "ID 1414: mean=0.800, min=0.603, max=0.951, std=0.104\n",
      "ID 1415: mean=0.799, min=0.510, max=0.931, std=0.096\n",
      "ID 1416: mean=0.875, min=0.739, max=0.954, std=0.048\n",
      "ID 1417: mean=0.774, min=0.560, max=0.925, std=0.073\n",
      "ID 1418: mean=0.837, min=0.736, max=0.917, std=0.046\n",
      "ID 1419: mean=0.713, min=0.566, max=0.880, std=0.067\n",
      "ID 1420: mean=0.877, min=0.788, max=0.960, std=0.043\n",
      "ID 1421: mean=0.833, min=0.591, max=0.941, std=0.089\n",
      "ID 1422: mean=0.832, min=0.552, max=0.950, std=0.104\n",
      "ID 1423: mean=0.744, min=0.541, max=0.986, std=0.108\n",
      "ID 1424: mean=0.778, min=0.596, max=0.951, std=0.081\n",
      "ID 1425: mean=0.790, min=0.507, max=0.951, std=0.112\n",
      "ID 1426: mean=0.852, min=0.738, max=0.959, std=0.064\n",
      "ID 1427: mean=0.770, min=0.578, max=0.917, std=0.089\n",
      "ID 1428: mean=0.796, min=0.632, max=0.964, std=0.065\n",
      "ID 1429: mean=0.790, min=0.609, max=0.957, std=0.084\n",
      "ID 1430: mean=0.825, min=0.637, max=0.948, std=0.079\n",
      "ID 1431: mean=0.809, min=0.449, max=0.967, std=0.112\n",
      "ID 1432: mean=0.804, min=0.558, max=0.970, std=0.106\n",
      "ID 1433: mean=0.800, min=0.662, max=0.967, std=0.088\n",
      "ID 1434: mean=0.729, min=0.513, max=0.908, std=0.089\n",
      "ID 1435: mean=0.865, min=0.636, max=0.963, std=0.095\n",
      "ID 1436: mean=0.769, min=0.602, max=0.965, std=0.102\n",
      "ID 1437: mean=0.794, min=0.608, max=0.951, std=0.074\n",
      "ID 1438: mean=0.834, min=0.625, max=0.952, std=0.069\n",
      "ID 1439: mean=0.850, min=0.728, max=0.954, std=0.065\n",
      "ID 1440: mean=0.837, min=0.708, max=0.921, std=0.052\n",
      "ID 1441: mean=0.813, min=0.671, max=0.939, std=0.070\n",
      "ID 1442: mean=0.737, min=0.532, max=0.950, std=0.123\n",
      "ID 1443: mean=0.731, min=0.528, max=0.963, std=0.109\n",
      "ID 1444: mean=0.754, min=0.512, max=0.957, std=0.106\n",
      "ID 1445: mean=0.817, min=0.608, max=0.957, std=0.101\n",
      "ID 1446: mean=0.751, min=0.497, max=0.935, std=0.112\n",
      "ID 1447: mean=0.729, min=0.483, max=0.919, std=0.119\n",
      "ID 1448: mean=0.757, min=0.453, max=0.914, std=0.115\n",
      "ID 1449: mean=0.833, min=0.682, max=0.930, std=0.058\n",
      "ID 1450: mean=0.883, min=0.745, max=0.981, std=0.068\n",
      "ID 1451: mean=0.835, min=0.573, max=0.959, std=0.106\n",
      "ID 1452: mean=0.826, min=0.645, max=0.964, std=0.071\n",
      "ID 1453: mean=0.791, min=0.667, max=0.898, std=0.049\n",
      "ID 1454: mean=0.696, min=0.515, max=0.843, std=0.081\n",
      "ID 1455: mean=0.800, min=0.589, max=0.918, std=0.067\n",
      "ID 1456: mean=0.767, min=0.585, max=0.939, std=0.093\n",
      "ID 1457: mean=0.782, min=0.587, max=0.946, std=0.076\n",
      "ID 1458: mean=0.783, min=0.579, max=0.951, std=0.081\n",
      "ID 1459: mean=0.751, min=0.594, max=0.903, std=0.078\n",
      "ID 1460: mean=0.723, min=0.512, max=0.904, std=0.090\n",
      "ID 1461: mean=0.730, min=0.516, max=0.929, std=0.105\n",
      "ID 1462: mean=0.733, min=0.539, max=0.940, std=0.079\n",
      "ID 1463: mean=0.734, min=0.492, max=0.974, std=0.106\n",
      "ID 1464: mean=0.758, min=0.632, max=0.925, std=0.073\n",
      "ID 1465: mean=0.865, min=0.743, max=0.955, std=0.054\n",
      "ID 1466: mean=0.818, min=0.546, max=0.981, std=0.116\n",
      "ID 1467: mean=0.774, min=0.651, max=0.941, std=0.068\n",
      "ID 1468: mean=0.784, min=0.617, max=0.956, std=0.095\n",
      "ID 1469: mean=0.859, min=0.726, max=0.953, std=0.059\n",
      "ID 1470: mean=0.803, min=0.645, max=0.930, std=0.060\n",
      "ID 1471: mean=0.817, min=0.683, max=0.934, std=0.061\n",
      "ID 1472: mean=0.892, min=0.752, max=0.973, std=0.062\n",
      "ID 1473: mean=0.764, min=0.610, max=0.874, std=0.066\n",
      "ID 1474: mean=0.832, min=0.685, max=0.923, std=0.060\n",
      "ID 1475: mean=0.865, min=0.769, max=0.938, std=0.048\n",
      "ID 1476: mean=0.814, min=0.586, max=0.916, std=0.073\n",
      "ID 1477: mean=0.855, min=0.700, max=0.949, std=0.057\n",
      "ID 1478: mean=0.859, min=0.722, max=0.960, std=0.056\n",
      "ID 1479: mean=0.791, min=0.637, max=0.945, std=0.079\n",
      "ID 1480: mean=0.913, min=0.842, max=0.972, std=0.031\n",
      "ID 1481: mean=0.917, min=0.847, max=0.969, std=0.029\n",
      "ID 1482: mean=0.764, min=0.621, max=0.906, std=0.071\n",
      "ID 1483: mean=0.818, min=0.550, max=0.949, std=0.084\n",
      "ID 1484: mean=0.863, min=0.707, max=0.962, std=0.071\n",
      "ID 1485: mean=0.812, min=0.578, max=0.952, std=0.131\n",
      "ID 1486: mean=0.921, min=0.866, max=0.972, std=0.028\n",
      "ID 1487: mean=0.773, min=0.617, max=0.939, std=0.092\n",
      "ID 1488: mean=0.782, min=0.553, max=0.967, std=0.124\n",
      "ID 1489: mean=0.833, min=0.710, max=0.960, std=0.065\n",
      "ID 1490: mean=0.852, min=0.724, max=0.958, std=0.064\n",
      "ID 1491: mean=0.855, min=0.799, max=0.944, std=0.039\n",
      "ID 1492: mean=0.782, min=0.673, max=0.878, std=0.062\n",
      "ID 1493: mean=0.724, min=0.528, max=0.894, std=0.097\n",
      "ID 1494: mean=0.734, min=0.605, max=0.869, std=0.078\n",
      "ID 1495: mean=0.776, min=0.578, max=0.921, std=0.092\n",
      "ID 1496: mean=0.817, min=0.688, max=0.906, std=0.060\n",
      "ID 1497: mean=0.834, min=0.725, max=0.946, std=0.063\n",
      "ID 1498: mean=0.795, min=0.549, max=0.962, std=0.107\n",
      "ID 1499: mean=0.699, min=0.526, max=0.872, std=0.090\n",
      "ID 1500: mean=0.856, min=0.757, max=0.929, std=0.047\n",
      "ID 1501: mean=0.813, min=0.683, max=0.909, std=0.054\n",
      "ID 1502: mean=0.784, min=0.619, max=0.904, std=0.067\n",
      "ID 1503: mean=0.756, min=0.578, max=0.899, std=0.077\n",
      "ID 1504: mean=0.740, min=0.500, max=0.950, std=0.113\n",
      "ID 1505: mean=0.836, min=0.731, max=0.915, std=0.049\n",
      "ID 1506: mean=0.781, min=0.632, max=0.933, std=0.083\n",
      "ID 1507: mean=0.748, min=0.611, max=0.909, std=0.078\n",
      "ID 1508: mean=0.792, min=0.489, max=0.965, std=0.114\n",
      "ID 1509: mean=0.776, min=0.532, max=0.922, std=0.108\n",
      "ID 1510: mean=0.804, min=0.663, max=0.916, std=0.058\n",
      "ID 1511: mean=0.759, min=0.596, max=0.967, std=0.072\n",
      "ID 1512: mean=0.893, min=0.823, max=0.970, std=0.036\n",
      "ID 1513: mean=0.844, min=0.642, max=0.954, std=0.088\n",
      "ID 1514: mean=0.860, min=0.805, max=0.938, std=0.034\n",
      "ID 1515: mean=0.794, min=0.582, max=0.918, std=0.082\n",
      "ID 1516: mean=0.793, min=0.615, max=0.950, std=0.083\n",
      "ID 1517: mean=0.754, min=0.595, max=0.902, std=0.076\n",
      "ID 1518: mean=0.740, min=0.575, max=0.883, std=0.065\n",
      "ID 1519: mean=0.856, min=0.734, max=0.963, std=0.058\n",
      "ID 1520: mean=0.810, min=0.722, max=0.906, std=0.042\n",
      "ID 1521: mean=0.750, min=0.598, max=0.917, std=0.072\n",
      "ID 1522: mean=0.835, min=0.663, max=0.969, std=0.075\n",
      "ID 1523: mean=0.791, min=0.659, max=0.891, std=0.071\n",
      "ID 1524: mean=0.736, min=0.496, max=0.932, std=0.093\n",
      "ID 1525: mean=0.803, min=0.543, max=0.937, std=0.116\n",
      "ID 1526: mean=0.831, min=0.747, max=0.946, std=0.046\n",
      "ID 1527: mean=0.745, min=0.598, max=0.907, std=0.064\n",
      "ID 1528: mean=0.750, min=0.627, max=0.879, std=0.061\n",
      "ID 1529: mean=0.806, min=0.575, max=0.962, std=0.104\n",
      "ID 1530: mean=0.694, min=0.574, max=0.891, std=0.096\n",
      "ID 1531: mean=0.756, min=0.505, max=0.903, std=0.114\n",
      "ID 1532: mean=0.706, min=0.528, max=0.919, std=0.081\n",
      "ID 1533: mean=0.682, min=0.540, max=0.866, std=0.091\n",
      "ID 1534: mean=0.840, min=0.668, max=0.926, std=0.070\n",
      "ID 1535: mean=0.839, min=0.744, max=0.916, std=0.051\n",
      "ID 1536: mean=0.688, min=0.588, max=0.790, std=0.083\n",
      "ID 1537: mean=0.799, min=0.672, max=0.915, std=0.076\n",
      "ID 1538: mean=0.855, min=0.740, max=0.952, std=0.064\n",
      "ID 1539: mean=0.743, min=0.442, max=0.903, std=0.107\n",
      "ID 1540: mean=0.787, min=0.592, max=0.910, std=0.089\n",
      "ID 1541: mean=0.734, min=0.629, max=0.912, std=0.071\n",
      "ID 1542: mean=0.849, min=0.719, max=0.965, std=0.069\n",
      "ID 1543: mean=0.813, min=0.705, max=0.932, std=0.061\n",
      "ID 1544: mean=0.700, min=0.478, max=0.870, std=0.089\n",
      "ID 1545: mean=0.754, min=0.583, max=0.913, std=0.090\n",
      "ID 1546: mean=0.830, min=0.734, max=0.935, std=0.053\n",
      "ID 1547: mean=0.734, min=0.642, max=0.839, std=0.064\n",
      "ID 1548: mean=0.635, min=0.453, max=0.809, std=0.088\n",
      "ID 1549: mean=0.769, min=0.676, max=0.912, std=0.061\n",
      "ID 1550: mean=0.765, min=0.587, max=0.925, std=0.085\n",
      "ID 1551: mean=0.763, min=0.584, max=0.906, std=0.084\n",
      "ID 1552: mean=0.875, min=0.808, max=0.968, std=0.041\n",
      "ID 1553: mean=0.809, min=0.653, max=0.930, std=0.074\n",
      "ID 1554: mean=0.734, min=0.464, max=0.933, std=0.108\n",
      "ID 1555: mean=0.777, min=0.609, max=0.927, std=0.072\n",
      "ID 1556: mean=0.703, min=0.571, max=0.907, std=0.090\n",
      "ID 1557: mean=0.842, min=0.718, max=0.960, std=0.054\n",
      "ID 1558: mean=0.847, min=0.764, max=0.928, std=0.046\n",
      "ID 1559: mean=0.857, min=0.773, max=0.943, std=0.044\n",
      "ID 1560: mean=0.805, min=0.650, max=0.942, std=0.065\n",
      "ID 1561: mean=0.738, min=0.377, max=0.901, std=0.134\n",
      "ID 1562: mean=0.825, min=0.697, max=0.928, std=0.067\n",
      "ID 1563: mean=0.773, min=0.468, max=0.960, std=0.125\n",
      "ID 1564: mean=0.781, min=0.658, max=0.938, std=0.067\n",
      "ID 1565: mean=0.809, min=0.698, max=0.892, std=0.054\n",
      "ID 1566: mean=0.756, min=0.609, max=0.888, std=0.078\n",
      "ID 1567: mean=0.786, min=0.550, max=0.941, std=0.095\n",
      "ID 1568: mean=0.759, min=0.557, max=0.939, std=0.120\n",
      "ID 1569: mean=0.761, min=0.628, max=0.864, std=0.068\n",
      "ID 1570: mean=0.795, min=0.567, max=0.924, std=0.077\n",
      "ID 1571: mean=0.839, min=0.646, max=0.954, std=0.068\n",
      "ID 1572: mean=0.822, min=0.605, max=0.932, std=0.074\n",
      "ID 1573: mean=0.742, min=0.579, max=0.906, std=0.089\n",
      "ID 1574: mean=0.789, min=0.647, max=0.907, std=0.062\n",
      "ID 1575: mean=0.879, min=0.804, max=0.948, std=0.043\n",
      "ID 1576: mean=0.850, min=0.660, max=0.933, std=0.069\n",
      "ID 1577: mean=0.828, min=0.683, max=0.943, std=0.081\n",
      "ID 1578: mean=0.841, min=0.666, max=0.950, std=0.086\n",
      "ID 1579: mean=0.814, min=0.710, max=0.920, std=0.051\n",
      "ID 1580: mean=0.805, min=0.609, max=0.956, std=0.080\n",
      "ID 1581: mean=0.777, min=0.638, max=0.951, std=0.086\n",
      "ID 1582: mean=0.863, min=0.762, max=0.945, std=0.043\n",
      "ID 1583: mean=0.828, min=0.690, max=0.971, std=0.060\n",
      "ID 1584: mean=0.831, min=0.699, max=0.964, std=0.069\n",
      "ID 1585: mean=0.757, min=0.540, max=0.943, std=0.114\n",
      "ID 1586: mean=0.872, min=0.735, max=0.940, std=0.049\n",
      "ID 1587: mean=0.784, min=0.516, max=0.924, std=0.104\n",
      "ID 1588: mean=0.851, min=0.658, max=0.942, std=0.088\n",
      "ID 1589: mean=0.816, min=0.595, max=0.925, std=0.079\n",
      "ID 1590: mean=0.806, min=0.681, max=0.956, std=0.071\n",
      "ID 1591: mean=0.771, min=0.591, max=0.967, std=0.080\n",
      "ID 1592: mean=0.860, min=0.635, max=0.969, std=0.072\n",
      "ID 1593: mean=0.743, min=0.603, max=0.907, std=0.087\n",
      "ID 1594: mean=0.824, min=0.630, max=0.964, std=0.082\n",
      "ID 1595: mean=0.826, min=0.643, max=0.936, std=0.069\n",
      "ID 1596: mean=0.817, min=0.583, max=0.952, std=0.096\n",
      "ID 1597: mean=0.810, min=0.718, max=0.953, std=0.060\n",
      "ID 1598: mean=0.831, min=0.731, max=0.924, std=0.049\n",
      "ID 1599: mean=0.803, min=0.650, max=0.914, std=0.070\n",
      "ID 1600: mean=0.874, min=0.781, max=0.961, std=0.042\n",
      "ID 1601: mean=0.768, min=0.649, max=0.921, std=0.058\n",
      "ID 1602: mean=0.812, min=0.690, max=0.924, std=0.061\n",
      "ID 1603: mean=0.828, min=0.540, max=0.948, std=0.074\n",
      "ID 1604: mean=0.834, min=0.707, max=0.932, std=0.058\n",
      "ID 1605: mean=0.797, min=0.606, max=0.911, std=0.063\n",
      "ID 1606: mean=0.815, min=0.708, max=0.907, std=0.044\n",
      "ID 1607: mean=0.763, min=0.548, max=0.931, std=0.066\n",
      "ID 1608: mean=0.766, min=0.643, max=0.890, std=0.063\n",
      "ID 1609: mean=0.795, min=0.669, max=0.954, std=0.079\n",
      "ID 1610: mean=0.791, min=0.570, max=0.932, std=0.107\n",
      "ID 1611: mean=0.917, min=0.860, max=0.959, std=0.023\n",
      "ID 1612: mean=0.756, min=0.591, max=0.922, std=0.117\n",
      "ID 1613: mean=0.891, min=0.768, max=0.966, std=0.048\n",
      "ID 1614: mean=0.746, min=0.444, max=0.936, std=0.115\n",
      "ID 1615: mean=0.744, min=0.457, max=0.933, std=0.123\n",
      "ID 1616: mean=0.766, min=0.637, max=0.906, std=0.076\n",
      "ID 1617: mean=0.794, min=0.670, max=0.915, std=0.068\n",
      "ID 1618: mean=0.776, min=0.625, max=0.968, std=0.090\n",
      "ID 1619: mean=0.756, min=0.461, max=0.961, std=0.163\n",
      "ID 1620: mean=0.857, min=0.751, max=0.948, std=0.046\n",
      "ID 1621: mean=0.886, min=0.789, max=0.961, std=0.055\n",
      "ID 1622: mean=0.931, min=0.887, max=0.972, std=0.022\n",
      "ID 1623: mean=0.825, min=0.625, max=0.948, std=0.080\n",
      "ID 1624: mean=0.842, min=0.738, max=0.953, std=0.062\n",
      "ID 1625: mean=0.931, min=0.890, max=0.972, std=0.021\n",
      "ID 1626: mean=0.742, min=0.556, max=0.952, std=0.102\n",
      "ID 1627: mean=0.904, min=0.846, max=0.962, std=0.030\n",
      "ID 1628: mean=0.757, min=0.565, max=0.913, std=0.079\n",
      "ID 1629: mean=0.763, min=0.576, max=0.954, std=0.096\n",
      "ID 1630: mean=0.842, min=0.731, max=0.935, std=0.052\n",
      "ID 1631: mean=0.808, min=0.674, max=0.918, std=0.059\n",
      "ID 1632: mean=0.860, min=0.748, max=0.950, std=0.050\n",
      "ID 1633: mean=0.762, min=0.612, max=0.912, std=0.080\n",
      "ID 1634: mean=0.781, min=0.636, max=0.940, std=0.089\n",
      "ID 1635: mean=0.874, min=0.757, max=0.933, std=0.041\n",
      "ID 1636: mean=0.784, min=0.662, max=0.901, std=0.065\n",
      "ID 1637: mean=0.845, min=0.711, max=0.935, std=0.060\n",
      "ID 1638: mean=0.814, min=0.679, max=0.935, std=0.070\n",
      "ID 1639: mean=0.737, min=0.606, max=0.906, std=0.069\n",
      "ID 1640: mean=0.819, min=0.684, max=0.944, std=0.057\n",
      "ID 1641: mean=0.868, min=0.693, max=0.955, std=0.051\n",
      "ID 1642: mean=0.854, min=0.719, max=0.947, std=0.050\n",
      "ID 1643: mean=0.679, min=0.543, max=0.827, std=0.068\n",
      "ID 1644: mean=0.772, min=0.638, max=0.887, std=0.059\n",
      "ID 1645: mean=0.830, min=0.742, max=0.933, std=0.049\n",
      "ID 1646: mean=0.817, min=0.674, max=0.950, std=0.066\n",
      "ID 1647: mean=0.762, min=0.549, max=0.916, std=0.098\n",
      "ID 1648: mean=0.757, min=0.535, max=0.904, std=0.080\n",
      "ID 1649: mean=0.737, min=0.577, max=0.947, std=0.083\n",
      "ID 1650: mean=0.755, min=0.526, max=0.904, std=0.091\n",
      "ID 1651: mean=0.715, min=0.465, max=0.941, std=0.114\n",
      "ID 1652: mean=0.777, min=0.582, max=0.944, std=0.081\n",
      "ID 1653: mean=0.737, min=0.460, max=0.883, std=0.098\n",
      "ID 1654: mean=0.745, min=0.529, max=0.929, std=0.104\n",
      "ID 1655: mean=0.714, min=0.556, max=0.900, std=0.079\n",
      "ID 1656: mean=0.781, min=0.592, max=0.937, std=0.080\n",
      "ID 1657: mean=0.717, min=0.509, max=0.930, std=0.096\n",
      "ID 1658: mean=0.779, min=0.508, max=0.941, std=0.095\n",
      "ID 1659: mean=0.841, min=0.689, max=0.952, std=0.073\n",
      "ID 1660: mean=0.830, min=0.666, max=0.921, std=0.060\n",
      "ID 1661: mean=0.751, min=0.497, max=0.954, std=0.102\n",
      "ID 1662: mean=0.780, min=0.602, max=0.947, std=0.063\n",
      "ID 1663: mean=0.790, min=0.554, max=0.916, std=0.084\n",
      "ID 1664: mean=0.817, min=0.558, max=0.959, std=0.084\n",
      "ID 1665: mean=0.762, min=0.601, max=0.924, std=0.078\n",
      "ID 1666: mean=0.706, min=0.472, max=0.910, std=0.097\n",
      "ID 1667: mean=0.738, min=0.555, max=0.905, std=0.069\n",
      "ID 1668: mean=0.791, min=0.504, max=0.902, std=0.083\n",
      "ID 1669: mean=0.895, min=0.795, max=0.955, std=0.034\n",
      "ID 1670: mean=0.788, min=0.551, max=0.933, std=0.081\n",
      "ID 1671: mean=0.724, min=0.568, max=0.867, std=0.076\n",
      "ID 1672: mean=0.801, min=0.658, max=0.908, std=0.077\n",
      "ID 1673: mean=0.721, min=0.569, max=0.919, std=0.090\n",
      "ID 1674: mean=0.773, min=0.599, max=0.950, std=0.080\n",
      "ID 1675: mean=0.745, min=0.557, max=0.909, std=0.095\n",
      "ID 1676: mean=0.785, min=0.585, max=0.967, std=0.098\n",
      "ID 1677: mean=0.760, min=0.575, max=0.936, std=0.106\n",
      "ID 1678: mean=0.808, min=0.694, max=0.956, std=0.081\n",
      "ID 1679: mean=0.841, min=0.592, max=0.980, std=0.089\n",
      "ID 1680: mean=0.717, min=0.498, max=0.966, std=0.112\n",
      "ID 1681: mean=0.724, min=0.583, max=0.929, std=0.082\n",
      "ID 1682: mean=0.743, min=0.468, max=0.943, std=0.133\n",
      "ID 1683: mean=0.824, min=0.593, max=0.923, std=0.074\n",
      "ID 1684: mean=0.837, min=0.700, max=0.941, std=0.060\n",
      "ID 1685: mean=0.806, min=0.654, max=0.969, std=0.108\n",
      "ID 1686: mean=0.780, min=0.621, max=0.919, std=0.071\n",
      "ID 1687: mean=0.893, min=0.835, max=0.951, std=0.032\n",
      "ID 1688: mean=0.870, min=0.777, max=0.955, std=0.049\n",
      "ID 1689: mean=0.747, min=0.604, max=0.959, std=0.083\n",
      "ID 1690: mean=0.725, min=0.482, max=0.919, std=0.096\n",
      "ID 1691: mean=0.775, min=0.543, max=0.954, std=0.090\n",
      "ID 1692: mean=0.759, min=0.569, max=0.976, std=0.097\n",
      "ID 1693: mean=0.796, min=0.614, max=0.956, std=0.093\n",
      "ID 1694: mean=0.787, min=0.592, max=0.967, std=0.097\n",
      "ID 1695: mean=0.751, min=0.503, max=0.904, std=0.121\n",
      "ID 1696: mean=0.739, min=0.516, max=0.958, std=0.118\n",
      "ID 1697: mean=0.773, min=0.528, max=0.951, std=0.096\n",
      "ID 1698: mean=0.750, min=0.505, max=0.938, std=0.109\n",
      "ID 1699: mean=0.774, min=0.581, max=0.951, std=0.075\n",
      "ID 1700: mean=0.864, min=0.674, max=0.961, std=0.065\n",
      "ID 1701: mean=0.831, min=0.602, max=0.981, std=0.087\n",
      "ID 1702: mean=0.805, min=0.575, max=0.957, std=0.098\n",
      "ID 1703: mean=0.764, min=0.596, max=0.937, std=0.077\n",
      "ID 1704: mean=0.798, min=0.641, max=0.932, std=0.073\n",
      "ID 1705: mean=0.781, min=0.608, max=0.948, std=0.083\n",
      "ID 1706: mean=0.786, min=0.637, max=0.922, std=0.073\n",
      "ID 1707: mean=0.868, min=0.604, max=0.985, std=0.109\n",
      "ID 1708: mean=0.757, min=0.567, max=0.895, std=0.078\n",
      "ID 1709: mean=0.836, min=0.627, max=0.959, std=0.081\n",
      "ID 1710: mean=0.791, min=0.639, max=0.921, std=0.079\n",
      "ID 1711: mean=0.745, min=0.568, max=0.925, std=0.092\n",
      "ID 1712: mean=0.841, min=0.743, max=0.960, std=0.052\n",
      "ID 1713: mean=0.833, min=0.690, max=0.959, std=0.062\n",
      "ID 1714: mean=0.750, min=0.416, max=0.950, std=0.112\n",
      "ID 1715: mean=0.757, min=0.532, max=0.941, std=0.107\n",
      "ID 1716: mean=0.803, min=0.617, max=0.956, std=0.077\n",
      "ID 1717: mean=0.817, min=0.638, max=0.947, std=0.083\n",
      "ID 1718: mean=0.725, min=0.498, max=0.964, std=0.104\n",
      "ID 1719: mean=0.778, min=0.590, max=0.937, std=0.077\n",
      "ID 1720: mean=0.794, min=0.593, max=0.913, std=0.079\n",
      "ID 1721: mean=0.823, min=0.674, max=0.954, std=0.081\n",
      "ID 1722: mean=0.770, min=0.599, max=0.927, std=0.081\n",
      "ID 1723: mean=0.768, min=0.560, max=0.939, std=0.088\n",
      "ID 1724: mean=0.782, min=0.639, max=0.958, std=0.099\n",
      "ID 1725: mean=0.754, min=0.490, max=0.944, std=0.106\n",
      "ID 1726: mean=0.704, min=0.558, max=0.918, std=0.087\n",
      "ID 1727: mean=0.791, min=0.620, max=0.947, std=0.088\n",
      "ID 1728: mean=0.766, min=0.657, max=0.871, std=0.054\n",
      "ID 1729: mean=0.729, min=0.568, max=0.931, std=0.070\n",
      "ID 1730: mean=0.741, min=0.521, max=0.880, std=0.088\n",
      "ID 1731: mean=0.819, min=0.716, max=0.920, std=0.050\n",
      "ID 1732: mean=0.785, min=0.577, max=0.914, std=0.073\n",
      "ID 1733: mean=0.749, min=0.536, max=0.928, std=0.094\n",
      "ID 1734: mean=0.801, min=0.615, max=0.939, std=0.082\n",
      "ID 1735: mean=0.700, min=0.573, max=0.866, std=0.090\n",
      "ID 1736: mean=0.794, min=0.629, max=0.932, std=0.083\n",
      "ID 1737: mean=0.886, min=0.774, max=0.960, std=0.042\n",
      "ID 1738: mean=0.818, min=0.704, max=0.914, std=0.055\n",
      "ID 1739: mean=0.838, min=0.638, max=0.958, std=0.061\n",
      "ID 1740: mean=0.753, min=0.614, max=0.847, std=0.059\n",
      "ID 1741: mean=0.749, min=0.576, max=0.896, std=0.079\n",
      "ID 1742: mean=0.815, min=0.695, max=0.923, std=0.068\n",
      "ID 1743: mean=0.787, min=0.538, max=0.940, std=0.107\n",
      "ID 1744: mean=0.763, min=0.529, max=0.892, std=0.086\n",
      "ID 1745: mean=0.791, min=0.603, max=0.942, std=0.092\n",
      "ID 1746: mean=0.783, min=0.591, max=0.949, std=0.099\n",
      "ID 1747: mean=0.718, min=0.574, max=0.892, std=0.078\n",
      "ID 1748: mean=0.812, min=0.716, max=0.905, std=0.048\n",
      "ID 1749: mean=0.774, min=0.657, max=0.898, std=0.069\n",
      "ID 1750: mean=0.741, min=0.572, max=0.913, std=0.075\n",
      "ID 1751: mean=0.800, min=0.611, max=0.943, std=0.080\n",
      "ID 1752: mean=0.729, min=0.518, max=0.975, std=0.102\n",
      "ID 1753: mean=0.778, min=0.623, max=0.929, std=0.064\n",
      "ID 1754: mean=0.772, min=0.574, max=0.936, std=0.079\n",
      "ID 1755: mean=0.753, min=0.483, max=0.956, std=0.088\n",
      "ID 1756: mean=0.747, min=0.551, max=0.877, std=0.076\n",
      "ID 1757: mean=0.734, min=0.602, max=0.924, std=0.076\n",
      "ID 1758: mean=0.728, min=0.541, max=0.914, std=0.068\n",
      "ID 1759: mean=0.770, min=0.563, max=0.947, std=0.085\n",
      "ID 1760: mean=0.758, min=0.599, max=0.924, std=0.079\n",
      "ID 1761: mean=0.668, min=0.511, max=0.881, std=0.079\n",
      "ID 1762: mean=0.753, min=0.463, max=0.927, std=0.096\n",
      "ID 1763: mean=0.773, min=0.608, max=0.918, std=0.085\n",
      "ID 1764: mean=0.708, min=0.511, max=0.846, std=0.082\n",
      "ID 1765: mean=0.718, min=0.523, max=0.945, std=0.132\n",
      "ID 1766: mean=0.717, min=0.511, max=0.890, std=0.074\n",
      "ID 1767: mean=0.774, min=0.601, max=0.952, std=0.083\n",
      "ID 1768: mean=0.769, min=0.525, max=0.928, std=0.090\n",
      "ID 1769: mean=0.746, min=0.625, max=0.924, std=0.073\n",
      "ID 1770: mean=0.741, min=0.547, max=0.910, std=0.085\n",
      "ID 1771: mean=0.762, min=0.546, max=0.947, std=0.087\n",
      "ID 1772: mean=0.721, min=0.396, max=0.962, std=0.101\n",
      "ID 1773: mean=0.796, min=0.617, max=0.948, std=0.065\n",
      "ID 1774: mean=0.713, min=0.558, max=0.885, std=0.083\n",
      "ID 1775: mean=0.733, min=0.562, max=0.942, std=0.081\n",
      "ID 1776: mean=0.802, min=0.657, max=0.954, std=0.088\n",
      "ID 1777: mean=0.751, min=0.587, max=0.932, std=0.078\n",
      "ID 1778: mean=0.774, min=0.519, max=0.960, std=0.081\n",
      "ID 1779: mean=0.760, min=0.534, max=0.909, std=0.076\n",
      "ID 1780: mean=0.795, min=0.617, max=0.914, std=0.070\n",
      "ID 1781: mean=0.736, min=0.537, max=0.922, std=0.097\n",
      "ID 1782: mean=0.824, min=0.513, max=0.972, std=0.105\n",
      "ID 1783: mean=0.743, min=0.526, max=0.893, std=0.090\n",
      "ID 1784: mean=0.808, min=0.592, max=0.952, std=0.064\n",
      "ID 1785: mean=0.831, min=0.622, max=0.956, std=0.071\n",
      "ID 1786: mean=0.752, min=0.524, max=0.900, std=0.085\n",
      "ID 1787: mean=0.846, min=0.589, max=0.978, std=0.114\n",
      "ID 1788: mean=0.763, min=0.544, max=0.958, std=0.108\n",
      "ID 1789: mean=0.819, min=0.590, max=0.957, std=0.083\n",
      "ID 1790: mean=0.714, min=0.596, max=0.858, std=0.068\n",
      "ID 1791: mean=0.669, min=0.471, max=0.877, std=0.099\n",
      "ID 1792: mean=0.726, min=0.527, max=0.906, std=0.088\n",
      "ID 1793: mean=0.707, min=0.534, max=0.867, std=0.068\n",
      "ID 1794: mean=0.730, min=0.509, max=0.890, std=0.084\n",
      "ID 1795: mean=0.726, min=0.570, max=0.899, std=0.088\n",
      "ID 1796: mean=0.748, min=0.556, max=0.917, std=0.081\n",
      "ID 1797: mean=0.767, min=0.593, max=0.885, std=0.075\n",
      "ID 1798: mean=0.742, min=0.552, max=0.921, std=0.111\n",
      "ID 1799: mean=0.711, min=0.482, max=0.904, std=0.085\n",
      "ID 1800: mean=0.829, min=0.614, max=0.959, std=0.080\n",
      "ID 1801: mean=0.759, min=0.496, max=0.923, std=0.086\n",
      "ID 1802: mean=0.743, min=0.578, max=0.913, std=0.078\n",
      "ID 1803: mean=0.752, min=0.534, max=0.934, std=0.095\n",
      "ID 1804: mean=0.706, min=0.564, max=0.821, std=0.062\n",
      "ID 1805: mean=0.718, min=0.476, max=0.905, std=0.093\n",
      "ID 1806: mean=0.793, min=0.669, max=0.944, std=0.066\n",
      "ID 1807: mean=0.808, min=0.689, max=0.898, std=0.052\n",
      "ID 1808: mean=0.716, min=0.554, max=0.890, std=0.080\n",
      "ID 1809: mean=0.817, min=0.673, max=0.949, std=0.082\n",
      "ID 1810: mean=0.743, min=0.465, max=0.942, std=0.104\n",
      "ID 1811: mean=0.723, min=0.553, max=0.887, std=0.082\n",
      "ID 1812: mean=0.799, min=0.560, max=0.935, std=0.080\n",
      "ID 1813: mean=0.730, min=0.421, max=0.948, std=0.116\n",
      "ID 1814: mean=0.727, min=0.385, max=0.909, std=0.114\n",
      "ID 1815: mean=0.675, min=0.464, max=0.901, std=0.103\n",
      "ID 1816: mean=0.688, min=0.564, max=0.930, std=0.093\n",
      "ID 1817: mean=0.721, min=0.467, max=0.937, std=0.101\n",
      "ID 1818: mean=0.746, min=0.501, max=0.940, std=0.129\n",
      "ID 1819: mean=0.721, min=0.494, max=0.901, std=0.096\n",
      "ID 1820: mean=0.678, min=0.423, max=0.870, std=0.105\n",
      "ID 1821: mean=0.696, min=0.526, max=0.915, std=0.099\n",
      "ID 1822: mean=0.721, min=0.508, max=0.925, std=0.107\n",
      "ID 1823: mean=0.722, min=0.525, max=0.912, std=0.093\n",
      "ID 1824: mean=0.751, min=0.490, max=0.925, std=0.115\n",
      "ID 1825: mean=0.804, min=0.616, max=0.913, std=0.080\n",
      "ID 1826: mean=0.673, min=0.533, max=0.867, std=0.078\n",
      "ID 1827: mean=0.669, min=0.506, max=0.922, std=0.108\n",
      "ID 1828: mean=0.747, min=0.522, max=0.952, std=0.099\n",
      "ID 1829: mean=0.775, min=0.576, max=0.949, std=0.106\n",
      "ID 1830: mean=0.640, min=0.437, max=0.941, std=0.114\n",
      "ID 1831: mean=0.785, min=0.665, max=0.896, std=0.066\n",
      "ID 1832: mean=0.852, min=0.678, max=0.944, std=0.067\n",
      "ID 1833: mean=0.676, min=0.476, max=0.877, std=0.106\n",
      "ID 1834: mean=0.707, min=0.381, max=0.887, std=0.124\n",
      "ID 1835: mean=0.731, min=0.565, max=0.863, std=0.081\n",
      "ID 1836: mean=0.718, min=0.587, max=0.899, std=0.073\n",
      "ID 1837: mean=0.802, min=0.560, max=0.965, std=0.102\n",
      "ID 1838: mean=0.753, min=0.553, max=0.924, std=0.108\n",
      "ID 1839: mean=0.730, min=0.540, max=0.898, std=0.106\n",
      "ID 1840: mean=0.754, min=0.516, max=0.913, std=0.098\n",
      "ID 1841: mean=0.804, min=0.642, max=0.931, std=0.087\n",
      "ID 1842: mean=0.735, min=0.458, max=0.943, std=0.111\n",
      "ID 1843: mean=0.741, min=0.540, max=0.907, std=0.084\n",
      "ID 1844: mean=0.797, min=0.633, max=0.956, std=0.075\n",
      "ID 1845: mean=0.726, min=0.535, max=0.889, std=0.090\n",
      "ID 1846: mean=0.696, min=0.541, max=0.868, std=0.103\n",
      "ID 1847: mean=0.784, min=0.673, max=0.929, std=0.072\n",
      "ID 1848: mean=0.793, min=0.613, max=0.871, std=0.066\n",
      "ID 1849: mean=0.758, min=0.604, max=0.889, std=0.072\n",
      "ID 1850: mean=0.687, min=0.454, max=0.887, std=0.104\n",
      "ID 1851: mean=0.817, min=0.684, max=0.904, std=0.058\n",
      "ID 1852: mean=0.766, min=0.549, max=0.936, std=0.098\n",
      "ID 1853: mean=0.802, min=0.595, max=0.936, std=0.090\n",
      "ID 1854: mean=0.784, min=0.680, max=0.892, std=0.055\n",
      "ID 1855: mean=0.739, min=0.593, max=0.884, std=0.077\n",
      "ID 1856: mean=0.868, min=0.799, max=0.962, std=0.048\n",
      "ID 1857: mean=0.827, min=0.713, max=0.933, std=0.053\n",
      "ID 1858: mean=0.747, min=0.591, max=0.902, std=0.080\n",
      "ID 1859: mean=0.740, min=0.536, max=0.876, std=0.089\n",
      "ID 1860: mean=0.817, min=0.631, max=0.922, std=0.081\n",
      "ID 1861: mean=0.627, min=0.469, max=0.922, std=0.112\n",
      "ID 1862: mean=0.733, min=0.495, max=0.940, std=0.096\n",
      "ID 1863: mean=0.725, min=0.565, max=0.871, std=0.070\n",
      "ID 1864: mean=0.713, min=0.507, max=0.906, std=0.095\n",
      "ID 1865: mean=0.740, min=0.466, max=0.916, std=0.120\n",
      "ID 1866: mean=0.658, min=0.458, max=0.858, std=0.083\n",
      "ID 1867: mean=0.746, min=0.541, max=0.935, std=0.096\n",
      "ID 1868: mean=0.823, min=0.592, max=0.979, std=0.105\n",
      "ID 1869: mean=0.741, min=0.542, max=0.954, std=0.106\n",
      "ID 1870: mean=0.731, min=0.514, max=0.962, std=0.143\n",
      "ID 1871: mean=0.785, min=0.606, max=0.956, std=0.114\n",
      "ID 1872: mean=0.770, min=0.586, max=0.898, std=0.077\n",
      "ID 1873: mean=0.817, min=0.676, max=0.920, std=0.058\n",
      "ID 1874: mean=0.740, min=0.524, max=0.896, std=0.097\n",
      "ID 1875: mean=0.731, min=0.574, max=0.882, std=0.081\n",
      "ID 1876: mean=0.814, min=0.676, max=0.922, std=0.061\n",
      "ID 1877: mean=0.759, min=0.611, max=0.903, std=0.087\n",
      "ID 1878: mean=0.773, min=0.623, max=0.909, std=0.075\n",
      "ID 1879: mean=0.703, min=0.567, max=0.876, std=0.068\n",
      "ID 1880: mean=0.683, min=0.575, max=0.948, std=0.086\n",
      "ID 1881: mean=0.836, min=0.686, max=0.972, std=0.070\n",
      "ID 1882: mean=0.799, min=0.632, max=0.927, std=0.088\n",
      "ID 1883: mean=0.755, min=0.609, max=0.874, std=0.080\n",
      "ID 1884: mean=0.747, min=0.448, max=0.963, std=0.133\n",
      "ID 1885: mean=0.696, min=0.460, max=0.885, std=0.113\n",
      "ID 1886: mean=0.801, min=0.653, max=0.966, std=0.096\n",
      "ID 1887: mean=0.719, min=0.560, max=0.898, std=0.098\n",
      "ID 1888: mean=0.841, min=0.766, max=0.952, std=0.054\n",
      "ID 1889: mean=0.741, min=0.439, max=0.937, std=0.118\n",
      "ID 1890: mean=0.733, min=0.470, max=0.907, std=0.110\n",
      "ID 1891: mean=0.837, min=0.535, max=0.975, std=0.111\n",
      "ID 1892: mean=0.763, min=0.608, max=0.964, std=0.082\n",
      "ID 1893: mean=0.838, min=0.751, max=0.969, std=0.056\n",
      "ID 1894: mean=0.792, min=0.521, max=0.934, std=0.095\n",
      "ID 1895: mean=0.793, min=0.565, max=0.944, std=0.102\n",
      "ID 1896: mean=0.810, min=0.619, max=0.919, std=0.071\n",
      "ID 1897: mean=0.728, min=0.525, max=0.946, std=0.104\n",
      "ID 1898: mean=0.750, min=0.599, max=0.892, std=0.075\n",
      "ID 1899: mean=0.762, min=0.548, max=0.924, std=0.105\n",
      "ID 1900: mean=0.788, min=0.578, max=0.932, std=0.084\n",
      "ID 1901: mean=0.798, min=0.688, max=0.946, std=0.064\n",
      "ID 1902: mean=0.799, min=0.588, max=0.903, std=0.076\n",
      "ID 1903: mean=0.837, min=0.569, max=0.962, std=0.107\n",
      "ID 1904: mean=0.803, min=0.708, max=0.928, std=0.051\n",
      "ID 1905: mean=0.786, min=0.609, max=0.945, std=0.098\n",
      "ID 1906: mean=0.853, min=0.721, max=0.964, std=0.055\n",
      "ID 1907: mean=0.792, min=0.608, max=0.942, std=0.075\n",
      "ID 1908: mean=0.798, min=0.667, max=0.925, std=0.063\n",
      "ID 1909: mean=0.731, min=0.541, max=0.935, std=0.085\n",
      "ID 1910: mean=0.720, min=0.492, max=0.945, std=0.111\n",
      "ID 1911: mean=0.783, min=0.641, max=0.925, std=0.060\n",
      "ID 1912: mean=0.783, min=0.632, max=0.930, std=0.073\n",
      "ID 1913: mean=0.748, min=0.528, max=0.946, std=0.096\n",
      "ID 1914: mean=0.764, min=0.632, max=0.914, std=0.080\n",
      "ID 1915: mean=0.853, min=0.677, max=0.958, std=0.065\n",
      "ID 1916: mean=0.749, min=0.474, max=0.926, std=0.123\n",
      "ID 1917: mean=0.842, min=0.649, max=0.963, std=0.077\n",
      "ID 1918: mean=0.766, min=0.608, max=0.940, std=0.081\n",
      "ID 1919: mean=0.760, min=0.521, max=0.880, std=0.087\n",
      "ID 1920: mean=0.772, min=0.618, max=0.916, std=0.074\n",
      "ID 1921: mean=0.800, min=0.549, max=0.954, std=0.120\n",
      "ID 1922: mean=0.737, min=0.531, max=0.910, std=0.095\n",
      "ID 1923: mean=0.781, min=0.473, max=0.930, std=0.106\n",
      "ID 1924: mean=0.720, min=0.587, max=0.901, std=0.074\n",
      "ID 1925: mean=0.758, min=0.497, max=0.936, std=0.097\n",
      "ID 1926: mean=0.875, min=0.771, max=0.925, std=0.042\n",
      "ID 1927: mean=0.795, min=0.571, max=0.919, std=0.080\n",
      "ID 1928: mean=0.791, min=0.620, max=0.917, std=0.079\n",
      "ID 1929: mean=0.801, min=0.659, max=0.914, std=0.064\n",
      "ID 1930: mean=0.763, min=0.584, max=0.914, std=0.082\n",
      "ID 1931: mean=0.748, min=0.580, max=0.919, std=0.091\n",
      "ID 1932: mean=0.843, min=0.675, max=0.958, std=0.075\n",
      "ID 1933: mean=0.723, min=0.497, max=0.921, std=0.089\n",
      "ID 1934: mean=0.710, min=0.492, max=0.914, std=0.084\n",
      "ID 1935: mean=0.781, min=0.657, max=0.891, std=0.070\n",
      "ID 1936: mean=0.751, min=0.572, max=0.922, std=0.095\n",
      "ID 1937: mean=0.766, min=0.617, max=0.928, std=0.073\n",
      "ID 1938: mean=0.741, min=0.536, max=0.875, std=0.076\n",
      "ID 1939: mean=0.767, min=0.501, max=0.905, std=0.105\n",
      "ID 1940: mean=0.807, min=0.629, max=0.933, std=0.073\n",
      "ID 1941: mean=0.855, min=0.794, max=0.929, std=0.037\n",
      "ID 1942: mean=0.711, min=0.543, max=0.878, std=0.075\n",
      "ID 1943: mean=0.746, min=0.441, max=0.968, std=0.112\n",
      "ID 1944: mean=0.779, min=0.534, max=0.952, std=0.127\n",
      "ID 1945: mean=0.788, min=0.660, max=0.903, std=0.065\n",
      "ID 1946: mean=0.843, min=0.689, max=0.949, std=0.072\n",
      "ID 1947: mean=0.785, min=0.569, max=0.904, std=0.079\n",
      "ID 1948: mean=0.797, min=0.652, max=0.952, std=0.058\n",
      "ID 1949: mean=0.745, min=0.620, max=0.904, std=0.075\n",
      "ID 1950: mean=0.729, min=0.438, max=0.876, std=0.104\n",
      "ID 1951: mean=0.772, min=0.569, max=0.936, std=0.099\n",
      "ID 1952: mean=0.721, min=0.499, max=0.941, std=0.109\n",
      "ID 1953: mean=0.674, min=0.417, max=0.858, std=0.107\n",
      "ID 1954: mean=0.763, min=0.589, max=0.932, std=0.080\n",
      "ID 1955: mean=0.771, min=0.628, max=0.924, std=0.082\n",
      "ID 1956: mean=0.749, min=0.607, max=0.938, std=0.097\n",
      "ID 1957: mean=0.722, min=0.530, max=0.927, std=0.089\n",
      "ID 1958: mean=0.867, min=0.791, max=0.937, std=0.037\n",
      "ID 1959: mean=0.798, min=0.555, max=0.940, std=0.100\n",
      "ID 1960: mean=0.803, min=0.625, max=0.907, std=0.079\n",
      "ID 1961: mean=0.803, min=0.651, max=0.930, std=0.080\n",
      "ID 1962: mean=0.791, min=0.602, max=0.906, std=0.073\n",
      "ID 1963: mean=0.754, min=0.597, max=0.874, std=0.073\n",
      "ID 1964: mean=0.815, min=0.610, max=0.930, std=0.079\n",
      "ID 1965: mean=0.777, min=0.662, max=0.909, std=0.065\n",
      "ID 1966: mean=0.739, min=0.567, max=0.911, std=0.097\n",
      "ID 1967: mean=0.760, min=0.491, max=0.938, std=0.103\n",
      "ID 1968: mean=0.886, min=0.834, max=0.951, std=0.028\n",
      "ID 1969: mean=0.820, min=0.705, max=0.934, std=0.063\n",
      "ID 1970: mean=0.690, min=0.452, max=0.943, std=0.112\n",
      "ID 1971: mean=0.758, min=0.576, max=0.879, std=0.083\n",
      "ID 1972: mean=0.799, min=0.641, max=0.962, std=0.078\n",
      "ID 1973: mean=0.865, min=0.776, max=0.947, std=0.049\n",
      "ID 1974: mean=0.782, min=0.635, max=0.884, std=0.065\n",
      "ID 1975: mean=0.778, min=0.548, max=0.932, std=0.086\n",
      "ID 1976: mean=0.692, min=0.490, max=0.900, std=0.122\n",
      "ID 1977: mean=0.774, min=0.536, max=0.957, std=0.097\n",
      "ID 1978: mean=0.747, min=0.586, max=0.877, std=0.078\n",
      "ID 1979: mean=0.803, min=0.519, max=0.967, std=0.115\n",
      "ID 1980: mean=0.806, min=0.598, max=0.944, std=0.082\n",
      "ID 1981: mean=0.716, min=0.578, max=0.843, std=0.070\n",
      "ID 1982: mean=0.793, min=0.587, max=0.941, std=0.083\n",
      "ID 1983: mean=0.812, min=0.333, max=0.966, std=0.131\n",
      "ID 1984: mean=0.800, min=0.564, max=0.962, std=0.100\n",
      "ID 1985: mean=0.813, min=0.502, max=0.953, std=0.111\n",
      "ID 1986: mean=0.802, min=0.605, max=0.956, std=0.077\n",
      "ID 1987: mean=0.731, min=0.516, max=0.914, std=0.094\n",
      "ID 1988: mean=0.818, min=0.702, max=0.922, std=0.048\n",
      "ID 1989: mean=0.725, min=0.561, max=0.949, std=0.091\n",
      "ID 1990: mean=0.743, min=0.523, max=0.909, std=0.115\n",
      "ID 1991: mean=0.665, min=0.523, max=0.795, std=0.072\n",
      "ID 1992: mean=0.635, min=0.481, max=0.892, std=0.116\n",
      "ID 1993: mean=0.749, min=0.588, max=0.859, std=0.071\n",
      "ID 1994: mean=0.656, min=0.425, max=0.873, std=0.133\n",
      "ID 1995: mean=0.769, min=0.598, max=0.896, std=0.089\n",
      "ID 1996: mean=0.700, min=0.538, max=0.849, std=0.094\n",
      "ID 1997: mean=0.759, min=0.539, max=0.894, std=0.088\n",
      "ID 1998: mean=0.801, min=0.563, max=0.942, std=0.109\n",
      "ID 1999: mean=0.749, min=0.587, max=0.881, std=0.094\n",
      "\n",
      " Inter-global overlap:\n",
      "0 vs 1: mean=0.622, max=0.899\n",
      "0 vs 2: mean=0.452, max=0.720\n",
      "0 vs 3: mean=0.393, max=0.695\n",
      "0 vs 4: mean=0.433, max=0.814\n",
      "0 vs 5: mean=0.574, max=0.849\n",
      "0 vs 6: mean=0.533, max=0.838\n",
      "0 vs 7: mean=0.339, max=0.713\n",
      "0 vs 8: mean=0.485, max=0.798\n",
      "0 vs 9: mean=0.509, max=0.764\n",
      "0 vs 10: mean=0.488, max=0.811\n",
      "0 vs 11: mean=0.256, max=0.518\n",
      "0 vs 12: mean=0.341, max=0.631\n",
      "0 vs 13: mean=0.677, max=0.862\n",
      "0 vs 14: mean=0.214, max=0.428\n",
      "0 vs 15: mean=0.283, max=0.698\n",
      "0 vs 16: mean=0.622, max=0.919\n",
      "0 vs 17: mean=0.471, max=0.697\n",
      "0 vs 18: mean=0.394, max=0.711\n",
      "0 vs 19: mean=0.367, max=0.567\n",
      "0 vs 20: mean=0.499, max=0.681\n",
      "0 vs 21: mean=0.440, max=0.791\n",
      "0 vs 22: mean=0.494, max=0.747\n",
      "0 vs 23: mean=0.381, max=0.513\n",
      "0 vs 24: mean=0.399, max=0.649\n",
      "0 vs 25: mean=0.291, max=0.635\n",
      "0 vs 26: mean=0.395, max=0.620\n",
      "0 vs 27: mean=0.274, max=0.462\n",
      "0 vs 28: mean=0.245, max=0.469\n",
      "0 vs 29: mean=0.178, max=0.344\n",
      "0 vs 30: mean=0.313, max=0.686\n",
      "0 vs 31: mean=0.232, max=0.515\n",
      "0 vs 32: mean=0.407, max=0.580\n",
      "0 vs 33: mean=0.399, max=0.692\n",
      "0 vs 34: mean=0.431, max=0.701\n",
      "0 vs 35: mean=0.354, max=0.673\n",
      "0 vs 36: mean=0.445, max=0.750\n",
      "0 vs 37: mean=0.462, max=0.692\n",
      "0 vs 38: mean=0.321, max=0.510\n",
      "0 vs 39: mean=0.395, max=0.749\n",
      "0 vs 40: mean=0.274, max=0.468\n",
      "0 vs 41: mean=0.325, max=0.596\n",
      "0 vs 42: mean=0.308, max=0.547\n",
      "0 vs 43: mean=0.392, max=0.592\n",
      "0 vs 44: mean=0.430, max=0.621\n",
      "0 vs 45: mean=0.414, max=0.710\n",
      "0 vs 46: mean=0.532, max=0.761\n",
      "0 vs 47: mean=0.319, max=0.526\n",
      "0 vs 48: mean=0.309, max=0.585\n",
      "0 vs 49: mean=0.166, max=0.373\n",
      "0 vs 50: mean=0.270, max=0.562\n",
      "0 vs 51: mean=0.278, max=0.548\n",
      "0 vs 52: mean=0.369, max=0.540\n",
      "0 vs 53: mean=0.155, max=0.346\n",
      "0 vs 54: mean=0.168, max=0.343\n",
      "0 vs 55: mean=0.448, max=0.663\n",
      "0 vs 56: mean=0.084, max=0.290\n",
      "0 vs 57: mean=0.222, max=0.461\n",
      "0 vs 58: mean=0.229, max=0.439\n",
      "0 vs 59: mean=0.255, max=0.490\n",
      "0 vs 60: mean=0.205, max=0.456\n",
      "0 vs 61: mean=0.293, max=0.598\n",
      "0 vs 62: mean=0.183, max=0.345\n",
      "0 vs 63: mean=0.403, max=0.624\n",
      "0 vs 64: mean=0.292, max=0.457\n",
      "0 vs 65: mean=0.603, max=0.803\n",
      "0 vs 66: mean=0.285, max=0.459\n",
      "0 vs 67: mean=0.322, max=0.598\n",
      "0 vs 68: mean=0.298, max=0.534\n",
      "0 vs 69: mean=0.457, max=0.686\n",
      "0 vs 70: mean=0.213, max=0.353\n",
      "0 vs 71: mean=0.261, max=0.575\n",
      "0 vs 72: mean=0.396, max=0.694\n",
      "0 vs 73: mean=0.243, max=0.416\n",
      "0 vs 74: mean=0.251, max=0.414\n",
      "0 vs 75: mean=0.251, max=0.434\n",
      "0 vs 76: mean=0.252, max=0.447\n",
      "0 vs 77: mean=0.274, max=0.533\n",
      "0 vs 78: mean=0.338, max=0.538\n",
      "0 vs 79: mean=0.329, max=0.549\n",
      "0 vs 80: mean=0.315, max=0.475\n",
      "0 vs 81: mean=0.201, max=0.420\n",
      "0 vs 82: mean=0.096, max=0.313\n",
      "0 vs 83: mean=0.155, max=0.458\n",
      "0 vs 84: mean=0.181, max=0.481\n",
      "0 vs 85: mean=0.401, max=0.652\n",
      "0 vs 86: mean=0.249, max=0.461\n",
      "0 vs 87: mean=0.191, max=0.388\n",
      "0 vs 88: mean=0.242, max=0.465\n",
      "0 vs 89: mean=0.447, max=0.710\n",
      "0 vs 90: mean=0.008, max=0.181\n",
      "0 vs 91: mean=-0.067, max=0.083\n",
      "0 vs 92: mean=-0.096, max=0.065\n",
      "0 vs 93: mean=-0.043, max=0.082\n",
      "0 vs 94: mean=0.007, max=0.160\n",
      "0 vs 95: mean=-0.151, max=0.041\n",
      "0 vs 96: mean=-0.197, max=-0.072\n",
      "0 vs 97: mean=0.080, max=0.265\n",
      "0 vs 98: mean=0.091, max=0.319\n",
      "0 vs 99: mean=-0.047, max=0.083\n",
      "0 vs 100: mean=0.086, max=0.461\n",
      "0 vs 101: mean=-0.026, max=0.114\n",
      "0 vs 102: mean=0.011, max=0.251\n",
      "0 vs 103: mean=-0.039, max=0.062\n",
      "0 vs 104: mean=-0.075, max=0.098\n",
      "0 vs 105: mean=-0.013, max=0.208\n",
      "0 vs 106: mean=0.113, max=0.334\n",
      "0 vs 107: mean=0.061, max=0.213\n",
      "0 vs 108: mean=0.063, max=0.249\n",
      "0 vs 109: mean=0.052, max=0.259\n",
      "0 vs 110: mean=-0.040, max=0.182\n",
      "0 vs 111: mean=-0.056, max=0.151\n",
      "0 vs 112: mean=0.036, max=0.196\n",
      "0 vs 113: mean=0.119, max=0.292\n",
      "0 vs 114: mean=0.085, max=0.302\n",
      "0 vs 115: mean=0.059, max=0.342\n",
      "0 vs 116: mean=-0.065, max=0.079\n",
      "0 vs 117: mean=-0.095, max=0.085\n",
      "0 vs 118: mean=-0.227, max=-0.104\n",
      "0 vs 119: mean=-0.143, max=-0.014\n",
      "0 vs 120: mean=-0.048, max=0.073\n",
      "0 vs 121: mean=0.119, max=0.289\n",
      "0 vs 122: mean=-0.017, max=0.200\n",
      "0 vs 123: mean=-0.049, max=0.101\n",
      "0 vs 124: mean=-0.039, max=0.112\n",
      "0 vs 125: mean=0.033, max=0.176\n",
      "0 vs 126: mean=-0.056, max=0.094\n",
      "0 vs 127: mean=0.009, max=0.152\n",
      "0 vs 128: mean=-0.077, max=0.068\n",
      "0 vs 129: mean=-0.098, max=0.024\n",
      "0 vs 130: mean=-0.157, max=-0.016\n",
      "0 vs 131: mean=-0.088, max=0.240\n",
      "0 vs 132: mean=-0.016, max=0.186\n",
      "0 vs 133: mean=-0.070, max=0.172\n",
      "0 vs 134: mean=-0.012, max=0.200\n",
      "0 vs 135: mean=0.084, max=0.233\n",
      "0 vs 136: mean=0.026, max=0.187\n",
      "0 vs 137: mean=-0.079, max=0.034\n",
      "0 vs 138: mean=0.078, max=0.242\n",
      "0 vs 139: mean=-0.034, max=0.262\n",
      "0 vs 140: mean=-0.063, max=0.089\n",
      "0 vs 141: mean=-0.011, max=0.102\n",
      "0 vs 142: mean=0.319, max=0.566\n",
      "0 vs 143: mean=-0.127, max=0.035\n",
      "0 vs 144: mean=-0.051, max=0.221\n",
      "0 vs 145: mean=-0.004, max=0.167\n",
      "0 vs 146: mean=0.037, max=0.201\n",
      "0 vs 147: mean=-0.021, max=0.195\n",
      "0 vs 148: mean=0.091, max=0.250\n",
      "0 vs 149: mean=-0.071, max=0.072\n",
      "0 vs 150: mean=-0.064, max=0.118\n",
      "0 vs 151: mean=-0.057, max=0.032\n",
      "0 vs 152: mean=-0.016, max=0.279\n",
      "0 vs 153: mean=-0.095, max=0.122\n",
      "0 vs 154: mean=-0.058, max=0.145\n",
      "0 vs 155: mean=-0.049, max=0.044\n",
      "0 vs 156: mean=0.068, max=0.217\n",
      "0 vs 157: mean=-0.019, max=0.137\n",
      "0 vs 158: mean=0.018, max=0.211\n",
      "0 vs 159: mean=-0.049, max=0.091\n",
      "0 vs 160: mean=-0.016, max=0.111\n",
      "0 vs 161: mean=-0.223, max=-0.088\n",
      "0 vs 162: mean=-0.062, max=0.084\n",
      "0 vs 163: mean=-0.050, max=0.174\n",
      "0 vs 164: mean=-0.150, max=-0.025\n",
      "0 vs 165: mean=0.040, max=0.197\n",
      "0 vs 166: mean=0.020, max=0.134\n",
      "0 vs 167: mean=-0.120, max=-0.025\n",
      "0 vs 168: mean=-0.163, max=-0.056\n",
      "0 vs 169: mean=-0.008, max=0.170\n",
      "0 vs 170: mean=-0.021, max=0.114\n",
      "0 vs 171: mean=-0.017, max=0.076\n",
      "0 vs 172: mean=0.057, max=0.276\n",
      "0 vs 173: mean=0.025, max=0.232\n",
      "0 vs 174: mean=0.054, max=0.286\n",
      "0 vs 175: mean=0.066, max=0.248\n",
      "0 vs 176: mean=-0.041, max=0.062\n",
      "0 vs 177: mean=-0.150, max=0.051\n",
      "0 vs 178: mean=-0.084, max=0.060\n",
      "0 vs 179: mean=-0.101, max=0.136\n",
      "0 vs 180: mean=0.028, max=0.172\n",
      "0 vs 181: mean=-0.101, max=0.014\n",
      "0 vs 182: mean=-0.086, max=0.045\n",
      "0 vs 183: mean=0.145, max=0.444\n",
      "0 vs 184: mean=-0.104, max=0.111\n",
      "0 vs 185: mean=-0.071, max=0.012\n",
      "0 vs 186: mean=0.052, max=0.306\n",
      "0 vs 187: mean=-0.008, max=0.130\n",
      "0 vs 188: mean=-0.118, max=0.062\n",
      "0 vs 189: mean=0.054, max=0.400\n",
      "0 vs 190: mean=-0.007, max=0.210\n",
      "0 vs 191: mean=-0.068, max=0.131\n",
      "0 vs 192: mean=-0.021, max=0.137\n",
      "0 vs 193: mean=0.001, max=0.110\n",
      "0 vs 194: mean=0.013, max=0.244\n",
      "0 vs 195: mean=-0.110, max=0.022\n",
      "0 vs 196: mean=0.054, max=0.242\n",
      "0 vs 197: mean=-0.082, max=0.030\n",
      "0 vs 198: mean=-0.104, max=0.008\n",
      "0 vs 199: mean=0.031, max=0.177\n",
      "0 vs 200: mean=0.017, max=0.247\n",
      "0 vs 201: mean=-0.153, max=0.041\n",
      "0 vs 202: mean=-0.038, max=0.147\n",
      "0 vs 203: mean=-0.074, max=0.093\n",
      "0 vs 204: mean=-0.130, max=-0.005\n",
      "0 vs 205: mean=0.019, max=0.281\n",
      "0 vs 206: mean=-0.012, max=0.252\n",
      "0 vs 207: mean=-0.078, max=0.062\n",
      "0 vs 208: mean=-0.151, max=-0.006\n",
      "0 vs 209: mean=-0.096, max=0.025\n",
      "0 vs 210: mean=0.069, max=0.208\n",
      "0 vs 211: mean=-0.090, max=0.037\n",
      "0 vs 212: mean=-0.127, max=-0.011\n",
      "0 vs 213: mean=-0.044, max=0.237\n",
      "0 vs 214: mean=-0.012, max=0.212\n",
      "0 vs 215: mean=0.086, max=0.227\n",
      "0 vs 216: mean=0.019, max=0.220\n",
      "0 vs 217: mean=-0.086, max=0.036\n",
      "0 vs 218: mean=-0.064, max=0.138\n",
      "0 vs 219: mean=-0.044, max=0.162\n",
      "0 vs 220: mean=0.057, max=0.226\n",
      "0 vs 221: mean=-0.025, max=0.127\n",
      "0 vs 222: mean=-0.086, max=0.044\n",
      "0 vs 223: mean=0.051, max=0.200\n",
      "0 vs 224: mean=-0.156, max=-0.017\n",
      "0 vs 225: mean=-0.080, max=0.070\n",
      "0 vs 226: mean=-0.026, max=0.312\n",
      "0 vs 227: mean=0.091, max=0.445\n",
      "0 vs 228: mean=-0.131, max=0.008\n",
      "0 vs 229: mean=0.067, max=0.237\n",
      "0 vs 230: mean=-0.131, max=0.028\n",
      "0 vs 231: mean=0.063, max=0.401\n",
      "0 vs 232: mean=-0.034, max=0.155\n",
      "0 vs 233: mean=-0.238, max=-0.107\n",
      "0 vs 234: mean=0.011, max=0.184\n",
      "0 vs 235: mean=-0.105, max=0.045\n",
      "0 vs 236: mean=-0.087, max=0.061\n",
      "0 vs 237: mean=-0.171, max=-0.011\n",
      "0 vs 238: mean=0.039, max=0.227\n",
      "0 vs 239: mean=-0.062, max=0.110\n",
      "0 vs 240: mean=-0.083, max=0.106\n",
      "0 vs 241: mean=0.054, max=0.218\n",
      "0 vs 242: mean=-0.153, max=0.110\n",
      "0 vs 243: mean=-0.088, max=0.104\n",
      "0 vs 244: mean=-0.065, max=0.295\n",
      "0 vs 245: mean=0.091, max=0.272\n",
      "0 vs 246: mean=-0.080, max=0.115\n",
      "0 vs 247: mean=-0.088, max=0.023\n",
      "0 vs 248: mean=-0.164, max=-0.014\n",
      "0 vs 249: mean=-0.062, max=0.100\n",
      "0 vs 250: mean=0.088, max=0.249\n",
      "0 vs 251: mean=0.067, max=0.189\n",
      "0 vs 252: mean=0.000, max=0.130\n",
      "0 vs 253: mean=-0.122, max=-0.032\n",
      "0 vs 254: mean=-0.058, max=0.062\n",
      "0 vs 255: mean=-0.104, max=0.009\n",
      "0 vs 256: mean=-0.057, max=0.085\n",
      "0 vs 257: mean=-0.120, max=0.073\n",
      "0 vs 258: mean=-0.181, max=-0.026\n",
      "0 vs 259: mean=-0.084, max=0.014\n",
      "0 vs 260: mean=-0.013, max=0.143\n",
      "0 vs 261: mean=-0.064, max=0.064\n",
      "0 vs 262: mean=-0.053, max=0.060\n",
      "0 vs 263: mean=0.059, max=0.203\n",
      "0 vs 264: mean=-0.153, max=0.013\n",
      "0 vs 265: mean=-0.090, max=0.033\n",
      "0 vs 266: mean=-0.114, max=-0.021\n",
      "0 vs 267: mean=-0.106, max=0.014\n",
      "0 vs 268: mean=-0.029, max=0.082\n",
      "0 vs 269: mean=-0.052, max=0.091\n",
      "0 vs 270: mean=0.110, max=0.326\n",
      "0 vs 271: mean=-0.096, max=-0.018\n",
      "0 vs 272: mean=-0.153, max=-0.027\n",
      "0 vs 273: mean=-0.029, max=0.112\n",
      "0 vs 274: mean=-0.137, max=-0.034\n",
      "0 vs 275: mean=-0.111, max=-0.006\n",
      "0 vs 276: mean=-0.009, max=0.125\n",
      "0 vs 277: mean=0.024, max=0.220\n",
      "0 vs 278: mean=-0.116, max=-0.020\n",
      "0 vs 279: mean=-0.145, max=-0.051\n",
      "0 vs 280: mean=0.038, max=0.143\n",
      "0 vs 281: mean=-0.128, max=-0.004\n",
      "0 vs 282: mean=-0.009, max=0.108\n",
      "0 vs 283: mean=-0.067, max=0.124\n",
      "0 vs 284: mean=0.045, max=0.275\n",
      "0 vs 285: mean=-0.047, max=0.129\n",
      "0 vs 286: mean=-0.090, max=0.041\n",
      "0 vs 287: mean=-0.114, max=-0.002\n",
      "0 vs 288: mean=0.067, max=0.207\n",
      "0 vs 289: mean=-0.060, max=0.051\n",
      "0 vs 290: mean=-0.070, max=0.020\n",
      "0 vs 291: mean=-0.000, max=0.081\n",
      "0 vs 292: mean=0.027, max=0.225\n",
      "0 vs 293: mean=0.051, max=0.189\n",
      "0 vs 294: mean=-0.074, max=0.070\n",
      "0 vs 295: mean=-0.102, max=0.016\n",
      "0 vs 296: mean=-0.066, max=0.076\n",
      "0 vs 297: mean=0.017, max=0.142\n",
      "0 vs 298: mean=-0.194, max=-0.037\n",
      "0 vs 299: mean=0.075, max=0.217\n",
      "0 vs 300: mean=0.101, max=0.350\n",
      "0 vs 301: mean=0.073, max=0.199\n",
      "0 vs 302: mean=-0.018, max=0.131\n",
      "0 vs 303: mean=-0.096, max=0.022\n",
      "0 vs 304: mean=0.014, max=0.124\n",
      "0 vs 305: mean=0.005, max=0.088\n",
      "0 vs 306: mean=-0.151, max=0.006\n",
      "0 vs 307: mean=-0.049, max=0.129\n",
      "0 vs 308: mean=-0.144, max=0.039\n",
      "0 vs 309: mean=-0.047, max=0.080\n",
      "0 vs 310: mean=-0.113, max=0.003\n",
      "0 vs 311: mean=-0.085, max=0.020\n",
      "0 vs 312: mean=-0.078, max=0.098\n",
      "0 vs 313: mean=-0.032, max=0.067\n",
      "0 vs 314: mean=-0.009, max=0.112\n",
      "0 vs 315: mean=-0.032, max=0.083\n",
      "0 vs 316: mean=-0.083, max=-0.000\n",
      "0 vs 317: mean=-0.112, max=-0.024\n",
      "0 vs 318: mean=-0.059, max=0.071\n",
      "0 vs 319: mean=-0.018, max=0.088\n",
      "0 vs 320: mean=-0.020, max=0.053\n",
      "0 vs 321: mean=-0.010, max=0.097\n",
      "0 vs 322: mean=-0.084, max=0.088\n",
      "0 vs 323: mean=0.038, max=0.153\n",
      "0 vs 324: mean=0.020, max=0.180\n",
      "0 vs 325: mean=0.083, max=0.281\n",
      "0 vs 326: mean=-0.070, max=0.062\n",
      "0 vs 327: mean=-0.039, max=0.054\n",
      "0 vs 328: mean=0.098, max=0.261\n",
      "0 vs 329: mean=-0.034, max=0.055\n",
      "0 vs 330: mean=-0.097, max=-0.014\n",
      "0 vs 331: mean=-0.043, max=0.075\n",
      "0 vs 332: mean=-0.039, max=0.071\n",
      "0 vs 333: mean=0.118, max=0.310\n",
      "0 vs 334: mean=-0.090, max=0.101\n",
      "0 vs 335: mean=-0.108, max=0.017\n",
      "0 vs 336: mean=-0.043, max=0.063\n",
      "0 vs 337: mean=-0.015, max=0.203\n",
      "0 vs 338: mean=-0.043, max=0.023\n",
      "0 vs 339: mean=0.005, max=0.103\n",
      "0 vs 340: mean=-0.029, max=0.079\n",
      "0 vs 341: mean=-0.005, max=0.122\n",
      "0 vs 342: mean=0.009, max=0.137\n",
      "0 vs 343: mean=-0.030, max=0.095\n",
      "0 vs 344: mean=0.014, max=0.096\n",
      "0 vs 345: mean=0.009, max=0.121\n",
      "0 vs 346: mean=0.031, max=0.115\n",
      "0 vs 347: mean=-0.056, max=0.067\n",
      "0 vs 348: mean=0.091, max=0.218\n",
      "0 vs 349: mean=0.075, max=0.154\n",
      "0 vs 350: mean=0.137, max=0.247\n",
      "0 vs 351: mean=-0.051, max=0.052\n",
      "0 vs 352: mean=-0.015, max=0.147\n",
      "0 vs 353: mean=0.088, max=0.238\n",
      "0 vs 354: mean=-0.004, max=0.149\n",
      "0 vs 355: mean=0.038, max=0.129\n",
      "0 vs 356: mean=-0.010, max=0.116\n",
      "0 vs 357: mean=-0.061, max=0.023\n",
      "0 vs 358: mean=-0.015, max=0.092\n",
      "0 vs 359: mean=0.047, max=0.221\n",
      "0 vs 360: mean=-0.044, max=0.074\n",
      "0 vs 361: mean=-0.054, max=0.070\n",
      "0 vs 362: mean=0.024, max=0.119\n",
      "0 vs 363: mean=-0.004, max=0.178\n",
      "0 vs 364: mean=0.074, max=0.214\n",
      "0 vs 365: mean=0.121, max=0.211\n",
      "0 vs 366: mean=0.087, max=0.189\n",
      "0 vs 367: mean=-0.038, max=0.100\n",
      "0 vs 368: mean=-0.007, max=0.091\n",
      "0 vs 369: mean=-0.027, max=0.076\n",
      "0 vs 370: mean=-0.077, max=0.185\n",
      "0 vs 371: mean=-0.017, max=0.176\n",
      "0 vs 372: mean=0.018, max=0.266\n",
      "0 vs 373: mean=-0.081, max=0.103\n",
      "0 vs 374: mean=-0.042, max=0.187\n",
      "0 vs 375: mean=0.059, max=0.282\n",
      "0 vs 376: mean=0.021, max=0.335\n",
      "0 vs 377: mean=-0.079, max=0.266\n",
      "0 vs 378: mean=0.012, max=0.257\n",
      "0 vs 379: mean=-0.085, max=0.105\n",
      "0 vs 380: mean=-0.092, max=0.032\n",
      "0 vs 381: mean=0.007, max=0.117\n",
      "0 vs 382: mean=0.033, max=0.167\n",
      "0 vs 383: mean=0.045, max=0.231\n",
      "0 vs 384: mean=-0.103, max=0.032\n",
      "0 vs 385: mean=-0.139, max=0.044\n",
      "0 vs 386: mean=-0.044, max=0.110\n",
      "0 vs 387: mean=-0.100, max=0.042\n",
      "0 vs 388: mean=-0.058, max=0.087\n",
      "0 vs 389: mean=-0.034, max=0.131\n",
      "0 vs 390: mean=-0.011, max=0.121\n",
      "0 vs 391: mean=0.043, max=0.185\n",
      "0 vs 392: mean=-0.151, max=-0.030\n",
      "0 vs 393: mean=-0.116, max=0.007\n",
      "0 vs 394: mean=-0.081, max=0.016\n",
      "0 vs 395: mean=-0.202, max=-0.067\n",
      "0 vs 396: mean=-0.026, max=0.113\n",
      "0 vs 397: mean=-0.003, max=0.150\n",
      "0 vs 398: mean=-0.067, max=0.044\n",
      "0 vs 399: mean=-0.042, max=0.109\n",
      "0 vs 400: mean=0.000, max=0.122\n",
      "0 vs 401: mean=0.012, max=0.112\n",
      "0 vs 402: mean=0.023, max=0.164\n",
      "0 vs 403: mean=-0.078, max=0.027\n",
      "0 vs 404: mean=-0.104, max=-0.011\n",
      "0 vs 405: mean=0.043, max=0.238\n",
      "0 vs 406: mean=0.073, max=0.227\n",
      "0 vs 407: mean=-0.069, max=0.065\n",
      "0 vs 408: mean=0.003, max=0.108\n",
      "0 vs 409: mean=-0.037, max=0.088\n",
      "0 vs 410: mean=-0.079, max=0.032\n",
      "0 vs 411: mean=-0.080, max=0.020\n",
      "0 vs 412: mean=0.033, max=0.117\n",
      "0 vs 413: mean=-0.072, max=0.056\n",
      "0 vs 414: mean=-0.080, max=0.061\n",
      "0 vs 415: mean=-0.046, max=0.081\n",
      "0 vs 416: mean=-0.017, max=0.088\n",
      "0 vs 417: mean=-0.067, max=0.023\n",
      "0 vs 418: mean=0.062, max=0.137\n",
      "0 vs 419: mean=-0.054, max=0.084\n",
      "0 vs 420: mean=-0.002, max=0.077\n",
      "0 vs 421: mean=-0.006, max=0.073\n",
      "0 vs 422: mean=-0.003, max=0.107\n",
      "0 vs 423: mean=0.011, max=0.132\n",
      "0 vs 424: mean=-0.015, max=0.117\n",
      "0 vs 425: mean=0.102, max=0.224\n",
      "0 vs 426: mean=0.020, max=0.137\n",
      "0 vs 427: mean=-0.047, max=0.062\n",
      "0 vs 428: mean=0.060, max=0.200\n",
      "0 vs 429: mean=0.124, max=0.239\n",
      "0 vs 430: mean=0.059, max=0.239\n",
      "0 vs 431: mean=0.002, max=0.171\n",
      "0 vs 432: mean=-0.034, max=0.119\n",
      "0 vs 433: mean=-0.021, max=0.092\n",
      "0 vs 434: mean=-0.008, max=0.082\n",
      "0 vs 435: mean=-0.037, max=0.062\n",
      "0 vs 436: mean=0.019, max=0.108\n",
      "0 vs 437: mean=-0.068, max=0.034\n",
      "0 vs 438: mean=-0.010, max=0.080\n",
      "0 vs 439: mean=0.056, max=0.154\n",
      "0 vs 440: mean=-0.011, max=0.076\n",
      "0 vs 441: mean=0.038, max=0.164\n",
      "0 vs 442: mean=-0.004, max=0.124\n",
      "0 vs 443: mean=-0.055, max=0.056\n",
      "0 vs 444: mean=-0.001, max=0.081\n",
      "0 vs 445: mean=0.017, max=0.120\n",
      "0 vs 446: mean=0.158, max=0.249\n",
      "0 vs 447: mean=0.060, max=0.150\n",
      "0 vs 448: mean=-0.005, max=0.144\n",
      "0 vs 449: mean=0.122, max=0.216\n",
      "0 vs 450: mean=0.020, max=0.167\n",
      "0 vs 451: mean=0.137, max=0.271\n",
      "0 vs 452: mean=-0.062, max=0.029\n",
      "0 vs 453: mean=0.046, max=0.162\n",
      "0 vs 454: mean=-0.060, max=0.064\n",
      "0 vs 455: mean=0.105, max=0.245\n",
      "0 vs 456: mean=-0.023, max=0.135\n",
      "0 vs 457: mean=0.007, max=0.097\n",
      "0 vs 458: mean=0.018, max=0.095\n",
      "0 vs 459: mean=-0.017, max=0.084\n",
      "0 vs 460: mean=0.038, max=0.241\n",
      "0 vs 461: mean=-0.023, max=0.147\n",
      "0 vs 462: mean=-0.155, max=-0.026\n",
      "0 vs 463: mean=-0.089, max=-0.002\n",
      "0 vs 464: mean=-0.156, max=-0.022\n",
      "0 vs 465: mean=-0.133, max=0.020\n",
      "0 vs 466: mean=-0.031, max=0.112\n",
      "0 vs 467: mean=0.003, max=0.171\n",
      "0 vs 468: mean=-0.065, max=0.097\n",
      "0 vs 469: mean=-0.150, max=-0.024\n",
      "0 vs 470: mean=0.102, max=0.211\n",
      "0 vs 471: mean=-0.034, max=0.046\n",
      "0 vs 472: mean=0.035, max=0.153\n",
      "0 vs 473: mean=-0.039, max=0.030\n",
      "0 vs 474: mean=0.071, max=0.155\n",
      "0 vs 475: mean=0.081, max=0.164\n",
      "0 vs 476: mean=0.025, max=0.122\n",
      "0 vs 477: mean=0.015, max=0.094\n",
      "0 vs 478: mean=-0.026, max=0.111\n",
      "0 vs 479: mean=-0.034, max=0.026\n",
      "0 vs 480: mean=0.003, max=0.108\n",
      "0 vs 481: mean=0.031, max=0.139\n",
      "0 vs 482: mean=0.040, max=0.139\n",
      "0 vs 483: mean=0.075, max=0.204\n",
      "0 vs 484: mean=0.004, max=0.145\n",
      "0 vs 485: mean=-0.012, max=0.120\n",
      "0 vs 486: mean=0.092, max=0.216\n",
      "0 vs 487: mean=0.065, max=0.192\n",
      "0 vs 488: mean=0.014, max=0.117\n",
      "0 vs 489: mean=-0.005, max=0.082\n",
      "0 vs 490: mean=0.060, max=0.243\n",
      "0 vs 491: mean=0.109, max=0.228\n",
      "0 vs 492: mean=-0.021, max=0.107\n",
      "0 vs 493: mean=-0.022, max=0.093\n",
      "0 vs 494: mean=-0.020, max=0.103\n",
      "0 vs 495: mean=0.030, max=0.148\n",
      "0 vs 496: mean=-0.013, max=0.115\n",
      "0 vs 497: mean=-0.031, max=0.070\n",
      "0 vs 498: mean=-0.052, max=0.097\n",
      "0 vs 499: mean=-0.004, max=0.096\n",
      "0 vs 500: mean=-0.008, max=0.172\n",
      "0 vs 501: mean=-0.039, max=0.074\n",
      "0 vs 502: mean=-0.032, max=0.088\n",
      "0 vs 503: mean=0.019, max=0.123\n",
      "0 vs 504: mean=-0.005, max=0.134\n",
      "0 vs 505: mean=0.008, max=0.107\n",
      "0 vs 506: mean=-0.004, max=0.135\n",
      "0 vs 507: mean=0.050, max=0.137\n",
      "0 vs 508: mean=-0.046, max=0.125\n",
      "0 vs 509: mean=-0.025, max=0.063\n",
      "0 vs 510: mean=0.121, max=0.244\n",
      "0 vs 511: mean=-0.020, max=0.163\n",
      "0 vs 512: mean=0.029, max=0.144\n",
      "0 vs 513: mean=0.083, max=0.222\n",
      "0 vs 514: mean=-0.035, max=0.062\n",
      "0 vs 515: mean=-0.032, max=0.107\n",
      "0 vs 516: mean=0.049, max=0.215\n",
      "0 vs 517: mean=0.057, max=0.198\n",
      "0 vs 518: mean=0.057, max=0.148\n",
      "0 vs 519: mean=0.095, max=0.222\n",
      "0 vs 520: mean=-0.002, max=0.099\n",
      "0 vs 521: mean=0.033, max=0.121\n",
      "0 vs 522: mean=-0.094, max=0.000\n",
      "0 vs 523: mean=0.018, max=0.198\n",
      "0 vs 524: mean=-0.038, max=0.093\n",
      "0 vs 525: mean=0.002, max=0.143\n",
      "0 vs 526: mean=-0.023, max=0.130\n",
      "0 vs 527: mean=0.075, max=0.219\n",
      "0 vs 528: mean=-0.066, max=0.123\n",
      "0 vs 529: mean=0.042, max=0.199\n",
      "0 vs 530: mean=0.016, max=0.116\n",
      "0 vs 531: mean=-0.028, max=0.131\n",
      "0 vs 532: mean=-0.007, max=0.127\n",
      "0 vs 533: mean=-0.089, max=-0.006\n",
      "0 vs 534: mean=-0.012, max=0.111\n",
      "0 vs 535: mean=-0.005, max=0.133\n",
      "0 vs 536: mean=-0.004, max=0.128\n",
      "0 vs 537: mean=0.043, max=0.127\n",
      "0 vs 538: mean=0.068, max=0.208\n",
      "0 vs 539: mean=-0.012, max=0.106\n",
      "0 vs 540: mean=0.075, max=0.223\n",
      "0 vs 541: mean=0.122, max=0.214\n",
      "0 vs 542: mean=-0.016, max=0.110\n",
      "0 vs 543: mean=0.077, max=0.165\n",
      "0 vs 544: mean=-0.011, max=0.121\n",
      "0 vs 545: mean=-0.002, max=0.129\n",
      "0 vs 546: mean=0.048, max=0.154\n",
      "0 vs 547: mean=0.132, max=0.212\n",
      "0 vs 548: mean=0.049, max=0.194\n",
      "0 vs 549: mean=0.145, max=0.247\n",
      "0 vs 550: mean=0.001, max=0.159\n",
      "0 vs 551: mean=-0.012, max=0.166\n",
      "0 vs 552: mean=0.011, max=0.165\n",
      "0 vs 553: mean=-0.011, max=0.125\n",
      "0 vs 554: mean=-0.019, max=0.080\n",
      "0 vs 555: mean=-0.046, max=0.096\n",
      "0 vs 556: mean=0.013, max=0.163\n",
      "0 vs 557: mean=0.002, max=0.202\n",
      "0 vs 558: mean=0.050, max=0.181\n",
      "0 vs 559: mean=-0.042, max=0.087\n",
      "0 vs 560: mean=0.004, max=0.129\n",
      "0 vs 561: mean=-0.017, max=0.129\n",
      "0 vs 562: mean=-0.019, max=0.086\n",
      "0 vs 563: mean=-0.036, max=0.077\n",
      "0 vs 564: mean=0.022, max=0.191\n",
      "0 vs 565: mean=-0.092, max=0.026\n",
      "0 vs 566: mean=-0.039, max=0.157\n",
      "0 vs 567: mean=-0.004, max=0.112\n",
      "0 vs 568: mean=0.077, max=0.201\n",
      "0 vs 569: mean=-0.024, max=0.090\n",
      "0 vs 570: mean=0.016, max=0.121\n",
      "0 vs 571: mean=0.010, max=0.129\n",
      "0 vs 572: mean=0.024, max=0.137\n",
      "0 vs 573: mean=0.024, max=0.135\n",
      "0 vs 574: mean=-0.041, max=0.126\n",
      "0 vs 575: mean=-0.001, max=0.095\n",
      "0 vs 576: mean=-0.098, max=0.037\n",
      "0 vs 577: mean=0.017, max=0.154\n",
      "0 vs 578: mean=-0.025, max=0.110\n",
      "0 vs 579: mean=-0.010, max=0.123\n",
      "0 vs 580: mean=-0.050, max=0.072\n",
      "0 vs 581: mean=0.014, max=0.166\n",
      "0 vs 582: mean=-0.009, max=0.116\n",
      "0 vs 583: mean=-0.026, max=0.159\n",
      "0 vs 584: mean=-0.010, max=0.094\n",
      "0 vs 585: mean=0.040, max=0.191\n",
      "0 vs 586: mean=-0.013, max=0.078\n",
      "0 vs 587: mean=-0.079, max=0.015\n",
      "0 vs 588: mean=-0.046, max=0.120\n",
      "0 vs 589: mean=-0.103, max=0.024\n",
      "0 vs 590: mean=0.013, max=0.122\n",
      "0 vs 591: mean=-0.027, max=0.155\n",
      "0 vs 592: mean=0.032, max=0.195\n",
      "0 vs 593: mean=0.004, max=0.114\n",
      "0 vs 594: mean=-0.047, max=0.067\n",
      "0 vs 595: mean=-0.009, max=0.151\n",
      "0 vs 596: mean=0.069, max=0.199\n",
      "0 vs 597: mean=0.055, max=0.197\n",
      "0 vs 598: mean=-0.024, max=0.105\n",
      "0 vs 599: mean=0.098, max=0.225\n",
      "0 vs 600: mean=-0.066, max=0.062\n",
      "0 vs 601: mean=0.014, max=0.122\n",
      "0 vs 602: mean=0.013, max=0.156\n",
      "0 vs 603: mean=0.037, max=0.118\n",
      "0 vs 604: mean=0.015, max=0.109\n",
      "0 vs 605: mean=-0.002, max=0.106\n",
      "0 vs 606: mean=0.096, max=0.217\n",
      "0 vs 607: mean=0.033, max=0.121\n",
      "0 vs 608: mean=-0.006, max=0.081\n",
      "0 vs 609: mean=0.015, max=0.144\n",
      "0 vs 610: mean=0.020, max=0.134\n",
      "0 vs 611: mean=0.082, max=0.172\n",
      "0 vs 612: mean=0.028, max=0.169\n",
      "0 vs 613: mean=0.050, max=0.153\n",
      "0 vs 614: mean=0.027, max=0.104\n",
      "0 vs 615: mean=0.105, max=0.260\n",
      "0 vs 616: mean=0.054, max=0.138\n",
      "0 vs 617: mean=0.010, max=0.153\n",
      "0 vs 618: mean=0.091, max=0.235\n",
      "0 vs 619: mean=-0.030, max=0.148\n",
      "0 vs 620: mean=-0.044, max=0.088\n",
      "0 vs 621: mean=0.046, max=0.174\n",
      "0 vs 622: mean=0.042, max=0.199\n",
      "0 vs 624: mean=0.059, max=0.193\n",
      "0 vs 625: mean=0.011, max=0.135\n",
      "0 vs 626: mean=0.096, max=0.198\n",
      "0 vs 627: mean=-0.014, max=0.080\n",
      "0 vs 628: mean=0.046, max=0.185\n",
      "0 vs 629: mean=-0.010, max=0.059\n",
      "0 vs 630: mean=0.013, max=0.170\n",
      "0 vs 631: mean=-0.006, max=0.153\n",
      "0 vs 632: mean=0.013, max=0.126\n",
      "0 vs 633: mean=0.034, max=0.152\n",
      "0 vs 634: mean=0.044, max=0.125\n",
      "0 vs 635: mean=0.012, max=0.124\n",
      "0 vs 636: mean=-0.032, max=0.073\n",
      "0 vs 637: mean=0.029, max=0.139\n",
      "0 vs 638: mean=0.052, max=0.191\n",
      "0 vs 639: mean=0.068, max=0.212\n",
      "0 vs 640: mean=0.023, max=0.087\n",
      "0 vs 641: mean=0.028, max=0.126\n",
      "0 vs 642: mean=0.049, max=0.148\n",
      "0 vs 643: mean=-0.002, max=0.173\n",
      "0 vs 644: mean=0.026, max=0.118\n",
      "0 vs 645: mean=0.037, max=0.194\n",
      "0 vs 646: mean=-0.008, max=0.175\n",
      "0 vs 647: mean=0.033, max=0.155\n",
      "0 vs 648: mean=-0.013, max=0.077\n",
      "0 vs 649: mean=0.065, max=0.195\n",
      "0 vs 650: mean=-0.046, max=0.083\n",
      "0 vs 651: mean=0.067, max=0.142\n",
      "0 vs 652: mean=-0.016, max=0.124\n",
      "0 vs 653: mean=-0.000, max=0.106\n",
      "0 vs 654: mean=-0.015, max=0.098\n",
      "0 vs 655: mean=-0.004, max=0.104\n",
      "0 vs 656: mean=-0.029, max=0.109\n",
      "0 vs 657: mean=-0.051, max=0.094\n",
      "0 vs 658: mean=-0.083, max=0.006\n",
      "0 vs 659: mean=0.031, max=0.162\n",
      "0 vs 660: mean=-0.065, max=0.054\n",
      "0 vs 661: mean=-0.005, max=0.136\n",
      "0 vs 662: mean=0.049, max=0.131\n",
      "0 vs 663: mean=0.060, max=0.179\n",
      "0 vs 664: mean=0.078, max=0.167\n",
      "0 vs 665: mean=0.038, max=0.231\n",
      "0 vs 666: mean=0.039, max=0.140\n",
      "0 vs 667: mean=0.004, max=0.109\n",
      "0 vs 668: mean=0.026, max=0.139\n",
      "0 vs 669: mean=-0.041, max=0.115\n",
      "0 vs 670: mean=0.020, max=0.162\n",
      "0 vs 671: mean=-0.047, max=0.126\n",
      "0 vs 672: mean=-0.079, max=0.029\n",
      "0 vs 673: mean=0.054, max=0.198\n",
      "0 vs 674: mean=-0.033, max=0.099\n",
      "0 vs 675: mean=0.010, max=0.183\n",
      "0 vs 676: mean=-0.039, max=0.106\n",
      "0 vs 677: mean=-0.005, max=0.127\n",
      "0 vs 678: mean=0.023, max=0.179\n",
      "0 vs 679: mean=-0.002, max=0.153\n",
      "0 vs 680: mean=-0.030, max=0.083\n",
      "0 vs 681: mean=-0.096, max=0.038\n",
      "0 vs 682: mean=-0.055, max=0.049\n",
      "0 vs 683: mean=0.043, max=0.140\n",
      "0 vs 684: mean=0.113, max=0.228\n",
      "0 vs 685: mean=0.063, max=0.221\n",
      "0 vs 686: mean=-0.131, max=-0.000\n",
      "0 vs 687: mean=0.056, max=0.143\n",
      "0 vs 688: mean=0.031, max=0.187\n",
      "0 vs 689: mean=-0.024, max=0.131\n",
      "0 vs 690: mean=0.090, max=0.202\n",
      "0 vs 691: mean=0.074, max=0.194\n",
      "0 vs 692: mean=0.117, max=0.241\n",
      "0 vs 693: mean=0.014, max=0.083\n",
      "0 vs 694: mean=0.035, max=0.122\n",
      "0 vs 695: mean=-0.014, max=0.081\n",
      "0 vs 696: mean=0.069, max=0.134\n",
      "0 vs 697: mean=0.096, max=0.195\n",
      "0 vs 698: mean=0.126, max=0.231\n",
      "0 vs 699: mean=-0.004, max=0.099\n",
      "0 vs 700: mean=-0.062, max=0.089\n",
      "0 vs 701: mean=0.096, max=0.221\n",
      "0 vs 702: mean=0.184, max=0.287\n",
      "0 vs 703: mean=-0.025, max=0.078\n",
      "0 vs 704: mean=0.048, max=0.162\n",
      "0 vs 705: mean=-0.009, max=0.167\n",
      "0 vs 706: mean=0.086, max=0.227\n",
      "0 vs 707: mean=0.072, max=0.217\n",
      "0 vs 708: mean=0.042, max=0.145\n",
      "0 vs 709: mean=0.026, max=0.139\n",
      "0 vs 710: mean=0.056, max=0.174\n",
      "0 vs 711: mean=0.088, max=0.178\n",
      "0 vs 712: mean=-0.026, max=0.071\n",
      "0 vs 713: mean=-0.010, max=0.127\n",
      "0 vs 714: mean=0.069, max=0.152\n",
      "0 vs 715: mean=0.092, max=0.237\n",
      "0 vs 716: mean=0.053, max=0.182\n",
      "0 vs 717: mean=0.083, max=0.245\n",
      "0 vs 718: mean=0.065, max=0.205\n",
      "0 vs 719: mean=0.037, max=0.154\n",
      "0 vs 720: mean=0.002, max=0.105\n",
      "0 vs 721: mean=0.046, max=0.118\n",
      "0 vs 722: mean=0.035, max=0.139\n",
      "0 vs 723: mean=-0.011, max=0.114\n",
      "0 vs 724: mean=0.075, max=0.271\n",
      "0 vs 725: mean=0.034, max=0.120\n",
      "0 vs 726: mean=0.091, max=0.213\n",
      "0 vs 727: mean=0.022, max=0.170\n",
      "0 vs 728: mean=0.125, max=0.255\n",
      "0 vs 729: mean=0.115, max=0.240\n",
      "0 vs 730: mean=0.042, max=0.192\n",
      "0 vs 731: mean=0.104, max=0.203\n",
      "0 vs 732: mean=0.065, max=0.144\n",
      "0 vs 733: mean=0.058, max=0.168\n",
      "0 vs 734: mean=0.012, max=0.108\n",
      "0 vs 735: mean=0.009, max=0.129\n",
      "0 vs 736: mean=0.054, max=0.182\n",
      "0 vs 737: mean=-0.060, max=0.052\n",
      "0 vs 738: mean=0.088, max=0.235\n",
      "0 vs 739: mean=0.118, max=0.223\n",
      "0 vs 740: mean=-0.002, max=0.168\n",
      "0 vs 741: mean=0.003, max=0.114\n",
      "0 vs 742: mean=-0.038, max=0.156\n",
      "0 vs 743: mean=0.120, max=0.255\n",
      "0 vs 744: mean=0.048, max=0.139\n",
      "0 vs 745: mean=0.076, max=0.248\n",
      "0 vs 746: mean=0.138, max=0.227\n",
      "0 vs 747: mean=0.044, max=0.170\n",
      "0 vs 748: mean=0.082, max=0.179\n",
      "0 vs 749: mean=0.054, max=0.178\n",
      "0 vs 750: mean=0.123, max=0.249\n",
      "0 vs 751: mean=0.038, max=0.143\n",
      "0 vs 752: mean=0.185, max=0.281\n",
      "0 vs 753: mean=0.062, max=0.170\n",
      "0 vs 754: mean=0.127, max=0.240\n",
      "0 vs 755: mean=0.060, max=0.192\n",
      "0 vs 756: mean=0.064, max=0.210\n",
      "0 vs 757: mean=0.033, max=0.192\n",
      "0 vs 758: mean=0.104, max=0.207\n",
      "0 vs 759: mean=0.023, max=0.118\n",
      "0 vs 760: mean=0.117, max=0.195\n",
      "0 vs 761: mean=0.095, max=0.193\n",
      "0 vs 762: mean=0.148, max=0.249\n",
      "0 vs 763: mean=0.083, max=0.199\n",
      "0 vs 764: mean=0.167, max=0.320\n",
      "0 vs 765: mean=0.097, max=0.220\n",
      "0 vs 766: mean=0.158, max=0.286\n",
      "0 vs 767: mean=0.032, max=0.113\n",
      "0 vs 768: mean=0.094, max=0.217\n",
      "0 vs 769: mean=0.114, max=0.223\n",
      "0 vs 770: mean=0.079, max=0.177\n",
      "0 vs 771: mean=0.084, max=0.231\n",
      "0 vs 772: mean=-0.027, max=0.102\n",
      "0 vs 773: mean=0.084, max=0.202\n",
      "0 vs 774: mean=0.069, max=0.152\n",
      "0 vs 775: mean=0.039, max=0.156\n",
      "0 vs 776: mean=0.119, max=0.211\n",
      "0 vs 777: mean=-0.002, max=0.081\n",
      "0 vs 778: mean=0.128, max=0.243\n",
      "0 vs 779: mean=0.066, max=0.163\n",
      "0 vs 780: mean=0.055, max=0.187\n",
      "0 vs 781: mean=0.088, max=0.172\n",
      "0 vs 782: mean=0.011, max=0.112\n",
      "0 vs 783: mean=0.065, max=0.151\n",
      "0 vs 784: mean=-0.012, max=0.082\n",
      "0 vs 785: mean=0.054, max=0.204\n",
      "0 vs 786: mean=0.072, max=0.235\n",
      "0 vs 787: mean=0.040, max=0.163\n",
      "0 vs 788: mean=0.060, max=0.190\n",
      "0 vs 789: mean=0.095, max=0.216\n",
      "0 vs 790: mean=-0.008, max=0.072\n",
      "0 vs 791: mean=0.020, max=0.127\n",
      "0 vs 792: mean=0.100, max=0.197\n",
      "0 vs 793: mean=0.015, max=0.140\n",
      "0 vs 794: mean=0.078, max=0.212\n",
      "0 vs 795: mean=0.080, max=0.210\n",
      "0 vs 796: mean=-0.009, max=0.084\n",
      "0 vs 797: mean=0.106, max=0.265\n",
      "0 vs 798: mean=0.202, max=0.329\n",
      "0 vs 799: mean=0.205, max=0.293\n",
      "0 vs 800: mean=0.030, max=0.146\n",
      "0 vs 801: mean=0.101, max=0.199\n",
      "0 vs 802: mean=0.043, max=0.145\n",
      "0 vs 803: mean=0.051, max=0.122\n",
      "0 vs 804: mean=0.071, max=0.179\n",
      "0 vs 805: mean=0.032, max=0.123\n",
      "0 vs 806: mean=0.059, max=0.179\n",
      "0 vs 807: mean=0.027, max=0.123\n",
      "0 vs 808: mean=0.094, max=0.209\n",
      "0 vs 809: mean=0.035, max=0.120\n",
      "0 vs 810: mean=0.038, max=0.146\n",
      "0 vs 811: mean=0.050, max=0.169\n",
      "0 vs 812: mean=0.017, max=0.115\n",
      "0 vs 813: mean=-0.023, max=0.071\n",
      "0 vs 814: mean=0.017, max=0.103\n",
      "0 vs 815: mean=0.076, max=0.176\n",
      "0 vs 816: mean=0.092, max=0.215\n",
      "0 vs 817: mean=-0.006, max=0.088\n",
      "0 vs 818: mean=0.038, max=0.128\n",
      "0 vs 819: mean=0.048, max=0.127\n",
      "0 vs 820: mean=0.122, max=0.254\n",
      "0 vs 821: mean=0.059, max=0.181\n",
      "0 vs 822: mean=0.029, max=0.166\n",
      "0 vs 823: mean=0.072, max=0.164\n",
      "0 vs 824: mean=0.066, max=0.196\n",
      "0 vs 825: mean=0.017, max=0.179\n",
      "0 vs 826: mean=-0.152, max=-0.041\n",
      "0 vs 827: mean=0.030, max=0.152\n",
      "0 vs 828: mean=0.063, max=0.153\n",
      "0 vs 829: mean=0.054, max=0.141\n",
      "0 vs 830: mean=0.118, max=0.256\n",
      "0 vs 831: mean=0.065, max=0.215\n",
      "0 vs 832: mean=0.060, max=0.195\n",
      "0 vs 833: mean=0.091, max=0.174\n",
      "0 vs 834: mean=0.063, max=0.158\n",
      "0 vs 835: mean=0.085, max=0.221\n",
      "0 vs 836: mean=0.054, max=0.173\n",
      "0 vs 837: mean=0.031, max=0.128\n",
      "0 vs 838: mean=0.212, max=0.364\n",
      "0 vs 839: mean=0.081, max=0.208\n",
      "0 vs 840: mean=0.093, max=0.247\n",
      "0 vs 841: mean=0.008, max=0.102\n",
      "0 vs 842: mean=0.070, max=0.257\n",
      "0 vs 843: mean=-0.045, max=0.024\n",
      "0 vs 844: mean=0.055, max=0.218\n",
      "0 vs 845: mean=0.093, max=0.207\n",
      "0 vs 846: mean=-0.011, max=0.107\n",
      "0 vs 847: mean=0.184, max=0.289\n",
      "0 vs 848: mean=0.081, max=0.154\n",
      "0 vs 849: mean=0.181, max=0.266\n",
      "0 vs 850: mean=0.134, max=0.264\n",
      "0 vs 851: mean=0.129, max=0.223\n",
      "0 vs 852: mean=0.072, max=0.182\n",
      "0 vs 853: mean=0.089, max=0.189\n",
      "0 vs 854: mean=0.102, max=0.185\n",
      "0 vs 855: mean=0.029, max=0.131\n",
      "0 vs 856: mean=0.106, max=0.218\n",
      "0 vs 857: mean=0.148, max=0.220\n",
      "0 vs 858: mean=0.023, max=0.122\n",
      "0 vs 859: mean=-0.061, max=0.046\n",
      "0 vs 860: mean=0.134, max=0.263\n",
      "0 vs 861: mean=0.064, max=0.141\n",
      "0 vs 862: mean=-0.014, max=0.068\n",
      "0 vs 863: mean=0.062, max=0.202\n",
      "0 vs 864: mean=-0.013, max=0.061\n",
      "0 vs 865: mean=0.066, max=0.163\n",
      "0 vs 866: mean=0.075, max=0.155\n",
      "0 vs 867: mean=0.114, max=0.189\n",
      "0 vs 868: mean=0.087, max=0.193\n",
      "0 vs 869: mean=0.040, max=0.134\n",
      "0 vs 870: mean=0.083, max=0.212\n",
      "0 vs 871: mean=0.072, max=0.170\n",
      "0 vs 872: mean=0.179, max=0.270\n",
      "0 vs 873: mean=0.093, max=0.187\n",
      "0 vs 874: mean=0.113, max=0.208\n",
      "0 vs 875: mean=0.047, max=0.139\n",
      "0 vs 876: mean=0.052, max=0.140\n",
      "0 vs 877: mean=0.076, max=0.189\n",
      "0 vs 878: mean=0.080, max=0.161\n",
      "0 vs 879: mean=0.096, max=0.164\n",
      "0 vs 880: mean=0.036, max=0.135\n",
      "0 vs 881: mean=0.035, max=0.126\n",
      "0 vs 882: mean=0.037, max=0.124\n",
      "0 vs 883: mean=0.078, max=0.202\n",
      "0 vs 884: mean=0.015, max=0.145\n",
      "0 vs 885: mean=-0.068, max=0.030\n",
      "0 vs 886: mean=-0.009, max=0.073\n",
      "0 vs 887: mean=0.051, max=0.178\n",
      "0 vs 888: mean=0.096, max=0.210\n",
      "0 vs 889: mean=0.048, max=0.148\n",
      "0 vs 890: mean=0.062, max=0.146\n",
      "0 vs 891: mean=0.189, max=0.343\n",
      "0 vs 892: mean=0.070, max=0.139\n",
      "0 vs 893: mean=0.009, max=0.122\n",
      "0 vs 894: mean=0.094, max=0.174\n",
      "0 vs 895: mean=0.013, max=0.081\n",
      "0 vs 896: mean=0.051, max=0.134\n",
      "0 vs 897: mean=0.172, max=0.257\n",
      "0 vs 898: mean=-0.134, max=-0.020\n",
      "0 vs 899: mean=0.059, max=0.176\n",
      "0 vs 900: mean=0.031, max=0.141\n",
      "0 vs 901: mean=0.092, max=0.222\n",
      "0 vs 902: mean=0.069, max=0.195\n",
      "0 vs 903: mean=0.050, max=0.182\n",
      "0 vs 904: mean=0.107, max=0.193\n",
      "0 vs 905: mean=0.033, max=0.142\n",
      "0 vs 906: mean=0.137, max=0.270\n",
      "0 vs 907: mean=0.034, max=0.171\n",
      "0 vs 908: mean=0.014, max=0.122\n",
      "0 vs 909: mean=0.046, max=0.141\n",
      "0 vs 910: mean=0.147, max=0.200\n",
      "0 vs 911: mean=0.059, max=0.137\n",
      "0 vs 912: mean=-0.012, max=0.073\n",
      "0 vs 913: mean=0.108, max=0.194\n",
      "0 vs 914: mean=0.120, max=0.194\n",
      "0 vs 915: mean=0.120, max=0.226\n",
      "0 vs 916: mean=0.037, max=0.134\n",
      "0 vs 917: mean=0.092, max=0.188\n",
      "0 vs 918: mean=0.025, max=0.097\n",
      "0 vs 919: mean=0.065, max=0.151\n",
      "0 vs 920: mean=0.032, max=0.130\n",
      "0 vs 921: mean=0.034, max=0.139\n",
      "0 vs 922: mean=0.064, max=0.173\n",
      "0 vs 923: mean=0.121, max=0.227\n",
      "0 vs 924: mean=0.091, max=0.156\n",
      "0 vs 925: mean=-0.002, max=0.117\n",
      "0 vs 926: mean=0.084, max=0.211\n",
      "0 vs 927: mean=0.111, max=0.175\n",
      "0 vs 928: mean=0.065, max=0.223\n",
      "0 vs 929: mean=0.077, max=0.170\n",
      "0 vs 930: mean=0.106, max=0.205\n",
      "0 vs 931: mean=0.087, max=0.200\n",
      "0 vs 932: mean=0.085, max=0.174\n",
      "0 vs 933: mean=-0.007, max=0.070\n",
      "0 vs 934: mean=0.062, max=0.171\n",
      "0 vs 935: mean=-0.017, max=0.044\n",
      "0 vs 936: mean=0.138, max=0.252\n",
      "0 vs 937: mean=0.069, max=0.229\n",
      "0 vs 938: mean=0.056, max=0.143\n",
      "0 vs 939: mean=0.026, max=0.156\n",
      "0 vs 940: mean=0.065, max=0.146\n",
      "0 vs 941: mean=0.072, max=0.192\n",
      "0 vs 942: mean=0.046, max=0.109\n",
      "0 vs 943: mean=0.012, max=0.088\n",
      "0 vs 944: mean=0.114, max=0.211\n",
      "0 vs 945: mean=0.062, max=0.126\n",
      "0 vs 946: mean=0.139, max=0.219\n",
      "0 vs 947: mean=0.020, max=0.112\n",
      "0 vs 948: mean=0.172, max=0.278\n",
      "0 vs 949: mean=0.086, max=0.203\n",
      "0 vs 950: mean=-0.018, max=0.075\n",
      "0 vs 951: mean=0.080, max=0.206\n",
      "0 vs 952: mean=0.069, max=0.203\n",
      "0 vs 953: mean=0.000, max=0.097\n",
      "0 vs 954: mean=0.098, max=0.226\n",
      "0 vs 955: mean=0.177, max=0.287\n",
      "0 vs 956: mean=0.125, max=0.262\n",
      "0 vs 957: mean=0.010, max=0.126\n",
      "0 vs 958: mean=0.107, max=0.193\n",
      "0 vs 959: mean=0.053, max=0.179\n",
      "0 vs 960: mean=0.062, max=0.182\n",
      "0 vs 961: mean=0.003, max=0.126\n",
      "0 vs 962: mean=0.199, max=0.264\n",
      "0 vs 963: mean=0.041, max=0.131\n",
      "0 vs 964: mean=0.081, max=0.188\n",
      "0 vs 965: mean=0.047, max=0.151\n",
      "0 vs 966: mean=0.077, max=0.160\n",
      "0 vs 967: mean=0.089, max=0.194\n",
      "0 vs 968: mean=0.074, max=0.196\n",
      "0 vs 969: mean=0.038, max=0.168\n",
      "0 vs 970: mean=0.040, max=0.208\n",
      "0 vs 971: mean=-0.029, max=0.095\n",
      "0 vs 972: mean=0.020, max=0.144\n",
      "0 vs 973: mean=0.024, max=0.113\n",
      "0 vs 974: mean=0.039, max=0.150\n",
      "0 vs 975: mean=0.019, max=0.131\n",
      "0 vs 976: mean=0.024, max=0.124\n",
      "0 vs 977: mean=0.031, max=0.173\n",
      "0 vs 978: mean=0.100, max=0.202\n",
      "0 vs 979: mean=-0.051, max=0.069\n",
      "0 vs 980: mean=0.105, max=0.237\n",
      "0 vs 981: mean=0.073, max=0.195\n",
      "0 vs 982: mean=0.100, max=0.202\n",
      "0 vs 983: mean=0.079, max=0.215\n",
      "0 vs 984: mean=-0.061, max=0.134\n",
      "0 vs 985: mean=0.155, max=0.269\n",
      "0 vs 986: mean=0.018, max=0.078\n",
      "0 vs 987: mean=0.032, max=0.144\n",
      "0 vs 988: mean=0.056, max=0.156\n",
      "0 vs 989: mean=0.008, max=0.127\n",
      "0 vs 990: mean=0.117, max=0.226\n",
      "0 vs 991: mean=0.070, max=0.175\n",
      "0 vs 992: mean=0.141, max=0.277\n",
      "0 vs 993: mean=0.060, max=0.147\n",
      "0 vs 994: mean=0.050, max=0.167\n",
      "0 vs 995: mean=0.186, max=0.325\n",
      "0 vs 996: mean=0.131, max=0.226\n",
      "0 vs 997: mean=0.191, max=0.307\n",
      "0 vs 998: mean=0.007, max=0.102\n",
      "0 vs 999: mean=0.074, max=0.214\n",
      "0 vs 1000: mean=0.027, max=0.139\n",
      "0 vs 1001: mean=0.055, max=0.176\n",
      "0 vs 1002: mean=0.159, max=0.267\n",
      "0 vs 1003: mean=0.007, max=0.128\n",
      "0 vs 1004: mean=0.176, max=0.288\n",
      "0 vs 1005: mean=0.079, max=0.177\n",
      "0 vs 1006: mean=0.100, max=0.230\n",
      "0 vs 1007: mean=0.091, max=0.187\n",
      "0 vs 1008: mean=0.052, max=0.168\n",
      "0 vs 1009: mean=0.049, max=0.159\n",
      "0 vs 1010: mean=0.107, max=0.202\n",
      "0 vs 1011: mean=0.018, max=0.134\n",
      "0 vs 1012: mean=0.084, max=0.172\n",
      "0 vs 1013: mean=0.070, max=0.214\n",
      "0 vs 1014: mean=-0.000, max=0.065\n",
      "0 vs 1015: mean=0.026, max=0.149\n",
      "0 vs 1016: mean=0.092, max=0.184\n",
      "0 vs 1017: mean=-0.053, max=0.057\n",
      "0 vs 1018: mean=0.142, max=0.230\n",
      "0 vs 1019: mean=0.146, max=0.217\n",
      "0 vs 1020: mean=-0.040, max=0.084\n",
      "0 vs 1021: mean=0.067, max=0.153\n",
      "0 vs 1022: mean=0.021, max=0.122\n",
      "0 vs 1023: mean=-0.025, max=0.109\n",
      "0 vs 1024: mean=0.072, max=0.210\n",
      "0 vs 1025: mean=0.043, max=0.138\n",
      "0 vs 1026: mean=0.094, max=0.230\n",
      "0 vs 1027: mean=-0.025, max=0.052\n",
      "0 vs 1028: mean=-0.058, max=0.099\n",
      "0 vs 1029: mean=0.017, max=0.117\n",
      "0 vs 1030: mean=0.134, max=0.279\n",
      "0 vs 1031: mean=0.109, max=0.226\n",
      "0 vs 1032: mean=0.095, max=0.214\n",
      "0 vs 1033: mean=0.088, max=0.206\n",
      "0 vs 1034: mean=0.114, max=0.207\n",
      "0 vs 1035: mean=0.118, max=0.210\n",
      "0 vs 1036: mean=0.122, max=0.259\n",
      "0 vs 1037: mean=0.075, max=0.221\n",
      "0 vs 1038: mean=0.003, max=0.093\n",
      "0 vs 1039: mean=0.030, max=0.124\n",
      "0 vs 1040: mean=0.111, max=0.233\n",
      "0 vs 1041: mean=0.041, max=0.116\n",
      "0 vs 1042: mean=0.107, max=0.199\n",
      "0 vs 1043: mean=0.102, max=0.260\n",
      "0 vs 1044: mean=0.107, max=0.185\n",
      "0 vs 1045: mean=0.028, max=0.122\n",
      "0 vs 1046: mean=0.172, max=0.263\n",
      "0 vs 1047: mean=0.037, max=0.188\n",
      "0 vs 1048: mean=0.030, max=0.135\n",
      "0 vs 1049: mean=-0.007, max=0.096\n",
      "0 vs 1050: mean=0.016, max=0.133\n",
      "0 vs 1051: mean=0.080, max=0.275\n",
      "0 vs 1052: mean=-0.001, max=0.125\n",
      "0 vs 1053: mean=-0.010, max=0.079\n",
      "0 vs 1054: mean=0.038, max=0.163\n",
      "0 vs 1055: mean=-0.070, max=0.041\n",
      "0 vs 1056: mean=0.012, max=0.108\n",
      "0 vs 1057: mean=-0.042, max=0.073\n",
      "0 vs 1058: mean=-0.032, max=0.079\n",
      "0 vs 1059: mean=0.072, max=0.164\n",
      "0 vs 1060: mean=0.082, max=0.189\n",
      "0 vs 1061: mean=0.050, max=0.165\n",
      "0 vs 1062: mean=-0.010, max=0.128\n",
      "0 vs 1063: mean=-0.036, max=0.069\n",
      "0 vs 1064: mean=0.024, max=0.092\n",
      "0 vs 1065: mean=-0.038, max=0.110\n",
      "0 vs 1066: mean=-0.009, max=0.062\n",
      "0 vs 1067: mean=0.047, max=0.199\n",
      "0 vs 1068: mean=-0.003, max=0.077\n",
      "0 vs 1069: mean=0.039, max=0.125\n",
      "0 vs 1070: mean=-0.000, max=0.133\n",
      "0 vs 1071: mean=0.050, max=0.143\n",
      "0 vs 1072: mean=-0.014, max=0.159\n",
      "0 vs 1073: mean=-0.026, max=0.109\n",
      "0 vs 1074: mean=0.010, max=0.129\n",
      "0 vs 1075: mean=-0.052, max=0.085\n",
      "0 vs 1076: mean=0.041, max=0.165\n",
      "0 vs 1077: mean=0.018, max=0.147\n",
      "0 vs 1078: mean=-0.008, max=0.116\n",
      "0 vs 1079: mean=0.021, max=0.137\n",
      "0 vs 1080: mean=0.041, max=0.137\n",
      "0 vs 1081: mean=0.006, max=0.155\n",
      "0 vs 1082: mean=-0.056, max=0.043\n",
      "0 vs 1083: mean=0.030, max=0.183\n",
      "0 vs 1084: mean=0.077, max=0.201\n",
      "0 vs 1085: mean=-0.012, max=0.157\n",
      "0 vs 1086: mean=0.060, max=0.178\n",
      "0 vs 1087: mean=-0.046, max=0.050\n",
      "0 vs 1088: mean=-0.007, max=0.104\n",
      "0 vs 1089: mean=-0.028, max=0.060\n",
      "0 vs 1090: mean=0.013, max=0.123\n",
      "0 vs 1091: mean=-0.018, max=0.076\n",
      "0 vs 1092: mean=0.125, max=0.233\n",
      "0 vs 1093: mean=-0.053, max=0.101\n",
      "0 vs 1094: mean=-0.012, max=0.074\n",
      "0 vs 1095: mean=0.057, max=0.201\n",
      "0 vs 1096: mean=0.023, max=0.145\n",
      "0 vs 1097: mean=-0.018, max=0.124\n",
      "0 vs 1098: mean=0.035, max=0.170\n",
      "0 vs 1099: mean=-0.018, max=0.084\n",
      "0 vs 1100: mean=0.088, max=0.204\n",
      "0 vs 1101: mean=-0.026, max=0.071\n",
      "0 vs 1102: mean=0.078, max=0.178\n",
      "0 vs 1103: mean=-0.036, max=0.053\n",
      "0 vs 1104: mean=0.035, max=0.114\n",
      "0 vs 1105: mean=-0.008, max=0.086\n",
      "0 vs 1106: mean=0.084, max=0.175\n",
      "0 vs 1107: mean=0.046, max=0.181\n",
      "0 vs 1108: mean=0.042, max=0.130\n",
      "0 vs 1109: mean=0.048, max=0.147\n",
      "0 vs 1110: mean=0.011, max=0.128\n",
      "0 vs 1111: mean=-0.042, max=0.126\n",
      "0 vs 1112: mean=-0.050, max=0.048\n",
      "0 vs 1113: mean=-0.012, max=0.134\n",
      "0 vs 1114: mean=-0.133, max=0.058\n",
      "0 vs 1115: mean=-0.153, max=0.006\n",
      "0 vs 1116: mean=-0.169, max=-0.047\n",
      "0 vs 1117: mean=-0.044, max=0.109\n",
      "0 vs 1118: mean=-0.003, max=0.143\n",
      "0 vs 1119: mean=-0.109, max=0.025\n",
      "0 vs 1120: mean=-0.086, max=0.069\n",
      "0 vs 1121: mean=-0.066, max=0.040\n",
      "0 vs 1122: mean=-0.141, max=-0.020\n",
      "0 vs 1123: mean=-0.065, max=0.048\n",
      "0 vs 1124: mean=-0.081, max=0.081\n",
      "0 vs 1125: mean=-0.046, max=0.075\n",
      "0 vs 1126: mean=0.005, max=0.144\n",
      "0 vs 1127: mean=-0.098, max=0.068\n",
      "0 vs 1128: mean=-0.162, max=-0.018\n",
      "0 vs 1129: mean=-0.120, max=0.003\n",
      "0 vs 1130: mean=0.002, max=0.103\n",
      "0 vs 1131: mean=-0.096, max=-0.020\n",
      "0 vs 1132: mean=0.044, max=0.121\n",
      "0 vs 1133: mean=0.064, max=0.159\n",
      "0 vs 1134: mean=0.039, max=0.148\n",
      "0 vs 1135: mean=-0.039, max=0.062\n",
      "0 vs 1136: mean=0.031, max=0.170\n",
      "0 vs 1137: mean=0.010, max=0.092\n",
      "0 vs 1138: mean=0.040, max=0.176\n",
      "0 vs 1139: mean=-0.047, max=0.049\n",
      "0 vs 1140: mean=0.086, max=0.218\n",
      "0 vs 1141: mean=0.034, max=0.135\n",
      "0 vs 1142: mean=0.063, max=0.168\n",
      "0 vs 1143: mean=0.128, max=0.208\n",
      "0 vs 1144: mean=0.067, max=0.209\n",
      "0 vs 1145: mean=0.090, max=0.151\n",
      "0 vs 1146: mean=-0.012, max=0.085\n",
      "0 vs 1147: mean=0.060, max=0.136\n",
      "0 vs 1148: mean=-0.024, max=0.043\n",
      "0 vs 1149: mean=0.016, max=0.140\n",
      "0 vs 1150: mean=0.052, max=0.160\n",
      "0 vs 1151: mean=0.120, max=0.250\n",
      "0 vs 1152: mean=0.082, max=0.166\n",
      "0 vs 1153: mean=0.014, max=0.122\n",
      "0 vs 1154: mean=-0.039, max=0.118\n",
      "0 vs 1155: mean=0.015, max=0.085\n",
      "0 vs 1156: mean=-0.101, max=0.020\n",
      "0 vs 1157: mean=0.014, max=0.139\n",
      "0 vs 1158: mean=-0.025, max=0.071\n",
      "0 vs 1159: mean=-0.033, max=0.097\n",
      "0 vs 1160: mean=0.072, max=0.213\n",
      "0 vs 1161: mean=0.027, max=0.138\n",
      "0 vs 1162: mean=-0.026, max=0.064\n",
      "0 vs 1163: mean=-0.017, max=0.094\n",
      "0 vs 1164: mean=-0.002, max=0.126\n",
      "0 vs 1165: mean=-0.000, max=0.100\n",
      "0 vs 1166: mean=0.031, max=0.121\n",
      "0 vs 1167: mean=0.081, max=0.186\n",
      "0 vs 1168: mean=-0.027, max=0.083\n",
      "0 vs 1169: mean=0.039, max=0.147\n",
      "0 vs 1170: mean=-0.026, max=0.116\n",
      "0 vs 1171: mean=0.071, max=0.165\n",
      "0 vs 1172: mean=0.036, max=0.138\n",
      "0 vs 1173: mean=0.091, max=0.161\n",
      "0 vs 1174: mean=0.014, max=0.169\n",
      "0 vs 1175: mean=0.078, max=0.199\n",
      "0 vs 1176: mean=0.001, max=0.075\n",
      "0 vs 1177: mean=0.035, max=0.120\n",
      "0 vs 1178: mean=-0.018, max=0.073\n",
      "0 vs 1179: mean=0.033, max=0.146\n",
      "0 vs 1180: mean=0.086, max=0.209\n",
      "0 vs 1181: mean=0.058, max=0.142\n",
      "0 vs 1182: mean=0.058, max=0.173\n",
      "0 vs 1183: mean=0.003, max=0.144\n",
      "0 vs 1184: mean=0.044, max=0.137\n",
      "0 vs 1185: mean=-0.010, max=0.112\n",
      "0 vs 1186: mean=0.077, max=0.174\n",
      "0 vs 1187: mean=0.069, max=0.177\n",
      "0 vs 1188: mean=-0.024, max=0.091\n",
      "0 vs 1189: mean=0.003, max=0.125\n",
      "0 vs 1190: mean=0.011, max=0.136\n",
      "0 vs 1191: mean=0.073, max=0.234\n",
      "0 vs 1192: mean=0.067, max=0.141\n",
      "0 vs 1193: mean=0.017, max=0.130\n",
      "0 vs 1194: mean=0.001, max=0.124\n",
      "0 vs 1195: mean=0.059, max=0.151\n",
      "0 vs 1196: mean=0.070, max=0.146\n",
      "0 vs 1197: mean=-0.031, max=0.058\n",
      "0 vs 1198: mean=0.017, max=0.142\n",
      "0 vs 1199: mean=0.005, max=0.122\n",
      "0 vs 1200: mean=0.106, max=0.184\n",
      "0 vs 1201: mean=0.025, max=0.134\n",
      "0 vs 1202: mean=0.039, max=0.141\n",
      "0 vs 1203: mean=-0.063, max=0.011\n",
      "0 vs 1204: mean=0.051, max=0.144\n",
      "0 vs 1205: mean=0.070, max=0.177\n",
      "0 vs 1206: mean=0.045, max=0.146\n",
      "0 vs 1207: mean=0.030, max=0.147\n",
      "0 vs 1208: mean=0.039, max=0.125\n",
      "0 vs 1209: mean=0.039, max=0.120\n",
      "0 vs 1210: mean=-0.017, max=0.107\n",
      "0 vs 1211: mean=-0.025, max=0.060\n",
      "0 vs 1212: mean=-0.027, max=0.065\n",
      "0 vs 1213: mean=-0.040, max=0.091\n",
      "0 vs 1214: mean=0.031, max=0.136\n",
      "0 vs 1215: mean=-0.080, max=0.029\n",
      "0 vs 1216: mean=0.000, max=0.109\n",
      "0 vs 1217: mean=-0.026, max=0.104\n",
      "0 vs 1218: mean=0.025, max=0.149\n",
      "0 vs 1219: mean=0.005, max=0.128\n",
      "0 vs 1220: mean=0.069, max=0.181\n",
      "0 vs 1221: mean=-0.018, max=0.126\n",
      "0 vs 1222: mean=0.017, max=0.122\n",
      "0 vs 1223: mean=-0.022, max=0.093\n",
      "0 vs 1224: mean=0.035, max=0.165\n",
      "0 vs 1225: mean=0.054, max=0.205\n",
      "0 vs 1226: mean=-0.001, max=0.118\n",
      "0 vs 1227: mean=0.073, max=0.177\n",
      "0 vs 1228: mean=-0.007, max=0.138\n",
      "0 vs 1229: mean=-0.031, max=0.082\n",
      "0 vs 1230: mean=0.014, max=0.126\n",
      "0 vs 1231: mean=-0.022, max=0.059\n",
      "0 vs 1232: mean=0.115, max=0.287\n",
      "0 vs 1233: mean=-0.036, max=0.148\n",
      "0 vs 1234: mean=0.105, max=0.204\n",
      "0 vs 1235: mean=0.050, max=0.174\n",
      "0 vs 1236: mean=0.063, max=0.175\n",
      "0 vs 1237: mean=0.028, max=0.118\n",
      "0 vs 1238: mean=0.031, max=0.147\n",
      "0 vs 1239: mean=0.056, max=0.231\n",
      "0 vs 1240: mean=0.015, max=0.107\n",
      "0 vs 1241: mean=-0.028, max=0.123\n",
      "0 vs 1242: mean=0.067, max=0.167\n",
      "0 vs 1243: mean=0.102, max=0.195\n",
      "0 vs 1244: mean=0.088, max=0.233\n",
      "0 vs 1245: mean=-0.052, max=0.061\n",
      "0 vs 1246: mean=-0.013, max=0.062\n",
      "0 vs 1247: mean=-0.123, max=-0.021\n",
      "0 vs 1248: mean=-0.000, max=0.098\n",
      "0 vs 1249: mean=0.039, max=0.131\n",
      "0 vs 1250: mean=0.025, max=0.140\n",
      "0 vs 1251: mean=0.027, max=0.131\n",
      "0 vs 1252: mean=0.075, max=0.152\n",
      "0 vs 1253: mean=0.013, max=0.118\n",
      "0 vs 1254: mean=0.003, max=0.122\n",
      "0 vs 1255: mean=0.081, max=0.193\n",
      "0 vs 1256: mean=-0.024, max=0.040\n",
      "0 vs 1257: mean=0.069, max=0.200\n",
      "0 vs 1258: mean=0.039, max=0.116\n",
      "0 vs 1259: mean=0.016, max=0.112\n",
      "0 vs 1260: mean=0.015, max=0.129\n",
      "0 vs 1261: mean=0.032, max=0.154\n",
      "0 vs 1262: mean=0.030, max=0.119\n",
      "0 vs 1263: mean=0.038, max=0.113\n",
      "0 vs 1264: mean=0.044, max=0.166\n",
      "0 vs 1265: mean=0.077, max=0.179\n",
      "0 vs 1266: mean=0.061, max=0.151\n",
      "0 vs 1267: mean=0.037, max=0.161\n",
      "0 vs 1268: mean=-0.027, max=0.076\n",
      "0 vs 1269: mean=0.057, max=0.175\n",
      "0 vs 1270: mean=-0.025, max=0.076\n",
      "0 vs 1271: mean=0.090, max=0.200\n",
      "0 vs 1272: mean=-0.000, max=0.123\n",
      "0 vs 1273: mean=0.007, max=0.112\n",
      "0 vs 1274: mean=0.019, max=0.156\n",
      "0 vs 1275: mean=0.002, max=0.081\n",
      "0 vs 1276: mean=-0.018, max=0.100\n",
      "0 vs 1277: mean=0.044, max=0.165\n",
      "0 vs 1278: mean=0.090, max=0.165\n",
      "0 vs 1279: mean=-0.053, max=0.046\n",
      "0 vs 1280: mean=0.074, max=0.168\n",
      "0 vs 1281: mean=0.041, max=0.172\n",
      "0 vs 1282: mean=0.040, max=0.138\n",
      "0 vs 1283: mean=-0.012, max=0.086\n",
      "0 vs 1284: mean=-0.015, max=0.086\n",
      "0 vs 1285: mean=0.066, max=0.175\n",
      "0 vs 1286: mean=-0.044, max=0.052\n",
      "0 vs 1287: mean=0.027, max=0.195\n",
      "0 vs 1288: mean=-0.078, max=0.040\n",
      "0 vs 1289: mean=0.019, max=0.143\n",
      "0 vs 1290: mean=0.066, max=0.193\n",
      "0 vs 1291: mean=0.031, max=0.129\n",
      "0 vs 1292: mean=-0.019, max=0.063\n",
      "0 vs 1293: mean=0.067, max=0.166\n",
      "0 vs 1294: mean=0.046, max=0.193\n",
      "0 vs 1295: mean=0.080, max=0.191\n",
      "0 vs 1296: mean=0.006, max=0.116\n",
      "0 vs 1297: mean=0.051, max=0.178\n",
      "0 vs 1298: mean=-0.025, max=0.102\n",
      "0 vs 1299: mean=0.105, max=0.193\n",
      "0 vs 1300: mean=0.012, max=0.104\n",
      "0 vs 1301: mean=-0.123, max=0.001\n",
      "0 vs 1302: mean=0.076, max=0.251\n",
      "0 vs 1303: mean=0.113, max=0.180\n",
      "0 vs 1304: mean=-0.005, max=0.115\n",
      "0 vs 1305: mean=0.083, max=0.171\n",
      "0 vs 1306: mean=0.070, max=0.152\n",
      "0 vs 1307: mean=0.079, max=0.171\n",
      "0 vs 1308: mean=0.054, max=0.159\n",
      "0 vs 1309: mean=0.089, max=0.172\n",
      "0 vs 1310: mean=-0.021, max=0.124\n",
      "0 vs 1311: mean=0.026, max=0.179\n",
      "0 vs 1312: mean=0.075, max=0.186\n",
      "0 vs 1313: mean=-0.006, max=0.088\n",
      "0 vs 1314: mean=0.062, max=0.245\n",
      "0 vs 1315: mean=-0.042, max=0.027\n",
      "0 vs 1316: mean=-0.002, max=0.104\n",
      "0 vs 1317: mean=-0.012, max=0.125\n",
      "0 vs 1318: mean=0.028, max=0.124\n",
      "0 vs 1319: mean=-0.041, max=0.079\n",
      "0 vs 1320: mean=-0.016, max=0.075\n",
      "0 vs 1321: mean=0.042, max=0.158\n",
      "0 vs 1322: mean=0.047, max=0.176\n",
      "0 vs 1323: mean=-0.050, max=0.068\n",
      "0 vs 1324: mean=-0.004, max=0.090\n",
      "0 vs 1325: mean=0.011, max=0.132\n",
      "0 vs 1326: mean=-0.029, max=0.086\n",
      "0 vs 1327: mean=0.018, max=0.128\n",
      "0 vs 1328: mean=0.020, max=0.125\n",
      "0 vs 1329: mean=0.046, max=0.134\n",
      "0 vs 1330: mean=0.193, max=0.411\n",
      "0 vs 1331: mean=0.147, max=0.396\n",
      "0 vs 1332: mean=0.110, max=0.300\n",
      "0 vs 1333: mean=0.189, max=0.430\n",
      "0 vs 1334: mean=0.068, max=0.374\n",
      "0 vs 1335: mean=0.134, max=0.318\n",
      "0 vs 1336: mean=0.175, max=0.360\n",
      "0 vs 1337: mean=0.118, max=0.511\n",
      "0 vs 1338: mean=0.160, max=0.359\n",
      "0 vs 1339: mean=0.233, max=0.521\n",
      "0 vs 1340: mean=0.104, max=0.288\n",
      "0 vs 1341: mean=0.171, max=0.394\n",
      "0 vs 1342: mean=0.200, max=0.407\n",
      "0 vs 1343: mean=0.142, max=0.288\n",
      "0 vs 1344: mean=0.265, max=0.495\n",
      "0 vs 1345: mean=0.112, max=0.350\n",
      "0 vs 1346: mean=0.130, max=0.385\n",
      "0 vs 1347: mean=0.068, max=0.252\n",
      "0 vs 1348: mean=0.221, max=0.429\n",
      "0 vs 1349: mean=0.223, max=0.436\n",
      "0 vs 1350: mean=0.208, max=0.407\n",
      "0 vs 1351: mean=0.082, max=0.307\n",
      "0 vs 1352: mean=0.026, max=0.200\n",
      "0 vs 1353: mean=0.068, max=0.257\n",
      "0 vs 1354: mean=0.341, max=0.504\n",
      "0 vs 1355: mean=0.072, max=0.266\n",
      "0 vs 1356: mean=-0.040, max=0.146\n",
      "0 vs 1357: mean=0.097, max=0.369\n",
      "0 vs 1358: mean=0.202, max=0.550\n",
      "0 vs 1359: mean=0.112, max=0.294\n",
      "0 vs 1360: mean=0.122, max=0.286\n",
      "0 vs 1361: mean=0.006, max=0.221\n",
      "0 vs 1362: mean=0.083, max=0.234\n",
      "0 vs 1363: mean=0.077, max=0.257\n",
      "0 vs 1364: mean=0.079, max=0.197\n",
      "0 vs 1365: mean=-0.043, max=0.160\n",
      "0 vs 1366: mean=0.230, max=0.421\n",
      "0 vs 1367: mean=0.160, max=0.406\n",
      "0 vs 1368: mean=0.033, max=0.189\n",
      "0 vs 1369: mean=0.114, max=0.335\n",
      "0 vs 1370: mean=0.195, max=0.451\n",
      "0 vs 1371: mean=0.092, max=0.473\n",
      "0 vs 1372: mean=0.225, max=0.571\n",
      "0 vs 1373: mean=0.119, max=0.329\n",
      "0 vs 1374: mean=0.101, max=0.447\n",
      "0 vs 1375: mean=0.142, max=0.461\n",
      "0 vs 1376: mean=0.089, max=0.296\n",
      "0 vs 1377: mean=0.037, max=0.165\n",
      "0 vs 1378: mean=0.052, max=0.229\n",
      "0 vs 1379: mean=0.063, max=0.288\n",
      "0 vs 1380: mean=0.101, max=0.325\n",
      "0 vs 1381: mean=0.038, max=0.229\n",
      "0 vs 1382: mean=-0.006, max=0.179\n",
      "0 vs 1383: mean=0.175, max=0.498\n",
      "0 vs 1384: mean=0.219, max=0.475\n",
      "0 vs 1385: mean=0.126, max=0.354\n",
      "0 vs 1386: mean=0.035, max=0.246\n",
      "0 vs 1387: mean=0.018, max=0.267\n",
      "0 vs 1388: mean=0.116, max=0.317\n",
      "0 vs 1389: mean=0.132, max=0.372\n",
      "0 vs 1390: mean=0.044, max=0.244\n",
      "0 vs 1391: mean=-0.125, max=0.031\n",
      "0 vs 1392: mean=0.059, max=0.193\n",
      "0 vs 1393: mean=-0.140, max=-0.033\n",
      "0 vs 1394: mean=-0.183, max=-0.056\n",
      "0 vs 1395: mean=-0.148, max=0.053\n",
      "0 vs 1396: mean=-0.024, max=0.144\n",
      "0 vs 1397: mean=0.020, max=0.183\n",
      "0 vs 1398: mean=0.015, max=0.146\n",
      "0 vs 1399: mean=-0.115, max=0.036\n",
      "0 vs 1400: mean=-0.018, max=0.147\n",
      "0 vs 1401: mean=0.028, max=0.195\n",
      "0 vs 1402: mean=-0.072, max=0.100\n",
      "0 vs 1403: mean=-0.075, max=0.083\n",
      "0 vs 1404: mean=-0.097, max=0.062\n",
      "0 vs 1405: mean=-0.071, max=0.148\n",
      "0 vs 1406: mean=0.085, max=0.258\n",
      "0 vs 1407: mean=-0.083, max=0.094\n",
      "0 vs 1408: mean=0.022, max=0.234\n",
      "0 vs 1409: mean=-0.026, max=0.161\n",
      "0 vs 1410: mean=0.001, max=0.228\n",
      "0 vs 1411: mean=0.178, max=0.541\n",
      "0 vs 1412: mean=-0.074, max=0.089\n",
      "0 vs 1413: mean=0.134, max=0.366\n",
      "0 vs 1414: mean=0.008, max=0.121\n",
      "0 vs 1415: mean=0.018, max=0.331\n",
      "0 vs 1416: mean=-0.031, max=0.115\n",
      "0 vs 1417: mean=-0.027, max=0.138\n",
      "0 vs 1418: mean=-0.025, max=0.071\n",
      "0 vs 1419: mean=-0.021, max=0.172\n",
      "0 vs 1420: mean=0.139, max=0.281\n",
      "0 vs 1421: mean=-0.037, max=0.122\n",
      "0 vs 1422: mean=-0.104, max=0.044\n",
      "0 vs 1423: mean=-0.072, max=0.027\n",
      "0 vs 1424: mean=-0.032, max=0.155\n",
      "0 vs 1425: mean=0.195, max=0.505\n",
      "0 vs 1426: mean=-0.030, max=0.087\n",
      "0 vs 1427: mean=0.037, max=0.199\n",
      "0 vs 1428: mean=0.094, max=0.458\n",
      "0 vs 1429: mean=-0.166, max=0.021\n",
      "0 vs 1430: mean=-0.107, max=0.005\n",
      "0 vs 1431: mean=-0.107, max=0.004\n",
      "0 vs 1432: mean=0.073, max=0.246\n",
      "0 vs 1433: mean=-0.035, max=0.106\n",
      "0 vs 1434: mean=0.049, max=0.209\n",
      "0 vs 1435: mean=0.016, max=0.163\n",
      "0 vs 1436: mean=-0.050, max=0.084\n",
      "0 vs 1437: mean=-0.075, max=0.051\n",
      "0 vs 1438: mean=0.030, max=0.261\n",
      "0 vs 1439: mean=0.022, max=0.171\n",
      "0 vs 1440: mean=0.009, max=0.215\n",
      "0 vs 1441: mean=-0.053, max=0.177\n",
      "0 vs 1442: mean=0.197, max=0.417\n",
      "0 vs 1443: mean=-0.095, max=0.019\n",
      "0 vs 1444: mean=0.039, max=0.215\n",
      "0 vs 1445: mean=-0.049, max=0.096\n",
      "0 vs 1446: mean=-0.068, max=0.086\n",
      "0 vs 1447: mean=-0.084, max=0.049\n",
      "0 vs 1448: mean=-0.095, max=0.059\n",
      "0 vs 1449: mean=-0.120, max=0.003\n",
      "0 vs 1450: mean=-0.017, max=0.093\n",
      "0 vs 1451: mean=-0.012, max=0.117\n",
      "0 vs 1452: mean=0.001, max=0.108\n",
      "0 vs 1453: mean=0.126, max=0.282\n",
      "0 vs 1454: mean=0.009, max=0.226\n",
      "0 vs 1455: mean=0.019, max=0.260\n",
      "0 vs 1456: mean=-0.109, max=0.001\n",
      "0 vs 1457: mean=-0.115, max=-0.028\n",
      "0 vs 1458: mean=0.005, max=0.109\n",
      "0 vs 1459: mean=0.011, max=0.164\n",
      "0 vs 1460: mean=-0.050, max=0.121\n",
      "0 vs 1461: mean=0.059, max=0.255\n",
      "0 vs 1462: mean=-0.022, max=0.315\n",
      "0 vs 1463: mean=-0.036, max=0.137\n",
      "0 vs 1464: mean=0.018, max=0.157\n",
      "0 vs 1465: mean=-0.090, max=0.012\n",
      "0 vs 1466: mean=-0.101, max=0.043\n",
      "0 vs 1467: mean=-0.067, max=0.172\n",
      "0 vs 1468: mean=-0.098, max=0.163\n",
      "0 vs 1469: mean=-0.036, max=0.104\n",
      "0 vs 1470: mean=-0.007, max=0.141\n",
      "0 vs 1471: mean=0.051, max=0.181\n",
      "0 vs 1472: mean=-0.075, max=-0.015\n",
      "0 vs 1473: mean=0.012, max=0.115\n",
      "0 vs 1474: mean=0.137, max=0.499\n",
      "0 vs 1475: mean=0.068, max=0.282\n",
      "0 vs 1476: mean=-0.007, max=0.207\n",
      "0 vs 1477: mean=-0.012, max=0.100\n",
      "0 vs 1478: mean=-0.072, max=0.060\n",
      "0 vs 1479: mean=-0.047, max=0.176\n",
      "0 vs 1480: mean=-0.066, max=0.033\n",
      "0 vs 1481: mean=-0.062, max=0.080\n",
      "0 vs 1482: mean=0.026, max=0.254\n",
      "0 vs 1483: mean=-0.058, max=0.088\n",
      "0 vs 1484: mean=-0.110, max=-0.018\n",
      "0 vs 1485: mean=-0.123, max=-0.011\n",
      "0 vs 1486: mean=-0.014, max=0.096\n",
      "0 vs 1487: mean=-0.038, max=0.207\n",
      "0 vs 1488: mean=0.117, max=0.356\n",
      "0 vs 1489: mean=-0.012, max=0.125\n",
      "0 vs 1490: mean=-0.150, max=-0.049\n",
      "0 vs 1491: mean=-0.110, max=0.030\n",
      "0 vs 1492: mean=-0.038, max=0.066\n",
      "0 vs 1493: mean=-0.098, max=0.003\n",
      "0 vs 1494: mean=-0.146, max=-0.013\n",
      "0 vs 1495: mean=-0.186, max=-0.085\n",
      "0 vs 1496: mean=-0.072, max=0.011\n",
      "0 vs 1497: mean=0.090, max=0.191\n",
      "0 vs 1498: mean=-0.122, max=-0.001\n",
      "0 vs 1499: mean=-0.104, max=0.039\n",
      "0 vs 1500: mean=-0.146, max=-0.045\n",
      "0 vs 1501: mean=-0.013, max=0.083\n",
      "0 vs 1502: mean=-0.114, max=0.033\n",
      "0 vs 1503: mean=-0.097, max=-0.014\n",
      "0 vs 1504: mean=-0.055, max=0.053\n",
      "0 vs 1505: mean=-0.151, max=-0.065\n",
      "0 vs 1506: mean=-0.099, max=0.017\n",
      "0 vs 1507: mean=-0.096, max=0.124\n",
      "0 vs 1508: mean=0.025, max=0.146\n",
      "0 vs 1509: mean=0.026, max=0.124\n",
      "0 vs 1510: mean=-0.074, max=0.065\n",
      "0 vs 1511: mean=-0.031, max=0.091\n",
      "0 vs 1512: mean=-0.039, max=0.086\n",
      "0 vs 1513: mean=-0.076, max=0.049\n",
      "0 vs 1514: mean=-0.027, max=0.091\n",
      "0 vs 1515: mean=0.078, max=0.163\n",
      "0 vs 1516: mean=-0.091, max=0.139\n",
      "0 vs 1517: mean=-0.046, max=0.072\n",
      "0 vs 1518: mean=-0.097, max=0.081\n",
      "0 vs 1519: mean=-0.085, max=0.055\n",
      "0 vs 1520: mean=0.044, max=0.163\n",
      "0 vs 1521: mean=-0.131, max=0.061\n",
      "0 vs 1522: mean=0.067, max=0.182\n",
      "0 vs 1523: mean=-0.028, max=0.100\n",
      "0 vs 1524: mean=-0.058, max=0.061\n",
      "0 vs 1525: mean=-0.107, max=-0.014\n",
      "0 vs 1526: mean=-0.061, max=0.061\n",
      "0 vs 1527: mean=-0.028, max=0.090\n",
      "0 vs 1528: mean=-0.051, max=0.111\n",
      "0 vs 1529: mean=-0.112, max=-0.006\n",
      "0 vs 1530: mean=0.036, max=0.344\n",
      "0 vs 1531: mean=-0.089, max=0.041\n",
      "0 vs 1532: mean=-0.033, max=0.194\n",
      "0 vs 1533: mean=0.082, max=0.290\n",
      "0 vs 1534: mean=0.040, max=0.332\n",
      "0 vs 1535: mean=0.011, max=0.139\n",
      "0 vs 1536: mean=-0.055, max=0.087\n",
      "0 vs 1537: mean=-0.046, max=0.078\n",
      "0 vs 1538: mean=-0.043, max=0.061\n",
      "0 vs 1539: mean=-0.051, max=0.131\n",
      "0 vs 1540: mean=-0.134, max=0.005\n",
      "0 vs 1541: mean=0.023, max=0.190\n",
      "0 vs 1542: mean=-0.039, max=0.084\n",
      "0 vs 1543: mean=-0.003, max=0.129\n",
      "0 vs 1544: mean=-0.019, max=0.082\n",
      "0 vs 1545: mean=-0.080, max=0.060\n",
      "0 vs 1546: mean=-0.062, max=0.083\n",
      "0 vs 1547: mean=-0.110, max=-0.014\n",
      "0 vs 1548: mean=-0.008, max=0.140\n",
      "0 vs 1549: mean=-0.058, max=0.065\n",
      "0 vs 1550: mean=-0.029, max=0.084\n",
      "0 vs 1551: mean=0.053, max=0.295\n",
      "0 vs 1552: mean=-0.029, max=0.067\n",
      "0 vs 1553: mean=-0.057, max=0.064\n",
      "0 vs 1554: mean=-0.131, max=-0.030\n",
      "0 vs 1555: mean=0.004, max=0.233\n",
      "0 vs 1556: mean=-0.144, max=0.103\n",
      "0 vs 1557: mean=-0.105, max=0.038\n",
      "0 vs 1558: mean=-0.082, max=0.015\n",
      "0 vs 1559: mean=0.025, max=0.153\n",
      "0 vs 1560: mean=-0.105, max=0.062\n",
      "0 vs 1561: mean=0.046, max=0.278\n",
      "0 vs 1562: mean=-0.081, max=0.093\n",
      "0 vs 1563: mean=-0.084, max=0.092\n",
      "0 vs 1564: mean=-0.059, max=0.082\n",
      "0 vs 1565: mean=-0.029, max=0.065\n",
      "0 vs 1566: mean=-0.028, max=0.101\n",
      "0 vs 1567: mean=-0.132, max=-0.056\n",
      "0 vs 1568: mean=-0.054, max=0.052\n",
      "0 vs 1569: mean=-0.053, max=0.074\n",
      "0 vs 1570: mean=-0.183, max=-0.058\n",
      "0 vs 1571: mean=-0.106, max=0.075\n",
      "0 vs 1572: mean=-0.127, max=0.006\n",
      "0 vs 1573: mean=-0.022, max=0.263\n",
      "0 vs 1574: mean=-0.035, max=0.127\n",
      "0 vs 1575: mean=-0.151, max=-0.045\n",
      "0 vs 1576: mean=-0.045, max=0.094\n",
      "0 vs 1577: mean=-0.082, max=0.024\n",
      "0 vs 1578: mean=0.106, max=0.348\n",
      "0 vs 1579: mean=-0.072, max=0.025\n",
      "0 vs 1580: mean=-0.043, max=0.070\n",
      "0 vs 1581: mean=-0.010, max=0.173\n",
      "0 vs 1582: mean=-0.018, max=0.194\n",
      "0 vs 1583: mean=0.021, max=0.187\n",
      "0 vs 1584: mean=-0.067, max=0.004\n",
      "0 vs 1585: mean=-0.046, max=0.100\n",
      "0 vs 1586: mean=-0.083, max=0.002\n",
      "0 vs 1587: mean=-0.066, max=0.046\n",
      "0 vs 1588: mean=-0.022, max=0.076\n",
      "0 vs 1589: mean=-0.033, max=0.265\n",
      "0 vs 1590: mean=-0.028, max=0.093\n",
      "0 vs 1591: mean=0.092, max=0.372\n",
      "0 vs 1592: mean=-0.138, max=-0.021\n",
      "0 vs 1593: mean=-0.033, max=0.087\n",
      "0 vs 1594: mean=0.010, max=0.144\n",
      "0 vs 1595: mean=-0.001, max=0.213\n",
      "0 vs 1596: mean=-0.079, max=0.060\n",
      "0 vs 1597: mean=-0.143, max=-0.027\n",
      "0 vs 1598: mean=-0.022, max=0.061\n",
      "0 vs 1599: mean=0.056, max=0.188\n",
      "0 vs 1600: mean=-0.069, max=0.031\n",
      "0 vs 1601: mean=-0.026, max=0.103\n",
      "0 vs 1602: mean=-0.071, max=0.031\n",
      "0 vs 1603: mean=-0.068, max=0.030\n",
      "0 vs 1604: mean=-0.043, max=0.074\n",
      "0 vs 1605: mean=-0.021, max=0.095\n",
      "0 vs 1606: mean=0.026, max=0.172\n",
      "0 vs 1607: mean=-0.081, max=0.004\n",
      "0 vs 1608: mean=-0.143, max=-0.040\n",
      "0 vs 1609: mean=-0.090, max=0.057\n",
      "0 vs 1610: mean=-0.124, max=-0.033\n",
      "0 vs 1611: mean=-0.057, max=0.059\n",
      "0 vs 1612: mean=-0.012, max=0.126\n",
      "0 vs 1613: mean=-0.053, max=0.067\n",
      "0 vs 1614: mean=-0.096, max=0.060\n",
      "0 vs 1615: mean=-0.084, max=0.036\n",
      "0 vs 1616: mean=-0.141, max=-0.024\n",
      "0 vs 1617: mean=-0.092, max=-0.019\n",
      "0 vs 1618: mean=-0.006, max=0.104\n",
      "0 vs 1619: mean=0.058, max=0.181\n",
      "0 vs 1620: mean=-0.072, max=0.054\n",
      "0 vs 1621: mean=-0.093, max=0.011\n",
      "0 vs 1622: mean=-0.160, max=-0.063\n",
      "0 vs 1623: mean=-0.105, max=-0.020\n",
      "0 vs 1624: mean=-0.056, max=0.091\n",
      "0 vs 1625: mean=-0.091, max=0.008\n",
      "0 vs 1626: mean=-0.049, max=0.007\n",
      "0 vs 1627: mean=-0.099, max=-0.024\n",
      "0 vs 1628: mean=-0.115, max=-0.011\n",
      "0 vs 1629: mean=-0.080, max=0.073\n",
      "0 vs 1630: mean=-0.111, max=-0.024\n",
      "0 vs 1631: mean=0.003, max=0.102\n",
      "0 vs 1632: mean=-0.023, max=0.082\n",
      "0 vs 1633: mean=-0.010, max=0.100\n",
      "0 vs 1634: mean=0.010, max=0.094\n",
      "0 vs 1635: mean=0.088, max=0.209\n",
      "0 vs 1636: mean=0.019, max=0.117\n",
      "0 vs 1637: mean=0.013, max=0.133\n",
      "0 vs 1638: mean=0.017, max=0.143\n",
      "0 vs 1639: mean=-0.030, max=0.121\n",
      "0 vs 1640: mean=-0.017, max=0.072\n",
      "0 vs 1641: mean=-0.119, max=-0.005\n",
      "0 vs 1642: mean=0.056, max=0.148\n",
      "0 vs 1643: mean=0.001, max=0.112\n",
      "0 vs 1644: mean=0.022, max=0.108\n",
      "0 vs 1645: mean=0.021, max=0.145\n",
      "0 vs 1646: mean=0.009, max=0.133\n",
      "0 vs 1647: mean=-0.065, max=0.078\n",
      "0 vs 1648: mean=-0.149, max=0.054\n",
      "0 vs 1649: mean=-0.046, max=0.087\n",
      "0 vs 1650: mean=0.011, max=0.324\n",
      "0 vs 1651: mean=-0.088, max=0.111\n",
      "0 vs 1652: mean=-0.078, max=0.245\n",
      "0 vs 1653: mean=-0.102, max=0.030\n",
      "0 vs 1654: mean=-0.092, max=0.045\n",
      "0 vs 1655: mean=-0.051, max=0.099\n",
      "0 vs 1656: mean=-0.100, max=0.028\n",
      "0 vs 1657: mean=-0.139, max=0.009\n",
      "0 vs 1658: mean=-0.071, max=0.052\n",
      "0 vs 1659: mean=-0.082, max=0.045\n",
      "0 vs 1660: mean=-0.053, max=0.054\n",
      "0 vs 1661: mean=-0.084, max=0.033\n",
      "0 vs 1662: mean=-0.062, max=0.085\n",
      "0 vs 1663: mean=-0.097, max=0.099\n",
      "0 vs 1664: mean=-0.117, max=0.013\n",
      "0 vs 1665: mean=-0.130, max=0.024\n",
      "0 vs 1666: mean=-0.004, max=0.131\n",
      "0 vs 1667: mean=-0.050, max=0.080\n",
      "0 vs 1668: mean=-0.103, max=0.036\n",
      "0 vs 1669: mean=-0.075, max=0.070\n",
      "0 vs 1670: mean=-0.208, max=-0.051\n",
      "0 vs 1671: mean=-0.059, max=0.162\n",
      "0 vs 1672: mean=-0.037, max=0.216\n",
      "0 vs 1673: mean=-0.069, max=0.110\n",
      "0 vs 1674: mean=0.028, max=0.166\n",
      "0 vs 1675: mean=-0.011, max=0.220\n",
      "0 vs 1676: mean=0.141, max=0.504\n",
      "0 vs 1677: mean=-0.038, max=0.099\n",
      "0 vs 1678: mean=-0.125, max=0.005\n",
      "0 vs 1679: mean=-0.086, max=0.111\n",
      "0 vs 1680: mean=-0.072, max=0.145\n",
      "0 vs 1681: mean=-0.037, max=0.192\n",
      "0 vs 1682: mean=-0.163, max=-0.036\n",
      "0 vs 1683: mean=-0.114, max=-0.003\n",
      "0 vs 1684: mean=-0.004, max=0.194\n",
      "0 vs 1685: mean=-0.159, max=-0.031\n",
      "0 vs 1686: mean=-0.087, max=0.057\n",
      "0 vs 1687: mean=-0.116, max=0.050\n",
      "0 vs 1688: mean=-0.089, max=0.033\n",
      "0 vs 1689: mean=-0.096, max=0.041\n",
      "0 vs 1690: mean=-0.139, max=-0.013\n",
      "0 vs 1691: mean=0.016, max=0.360\n",
      "0 vs 1692: mean=0.003, max=0.200\n",
      "0 vs 1693: mean=-0.079, max=0.032\n",
      "0 vs 1694: mean=-0.109, max=-0.025\n",
      "0 vs 1695: mean=-0.033, max=0.187\n",
      "0 vs 1696: mean=0.018, max=0.245\n",
      "0 vs 1697: mean=0.014, max=0.203\n",
      "0 vs 1698: mean=-0.192, max=-0.014\n",
      "0 vs 1699: mean=0.106, max=0.297\n",
      "0 vs 1700: mean=-0.206, max=-0.052\n",
      "0 vs 1701: mean=-0.190, max=-0.090\n",
      "0 vs 1702: mean=-0.175, max=-0.043\n",
      "0 vs 1703: mean=-0.087, max=0.081\n",
      "0 vs 1704: mean=-0.048, max=0.113\n",
      "0 vs 1705: mean=-0.160, max=-0.061\n",
      "0 vs 1706: mean=-0.081, max=0.033\n",
      "0 vs 1707: mean=-0.144, max=-0.034\n",
      "0 vs 1708: mean=-0.142, max=-0.070\n",
      "0 vs 1709: mean=-0.064, max=0.094\n",
      "0 vs 1710: mean=0.027, max=0.210\n",
      "0 vs 1711: mean=-0.054, max=0.109\n",
      "0 vs 1712: mean=0.025, max=0.232\n",
      "0 vs 1713: mean=0.104, max=0.221\n",
      "0 vs 1714: mean=-0.001, max=0.209\n",
      "0 vs 1715: mean=0.027, max=0.247\n",
      "0 vs 1716: mean=0.001, max=0.207\n",
      "0 vs 1717: mean=0.137, max=0.340\n",
      "0 vs 1718: mean=-0.030, max=0.210\n",
      "0 vs 1719: mean=-0.036, max=0.089\n",
      "0 vs 1720: mean=0.020, max=0.233\n",
      "0 vs 1721: mean=0.031, max=0.192\n",
      "0 vs 1722: mean=0.086, max=0.318\n",
      "0 vs 1723: mean=-0.076, max=0.061\n",
      "0 vs 1724: mean=-0.174, max=-0.078\n",
      "0 vs 1725: mean=-0.162, max=-0.060\n",
      "0 vs 1726: mean=0.050, max=0.264\n",
      "0 vs 1727: mean=0.103, max=0.306\n",
      "0 vs 1728: mean=0.115, max=0.326\n",
      "0 vs 1729: mean=-0.028, max=0.226\n",
      "0 vs 1730: mean=-0.012, max=0.296\n",
      "0 vs 1731: mean=-0.043, max=0.170\n",
      "0 vs 1732: mean=-0.177, max=-0.015\n",
      "0 vs 1733: mean=-0.183, max=-0.040\n",
      "0 vs 1734: mean=-0.168, max=-0.073\n",
      "0 vs 1735: mean=-0.056, max=0.217\n",
      "0 vs 1736: mean=-0.130, max=0.127\n",
      "0 vs 1737: mean=-0.190, max=-0.089\n",
      "0 vs 1738: mean=-0.146, max=-0.058\n",
      "0 vs 1739: mean=-0.141, max=-0.043\n",
      "0 vs 1740: mean=0.005, max=0.090\n",
      "0 vs 1741: mean=-0.130, max=-0.053\n",
      "0 vs 1742: mean=-0.144, max=-0.069\n",
      "0 vs 1743: mean=-0.087, max=0.030\n",
      "0 vs 1744: mean=-0.074, max=0.093\n",
      "0 vs 1745: mean=-0.060, max=0.132\n",
      "0 vs 1746: mean=-0.120, max=-0.043\n",
      "0 vs 1747: mean=0.008, max=0.168\n",
      "0 vs 1748: mean=-0.036, max=0.107\n",
      "0 vs 1749: mean=-0.051, max=0.079\n",
      "0 vs 1750: mean=-0.109, max=0.133\n",
      "0 vs 1751: mean=-0.143, max=0.139\n",
      "0 vs 1752: mean=-0.183, max=-0.054\n",
      "0 vs 1753: mean=-0.163, max=0.022\n",
      "0 vs 1754: mean=-0.176, max=-0.044\n",
      "0 vs 1755: mean=-0.205, max=-0.071\n",
      "0 vs 1756: mean=-0.150, max=0.001\n",
      "0 vs 1757: mean=-0.126, max=0.056\n",
      "0 vs 1758: mean=-0.120, max=0.093\n",
      "0 vs 1759: mean=-0.151, max=-0.014\n",
      "0 vs 1760: mean=-0.196, max=-0.077\n",
      "0 vs 1761: mean=-0.092, max=0.065\n",
      "0 vs 1762: mean=-0.173, max=0.009\n",
      "0 vs 1763: mean=-0.044, max=0.151\n",
      "0 vs 1764: mean=-0.122, max=0.008\n",
      "0 vs 1765: mean=-0.075, max=0.095\n",
      "0 vs 1766: mean=0.019, max=0.161\n",
      "0 vs 1767: mean=-0.136, max=0.017\n",
      "0 vs 1768: mean=-0.158, max=-0.045\n",
      "0 vs 1769: mean=-0.197, max=-0.033\n",
      "0 vs 1770: mean=0.043, max=0.225\n",
      "0 vs 1771: mean=-0.046, max=0.132\n",
      "0 vs 1772: mean=-0.158, max=0.026\n",
      "0 vs 1773: mean=-0.133, max=0.092\n",
      "0 vs 1774: mean=-0.247, max=-0.050\n",
      "0 vs 1775: mean=-0.139, max=-0.017\n",
      "0 vs 1776: mean=-0.051, max=0.149\n",
      "0 vs 1777: mean=-0.004, max=0.184\n",
      "0 vs 1778: mean=-0.173, max=-0.062\n",
      "0 vs 1779: mean=-0.067, max=0.091\n",
      "0 vs 1780: mean=-0.152, max=0.028\n",
      "0 vs 1781: mean=-0.091, max=0.124\n",
      "0 vs 1782: mean=-0.074, max=0.086\n",
      "0 vs 1783: mean=-0.061, max=0.138\n",
      "0 vs 1784: mean=-0.079, max=0.193\n",
      "0 vs 1785: mean=-0.110, max=0.025\n",
      "0 vs 1786: mean=-0.124, max=-0.002\n",
      "0 vs 1787: mean=-0.173, max=-0.049\n",
      "0 vs 1788: mean=-0.029, max=0.150\n",
      "0 vs 1789: mean=-0.102, max=-0.011\n",
      "0 vs 1790: mean=-0.106, max=-0.030\n",
      "0 vs 1791: mean=-0.036, max=0.117\n",
      "0 vs 1792: mean=-0.078, max=0.178\n",
      "0 vs 1793: mean=-0.069, max=0.097\n",
      "0 vs 1794: mean=-0.173, max=-0.065\n",
      "0 vs 1795: mean=-0.085, max=0.026\n",
      "0 vs 1796: mean=-0.111, max=-0.023\n",
      "0 vs 1797: mean=-0.129, max=0.015\n",
      "0 vs 1798: mean=-0.139, max=-0.012\n",
      "0 vs 1799: mean=-0.095, max=0.032\n",
      "0 vs 1800: mean=-0.154, max=-0.011\n",
      "0 vs 1801: mean=-0.173, max=-0.064\n",
      "0 vs 1802: mean=-0.072, max=0.251\n",
      "0 vs 1803: mean=-0.020, max=0.143\n",
      "0 vs 1804: mean=-0.051, max=0.109\n",
      "0 vs 1805: mean=-0.064, max=0.084\n",
      "0 vs 1806: mean=-0.209, max=-0.063\n",
      "0 vs 1807: mean=-0.066, max=0.051\n",
      "0 vs 1808: mean=0.065, max=0.270\n",
      "0 vs 1809: mean=-0.141, max=0.010\n",
      "0 vs 1810: mean=-0.184, max=-0.079\n",
      "0 vs 1811: mean=-0.050, max=0.201\n",
      "0 vs 1812: mean=-0.178, max=0.025\n",
      "0 vs 1813: mean=-0.121, max=0.059\n",
      "0 vs 1814: mean=-0.082, max=0.110\n",
      "0 vs 1815: mean=-0.072, max=0.097\n",
      "0 vs 1816: mean=-0.147, max=0.051\n",
      "0 vs 1817: mean=-0.154, max=-0.011\n",
      "0 vs 1818: mean=-0.127, max=0.070\n",
      "0 vs 1819: mean=-0.004, max=0.283\n",
      "0 vs 1820: mean=-0.218, max=-0.050\n",
      "0 vs 1821: mean=-0.134, max=0.008\n",
      "0 vs 1822: mean=-0.232, max=-0.121\n",
      "0 vs 1823: mean=-0.141, max=0.009\n",
      "0 vs 1824: mean=-0.171, max=0.037\n",
      "0 vs 1825: mean=-0.107, max=0.038\n",
      "0 vs 1826: mean=-0.114, max=0.041\n",
      "0 vs 1827: mean=-0.066, max=0.112\n",
      "0 vs 1828: mean=-0.213, max=-0.097\n",
      "0 vs 1829: mean=-0.109, max=0.038\n",
      "0 vs 1830: mean=-0.144, max=-0.000\n",
      "0 vs 1831: mean=-0.103, max=0.067\n",
      "0 vs 1832: mean=-0.049, max=0.065\n",
      "0 vs 1833: mean=-0.144, max=-0.015\n",
      "0 vs 1834: mean=0.004, max=0.145\n",
      "0 vs 1835: mean=-0.141, max=-0.006\n",
      "0 vs 1836: mean=-0.174, max=-0.029\n",
      "0 vs 1837: mean=-0.132, max=-0.022\n",
      "0 vs 1838: mean=-0.042, max=0.083\n",
      "0 vs 1839: mean=0.008, max=0.179\n",
      "0 vs 1840: mean=-0.069, max=0.062\n",
      "0 vs 1841: mean=0.064, max=0.202\n",
      "0 vs 1842: mean=-0.202, max=-0.046\n",
      "0 vs 1843: mean=-0.039, max=0.051\n",
      "0 vs 1844: mean=-0.118, max=-0.008\n",
      "0 vs 1845: mean=-0.067, max=0.070\n",
      "0 vs 1846: mean=0.063, max=0.256\n",
      "0 vs 1847: mean=-0.061, max=0.091\n",
      "0 vs 1848: mean=-0.011, max=0.165\n",
      "0 vs 1849: mean=-0.113, max=0.100\n",
      "0 vs 1850: mean=-0.057, max=0.079\n",
      "0 vs 1851: mean=-0.074, max=0.081\n",
      "0 vs 1852: mean=-0.155, max=-0.025\n",
      "0 vs 1853: mean=-0.079, max=0.054\n",
      "0 vs 1854: mean=-0.078, max=0.039\n",
      "0 vs 1855: mean=-0.059, max=0.120\n",
      "0 vs 1856: mean=-0.130, max=-0.058\n",
      "0 vs 1857: mean=-0.080, max=0.153\n",
      "0 vs 1858: mean=0.029, max=0.142\n",
      "0 vs 1859: mean=-0.108, max=0.097\n",
      "0 vs 1860: mean=0.099, max=0.246\n",
      "0 vs 1861: mean=-0.018, max=0.140\n",
      "0 vs 1862: mean=-0.054, max=0.173\n",
      "0 vs 1863: mean=-0.011, max=0.183\n",
      "0 vs 1864: mean=-0.081, max=0.037\n",
      "0 vs 1865: mean=-0.033, max=0.124\n",
      "0 vs 1866: mean=-0.076, max=0.072\n",
      "0 vs 1867: mean=-0.073, max=0.117\n",
      "0 vs 1868: mean=-0.175, max=-0.075\n",
      "0 vs 1869: mean=-0.016, max=0.084\n",
      "0 vs 1870: mean=-0.124, max=0.081\n",
      "0 vs 1871: mean=-0.174, max=-0.052\n",
      "0 vs 1872: mean=-0.036, max=0.181\n",
      "0 vs 1873: mean=-0.127, max=0.012\n",
      "0 vs 1874: mean=-0.023, max=0.181\n",
      "0 vs 1875: mean=-0.143, max=0.028\n",
      "0 vs 1876: mean=0.035, max=0.180\n",
      "0 vs 1877: mean=-0.017, max=0.098\n",
      "0 vs 1878: mean=-0.094, max=0.030\n",
      "0 vs 1879: mean=-0.173, max=0.041\n",
      "0 vs 1880: mean=-0.030, max=0.167\n",
      "0 vs 1881: mean=-0.099, max=0.048\n",
      "0 vs 1882: mean=-0.054, max=0.072\n",
      "0 vs 1883: mean=-0.122, max=-0.016\n",
      "0 vs 1884: mean=-0.088, max=0.111\n",
      "0 vs 1885: mean=-0.029, max=0.092\n",
      "0 vs 1886: mean=-0.058, max=0.062\n",
      "0 vs 1887: mean=0.022, max=0.170\n",
      "0 vs 1888: mean=-0.139, max=0.002\n",
      "0 vs 1889: mean=-0.163, max=-0.043\n",
      "0 vs 1890: mean=-0.069, max=0.044\n",
      "0 vs 1891: mean=-0.015, max=0.090\n",
      "0 vs 1892: mean=-0.024, max=0.135\n",
      "0 vs 1893: mean=-0.144, max=-0.017\n",
      "0 vs 1894: mean=-0.085, max=0.028\n",
      "0 vs 1895: mean=0.139, max=0.256\n",
      "0 vs 1896: mean=-0.050, max=0.078\n",
      "0 vs 1897: mean=0.050, max=0.182\n",
      "0 vs 1898: mean=-0.069, max=0.076\n",
      "0 vs 1899: mean=-0.089, max=0.086\n",
      "0 vs 1900: mean=-0.122, max=0.006\n",
      "0 vs 1901: mean=-0.075, max=0.067\n",
      "0 vs 1902: mean=-0.049, max=0.116\n",
      "0 vs 1903: mean=0.029, max=0.155\n",
      "0 vs 1904: mean=-0.001, max=0.144\n",
      "0 vs 1905: mean=0.024, max=0.213\n",
      "0 vs 1906: mean=-0.033, max=0.080\n",
      "0 vs 1907: mean=-0.013, max=0.126\n",
      "0 vs 1908: mean=-0.033, max=0.078\n",
      "0 vs 1909: mean=-0.061, max=0.104\n",
      "0 vs 1910: mean=-0.134, max=-0.033\n",
      "0 vs 1911: mean=0.004, max=0.138\n",
      "0 vs 1912: mean=-0.030, max=0.079\n",
      "0 vs 1913: mean=-0.002, max=0.228\n",
      "0 vs 1914: mean=-0.027, max=0.155\n",
      "0 vs 1915: mean=-0.032, max=0.081\n",
      "0 vs 1916: mean=-0.120, max=-0.002\n",
      "0 vs 1917: mean=-0.073, max=0.090\n",
      "0 vs 1918: mean=0.130, max=0.241\n",
      "0 vs 1919: mean=-0.125, max=0.021\n",
      "0 vs 1920: mean=0.009, max=0.176\n",
      "0 vs 1921: mean=-0.020, max=0.154\n",
      "0 vs 1922: mean=-0.079, max=0.080\n",
      "0 vs 1923: mean=0.072, max=0.301\n",
      "0 vs 1924: mean=0.004, max=0.200\n",
      "0 vs 1925: mean=-0.041, max=0.064\n",
      "0 vs 1926: mean=-0.002, max=0.128\n",
      "0 vs 1927: mean=-0.030, max=0.111\n",
      "0 vs 1928: mean=-0.096, max=0.046\n",
      "0 vs 1929: mean=-0.027, max=0.102\n",
      "0 vs 1930: mean=-0.016, max=0.102\n",
      "0 vs 1931: mean=-0.033, max=0.126\n",
      "0 vs 1932: mean=-0.038, max=0.089\n",
      "0 vs 1933: mean=-0.036, max=0.134\n",
      "0 vs 1934: mean=-0.012, max=0.113\n",
      "0 vs 1935: mean=0.000, max=0.080\n",
      "0 vs 1936: mean=0.032, max=0.172\n",
      "0 vs 1937: mean=-0.116, max=0.033\n",
      "0 vs 1938: mean=-0.040, max=0.092\n",
      "0 vs 1939: mean=-0.101, max=0.029\n",
      "0 vs 1940: mean=-0.100, max=0.033\n",
      "0 vs 1941: mean=-0.017, max=0.105\n",
      "0 vs 1942: mean=-0.007, max=0.169\n",
      "0 vs 1943: mean=-0.181, max=-0.039\n",
      "0 vs 1944: mean=-0.074, max=0.031\n",
      "0 vs 1945: mean=-0.052, max=0.077\n",
      "0 vs 1946: mean=-0.105, max=0.076\n",
      "0 vs 1947: mean=-0.059, max=0.052\n",
      "0 vs 1948: mean=-0.070, max=0.027\n",
      "0 vs 1949: mean=-0.055, max=0.076\n",
      "0 vs 1950: mean=-0.093, max=0.060\n",
      "0 vs 1951: mean=-0.046, max=0.121\n",
      "0 vs 1952: mean=-0.130, max=-0.024\n",
      "0 vs 1953: mean=-0.136, max=-0.016\n",
      "0 vs 1954: mean=-0.125, max=0.038\n",
      "0 vs 1955: mean=0.058, max=0.188\n",
      "0 vs 1956: mean=-0.029, max=0.226\n",
      "0 vs 1957: mean=-0.126, max=-0.042\n",
      "0 vs 1958: mean=-0.084, max=0.045\n",
      "0 vs 1959: mean=-0.160, max=-0.013\n",
      "0 vs 1960: mean=-0.107, max=0.046\n",
      "0 vs 1961: mean=-0.134, max=-0.004\n",
      "0 vs 1962: mean=-0.037, max=0.221\n",
      "0 vs 1963: mean=-0.154, max=-0.039\n",
      "0 vs 1964: mean=-0.126, max=0.008\n",
      "0 vs 1965: mean=-0.086, max=0.060\n",
      "0 vs 1966: mean=-0.071, max=0.058\n",
      "0 vs 1967: mean=-0.056, max=0.096\n",
      "0 vs 1968: mean=-0.050, max=0.085\n",
      "0 vs 1969: mean=-0.126, max=0.021\n",
      "0 vs 1970: mean=0.003, max=0.121\n",
      "0 vs 1971: mean=0.010, max=0.097\n",
      "0 vs 1972: mean=0.038, max=0.150\n",
      "0 vs 1973: mean=-0.072, max=0.040\n",
      "0 vs 1974: mean=0.031, max=0.156\n",
      "0 vs 1975: mean=0.111, max=0.264\n",
      "0 vs 1976: mean=0.031, max=0.173\n",
      "0 vs 1977: mean=0.061, max=0.187\n",
      "0 vs 1978: mean=-0.171, max=-0.011\n",
      "0 vs 1979: mean=-0.046, max=0.061\n",
      "0 vs 1980: mean=0.074, max=0.227\n",
      "0 vs 1981: mean=-0.002, max=0.097\n",
      "0 vs 1982: mean=0.066, max=0.154\n",
      "0 vs 1983: mean=-0.111, max=-0.028\n",
      "0 vs 1984: mean=-0.161, max=0.007\n",
      "0 vs 1985: mean=-0.043, max=0.047\n",
      "0 vs 1986: mean=-0.021, max=0.102\n",
      "0 vs 1987: mean=-0.018, max=0.127\n",
      "0 vs 1988: mean=-0.043, max=0.099\n",
      "0 vs 1989: mean=-0.060, max=0.036\n",
      "0 vs 1990: mean=-0.027, max=0.137\n",
      "0 vs 1991: mean=-0.066, max=0.041\n",
      "0 vs 1992: mean=-0.044, max=0.076\n",
      "0 vs 1993: mean=0.011, max=0.147\n",
      "0 vs 1994: mean=-0.030, max=0.107\n",
      "0 vs 1995: mean=-0.038, max=0.091\n",
      "0 vs 1996: mean=-0.053, max=0.060\n",
      "0 vs 1997: mean=-0.178, max=-0.055\n",
      "0 vs 1998: mean=0.070, max=0.158\n",
      "0 vs 1999: mean=0.021, max=0.180\n",
      "1 vs 2: mean=0.409, max=0.719\n",
      "1 vs 3: mean=0.387, max=0.708\n",
      "1 vs 4: mean=0.562, max=0.834\n",
      "1 vs 5: mean=0.383, max=0.644\n",
      "1 vs 6: mean=0.391, max=0.803\n",
      "1 vs 7: mean=0.280, max=0.539\n",
      "1 vs 8: mean=0.479, max=0.821\n",
      "1 vs 9: mean=0.474, max=0.795\n",
      "1 vs 10: mean=0.396, max=0.790\n",
      "1 vs 11: mean=0.351, max=0.637\n",
      "1 vs 12: mean=0.502, max=0.676\n",
      "1 vs 13: mean=0.551, max=0.761\n",
      "1 vs 14: mean=0.247, max=0.407\n",
      "1 vs 15: mean=0.384, max=0.733\n",
      "1 vs 16: mean=0.519, max=0.840\n",
      "1 vs 17: mean=0.531, max=0.776\n",
      "1 vs 18: mean=0.297, max=0.524\n",
      "1 vs 19: mean=0.244, max=0.487\n",
      "1 vs 20: mean=0.531, max=0.657\n",
      "1 vs 21: mean=0.232, max=0.485\n",
      "1 vs 22: mean=0.673, max=0.942\n",
      "1 vs 23: mean=0.381, max=0.558\n",
      "1 vs 24: mean=0.464, max=0.650\n",
      "1 vs 25: mean=0.366, max=0.683\n",
      "1 vs 26: mean=0.352, max=0.551\n",
      "1 vs 27: mean=0.370, max=0.537\n",
      "1 vs 28: mean=0.308, max=0.468\n",
      "1 vs 29: mean=0.149, max=0.349\n",
      "1 vs 30: mean=0.260, max=0.655\n",
      "1 vs 31: mean=0.162, max=0.398\n",
      "1 vs 32: mean=0.324, max=0.663\n",
      "1 vs 33: mean=0.378, max=0.795\n",
      "1 vs 34: mean=0.537, max=0.770\n",
      "1 vs 35: mean=0.417, max=0.659\n",
      "1 vs 36: mean=0.241, max=0.482\n",
      "1 vs 37: mean=0.344, max=0.713\n",
      "1 vs 38: mean=0.227, max=0.444\n",
      "1 vs 39: mean=0.231, max=0.468\n",
      "1 vs 40: mean=0.244, max=0.345\n",
      "1 vs 41: mean=0.237, max=0.453\n",
      "1 vs 42: mean=0.225, max=0.432\n",
      "1 vs 43: mean=0.367, max=0.549\n",
      "1 vs 44: mean=0.299, max=0.530\n",
      "1 vs 45: mean=0.256, max=0.506\n",
      "1 vs 46: mean=0.349, max=0.585\n",
      "1 vs 47: mean=0.254, max=0.462\n",
      "1 vs 48: mean=0.326, max=0.544\n",
      "1 vs 49: mean=0.325, max=0.555\n",
      "1 vs 50: mean=0.222, max=0.482\n",
      "1 vs 51: mean=0.177, max=0.344\n",
      "1 vs 52: mean=0.364, max=0.628\n",
      "1 vs 53: mean=0.115, max=0.306\n",
      "1 vs 54: mean=0.184, max=0.371\n",
      "1 vs 55: mean=0.361, max=0.556\n",
      "1 vs 56: mean=0.128, max=0.364\n",
      "1 vs 57: mean=0.266, max=0.509\n",
      "1 vs 58: mean=0.176, max=0.328\n",
      "1 vs 59: mean=0.191, max=0.379\n",
      "1 vs 60: mean=0.211, max=0.407\n",
      "1 vs 61: mean=0.168, max=0.379\n",
      "1 vs 62: mean=0.162, max=0.349\n",
      "1 vs 63: mean=0.355, max=0.689\n",
      "1 vs 64: mean=0.345, max=0.491\n",
      "1 vs 65: mean=0.439, max=0.639\n",
      "1 vs 66: mean=0.253, max=0.470\n",
      "1 vs 67: mean=0.181, max=0.405\n",
      "1 vs 68: mean=0.268, max=0.483\n",
      "1 vs 69: mean=0.374, max=0.613\n",
      "1 vs 70: mean=0.159, max=0.331\n",
      "1 vs 71: mean=0.124, max=0.306\n",
      "1 vs 72: mean=0.207, max=0.393\n",
      "1 vs 73: mean=0.268, max=0.444\n",
      "1 vs 74: mean=0.262, max=0.392\n",
      "1 vs 75: mean=0.284, max=0.486\n",
      "1 vs 76: mean=0.175, max=0.312\n",
      "1 vs 77: mean=0.159, max=0.347\n",
      "1 vs 78: mean=0.382, max=0.580\n",
      "1 vs 79: mean=0.231, max=0.441\n",
      "1 vs 80: mean=0.265, max=0.564\n",
      "1 vs 81: mean=0.132, max=0.361\n",
      "1 vs 82: mean=0.125, max=0.243\n",
      "1 vs 83: mean=0.075, max=0.192\n",
      "1 vs 84: mean=0.169, max=0.327\n",
      "1 vs 85: mean=0.307, max=0.510\n",
      "1 vs 86: mean=0.173, max=0.366\n",
      "1 vs 87: mean=0.256, max=0.393\n",
      "1 vs 88: mean=0.183, max=0.326\n",
      "1 vs 89: mean=0.359, max=0.608\n",
      "1 vs 90: mean=-0.129, max=-0.016\n",
      "1 vs 91: mean=-0.076, max=0.048\n",
      "1 vs 92: mean=-0.038, max=0.162\n",
      "1 vs 93: mean=-0.091, max=0.065\n",
      "1 vs 94: mean=-0.030, max=0.141\n",
      "1 vs 95: mean=-0.133, max=0.072\n",
      "1 vs 96: mean=-0.147, max=0.006\n",
      "1 vs 97: mean=0.142, max=0.279\n",
      "1 vs 98: mean=0.094, max=0.290\n",
      "1 vs 99: mean=-0.129, max=0.019\n",
      "1 vs 100: mean=0.162, max=0.423\n",
      "1 vs 101: mean=-0.057, max=0.099\n",
      "1 vs 102: mean=-0.004, max=0.155\n",
      "1 vs 103: mean=-0.007, max=0.135\n",
      "1 vs 104: mean=-0.013, max=0.155\n",
      "1 vs 105: mean=0.052, max=0.202\n",
      "1 vs 106: mean=0.142, max=0.430\n",
      "1 vs 107: mean=-0.107, max=0.074\n",
      "1 vs 108: mean=0.011, max=0.153\n",
      "1 vs 109: mean=0.176, max=0.388\n",
      "1 vs 110: mean=0.141, max=0.508\n",
      "1 vs 111: mean=0.003, max=0.236\n",
      "1 vs 112: mean=-0.036, max=0.124\n",
      "1 vs 113: mean=0.089, max=0.276\n",
      "1 vs 114: mean=-0.003, max=0.166\n",
      "1 vs 115: mean=0.079, max=0.354\n",
      "1 vs 116: mean=-0.088, max=0.038\n",
      "1 vs 117: mean=-0.109, max=0.001\n",
      "1 vs 118: mean=-0.177, max=-0.084\n",
      "1 vs 119: mean=-0.098, max=0.077\n",
      "1 vs 120: mean=-0.067, max=0.063\n",
      "1 vs 121: mean=0.149, max=0.411\n",
      "1 vs 122: mean=0.083, max=0.215\n",
      "1 vs 123: mean=-0.116, max=0.038\n",
      "1 vs 124: mean=-0.044, max=0.060\n",
      "1 vs 125: mean=0.064, max=0.264\n",
      "1 vs 126: mean=-0.031, max=0.076\n",
      "1 vs 127: mean=0.032, max=0.195\n",
      "1 vs 128: mean=-0.089, max=-0.004\n",
      "1 vs 129: mean=-0.070, max=0.041\n",
      "1 vs 130: mean=-0.008, max=0.170\n",
      "1 vs 131: mean=-0.077, max=0.133\n",
      "1 vs 132: mean=-0.048, max=0.061\n",
      "1 vs 133: mean=0.074, max=0.280\n",
      "1 vs 134: mean=-0.039, max=0.108\n",
      "1 vs 135: mean=0.022, max=0.156\n",
      "1 vs 136: mean=0.034, max=0.191\n",
      "1 vs 137: mean=-0.048, max=0.095\n",
      "1 vs 138: mean=0.021, max=0.193\n",
      "1 vs 139: mean=-0.055, max=0.120\n",
      "1 vs 140: mean=-0.062, max=0.075\n",
      "1 vs 141: mean=-0.025, max=0.072\n",
      "1 vs 142: mean=0.262, max=0.533\n",
      "1 vs 143: mean=-0.038, max=0.149\n",
      "1 vs 144: mean=0.056, max=0.272\n",
      "1 vs 145: mean=-0.028, max=0.149\n",
      "1 vs 146: mean=0.000, max=0.140\n",
      "1 vs 147: mean=-0.077, max=0.056\n",
      "1 vs 148: mean=0.110, max=0.252\n",
      "1 vs 149: mean=-0.130, max=-0.043\n",
      "1 vs 150: mean=0.030, max=0.199\n",
      "1 vs 151: mean=-0.061, max=0.027\n",
      "1 vs 152: mean=-0.016, max=0.244\n",
      "1 vs 153: mean=0.046, max=0.311\n",
      "1 vs 154: mean=-0.108, max=-0.008\n",
      "1 vs 155: mean=-0.073, max=0.050\n",
      "1 vs 156: mean=0.044, max=0.165\n",
      "1 vs 157: mean=-0.004, max=0.109\n",
      "1 vs 158: mean=-0.088, max=0.107\n",
      "1 vs 159: mean=-0.039, max=0.127\n",
      "1 vs 160: mean=-0.092, max=0.028\n",
      "1 vs 161: mean=-0.175, max=-0.076\n",
      "1 vs 162: mean=-0.094, max=0.098\n",
      "1 vs 163: mean=0.008, max=0.202\n",
      "1 vs 164: mean=-0.140, max=-0.001\n",
      "1 vs 165: mean=0.077, max=0.259\n",
      "1 vs 166: mean=0.003, max=0.091\n",
      "1 vs 167: mean=-0.101, max=0.008\n",
      "1 vs 168: mean=-0.002, max=0.159\n",
      "1 vs 169: mean=-0.113, max=0.031\n",
      "1 vs 170: mean=0.048, max=0.207\n",
      "1 vs 171: mean=-0.084, max=0.030\n",
      "1 vs 172: mean=-0.032, max=0.214\n",
      "1 vs 173: mean=0.001, max=0.230\n",
      "1 vs 174: mean=0.145, max=0.310\n",
      "1 vs 175: mean=0.072, max=0.246\n",
      "1 vs 176: mean=-0.068, max=0.028\n",
      "1 vs 177: mean=-0.162, max=0.018\n",
      "1 vs 178: mean=-0.177, max=-0.092\n",
      "1 vs 179: mean=-0.065, max=0.091\n",
      "1 vs 180: mean=-0.032, max=0.077\n",
      "1 vs 181: mean=-0.104, max=0.054\n",
      "1 vs 182: mean=-0.085, max=0.022\n",
      "1 vs 183: mean=0.134, max=0.261\n",
      "1 vs 184: mean=-0.175, max=-0.041\n",
      "1 vs 185: mean=-0.010, max=0.101\n",
      "1 vs 186: mean=0.251, max=0.550\n",
      "1 vs 187: mean=-0.045, max=0.063\n",
      "1 vs 188: mean=-0.082, max=0.077\n",
      "1 vs 189: mean=0.136, max=0.290\n",
      "1 vs 190: mean=-0.130, max=0.016\n",
      "1 vs 191: mean=-0.209, max=-0.023\n",
      "1 vs 192: mean=-0.074, max=0.062\n",
      "1 vs 193: mean=-0.033, max=0.067\n",
      "1 vs 194: mean=-0.043, max=0.064\n",
      "1 vs 195: mean=-0.076, max=0.040\n",
      "1 vs 196: mean=0.078, max=0.232\n",
      "1 vs 197: mean=-0.054, max=0.092\n",
      "1 vs 198: mean=-0.116, max=0.125\n",
      "1 vs 199: mean=0.039, max=0.220\n",
      "1 vs 200: mean=-0.021, max=0.277\n",
      "1 vs 201: mean=-0.142, max=-0.009\n",
      "1 vs 202: mean=-0.111, max=-0.009\n",
      "1 vs 203: mean=0.054, max=0.267\n",
      "1 vs 204: mean=-0.098, max=0.033\n",
      "1 vs 205: mean=-0.072, max=0.105\n",
      "1 vs 206: mean=0.116, max=0.264\n",
      "1 vs 207: mean=-0.104, max=0.061\n",
      "1 vs 208: mean=-0.094, max=0.106\n",
      "1 vs 209: mean=-0.181, max=-0.074\n",
      "1 vs 210: mean=0.011, max=0.149\n",
      "1 vs 211: mean=-0.050, max=0.040\n",
      "1 vs 212: mean=-0.086, max=0.044\n",
      "1 vs 213: mean=0.066, max=0.353\n",
      "1 vs 214: mean=0.004, max=0.240\n",
      "1 vs 215: mean=-0.038, max=0.133\n",
      "1 vs 216: mean=0.026, max=0.220\n",
      "1 vs 217: mean=-0.048, max=0.175\n",
      "1 vs 218: mean=0.010, max=0.118\n",
      "1 vs 219: mean=-0.074, max=0.081\n",
      "1 vs 220: mean=0.074, max=0.219\n",
      "1 vs 221: mean=-0.012, max=0.135\n",
      "1 vs 222: mean=-0.089, max=0.032\n",
      "1 vs 223: mean=-0.025, max=0.164\n",
      "1 vs 224: mean=-0.142, max=-0.061\n",
      "1 vs 225: mean=-0.159, max=-0.047\n",
      "1 vs 226: mean=0.139, max=0.464\n",
      "1 vs 227: mean=0.119, max=0.286\n",
      "1 vs 228: mean=-0.070, max=0.056\n",
      "1 vs 229: mean=0.014, max=0.183\n",
      "1 vs 230: mean=-0.121, max=0.055\n",
      "1 vs 231: mean=0.148, max=0.309\n",
      "1 vs 232: mean=-0.081, max=0.130\n",
      "1 vs 233: mean=-0.187, max=-0.072\n",
      "1 vs 234: mean=0.080, max=0.299\n",
      "1 vs 235: mean=-0.038, max=0.109\n",
      "1 vs 236: mean=-0.065, max=0.070\n",
      "1 vs 237: mean=-0.138, max=0.009\n",
      "1 vs 238: mean=0.093, max=0.244\n",
      "1 vs 239: mean=0.001, max=0.165\n",
      "1 vs 240: mean=-0.082, max=0.014\n",
      "1 vs 241: mean=-0.077, max=0.101\n",
      "1 vs 242: mean=-0.032, max=0.182\n",
      "1 vs 243: mean=-0.141, max=-0.025\n",
      "1 vs 244: mean=-0.078, max=0.099\n",
      "1 vs 245: mean=0.001, max=0.098\n",
      "1 vs 246: mean=-0.000, max=0.186\n",
      "1 vs 247: mean=-0.048, max=0.087\n",
      "1 vs 248: mean=-0.100, max=0.043\n",
      "1 vs 249: mean=-0.120, max=-0.008\n",
      "1 vs 250: mean=0.012, max=0.155\n",
      "1 vs 251: mean=0.038, max=0.175\n",
      "1 vs 252: mean=-0.021, max=0.096\n",
      "1 vs 253: mean=-0.132, max=-0.051\n",
      "1 vs 254: mean=-0.064, max=0.038\n",
      "1 vs 255: mean=-0.077, max=0.037\n",
      "1 vs 256: mean=-0.068, max=0.041\n",
      "1 vs 257: mean=-0.197, max=-0.050\n",
      "1 vs 258: mean=-0.151, max=-0.028\n",
      "1 vs 259: mean=-0.038, max=0.060\n",
      "1 vs 260: mean=-0.023, max=0.111\n",
      "1 vs 261: mean=-0.083, max=0.011\n",
      "1 vs 262: mean=-0.109, max=0.014\n",
      "1 vs 263: mean=-0.025, max=0.147\n",
      "1 vs 264: mean=-0.070, max=0.107\n",
      "1 vs 265: mean=-0.143, max=0.019\n",
      "1 vs 266: mean=-0.099, max=-0.000\n",
      "1 vs 267: mean=-0.107, max=-0.024\n",
      "1 vs 268: mean=-0.063, max=0.064\n",
      "1 vs 269: mean=-0.051, max=0.141\n",
      "1 vs 270: mean=0.042, max=0.158\n",
      "1 vs 271: mean=-0.075, max=0.022\n",
      "1 vs 272: mean=-0.138, max=-0.026\n",
      "1 vs 273: mean=0.001, max=0.170\n",
      "1 vs 274: mean=-0.083, max=0.009\n",
      "1 vs 275: mean=-0.113, max=-0.013\n",
      "1 vs 276: mean=-0.061, max=0.027\n",
      "1 vs 277: mean=-0.038, max=0.158\n",
      "1 vs 278: mean=-0.109, max=-0.025\n",
      "1 vs 279: mean=-0.110, max=-0.020\n",
      "1 vs 280: mean=-0.007, max=0.043\n",
      "1 vs 281: mean=-0.141, max=-0.042\n",
      "1 vs 282: mean=-0.008, max=0.094\n",
      "1 vs 283: mean=-0.145, max=-0.039\n",
      "1 vs 284: mean=-0.061, max=0.055\n",
      "1 vs 285: mean=0.017, max=0.238\n",
      "1 vs 286: mean=-0.091, max=0.021\n",
      "1 vs 287: mean=-0.162, max=-0.080\n",
      "1 vs 288: mean=0.017, max=0.160\n",
      "1 vs 289: mean=-0.062, max=0.056\n",
      "1 vs 290: mean=-0.061, max=0.012\n",
      "1 vs 291: mean=-0.028, max=0.053\n",
      "1 vs 292: mean=-0.004, max=0.224\n",
      "1 vs 293: mean=-0.039, max=0.080\n",
      "1 vs 294: mean=-0.133, max=-0.028\n",
      "1 vs 295: mean=-0.101, max=0.023\n",
      "1 vs 296: mean=-0.081, max=0.065\n",
      "1 vs 297: mean=0.014, max=0.152\n",
      "1 vs 298: mean=-0.154, max=-0.024\n",
      "1 vs 299: mean=0.070, max=0.237\n",
      "1 vs 300: mean=0.035, max=0.210\n",
      "1 vs 301: mean=0.067, max=0.183\n",
      "1 vs 302: mean=-0.040, max=0.065\n",
      "1 vs 303: mean=-0.106, max=0.012\n",
      "1 vs 304: mean=-0.022, max=0.121\n",
      "1 vs 305: mean=0.002, max=0.075\n",
      "1 vs 306: mean=-0.093, max=0.067\n",
      "1 vs 307: mean=-0.052, max=0.117\n",
      "1 vs 308: mean=-0.119, max=-0.002\n",
      "1 vs 309: mean=-0.046, max=0.096\n",
      "1 vs 310: mean=-0.100, max=0.034\n",
      "1 vs 311: mean=-0.090, max=0.025\n",
      "1 vs 312: mean=-0.103, max=0.038\n",
      "1 vs 313: mean=-0.088, max=0.097\n",
      "1 vs 314: mean=0.022, max=0.126\n",
      "1 vs 315: mean=-0.021, max=0.069\n",
      "1 vs 316: mean=-0.089, max=-0.010\n",
      "1 vs 317: mean=-0.105, max=-0.025\n",
      "1 vs 318: mean=-0.063, max=0.142\n",
      "1 vs 319: mean=0.014, max=0.142\n",
      "1 vs 320: mean=-0.062, max=0.036\n",
      "1 vs 321: mean=-0.039, max=0.087\n",
      "1 vs 322: mean=-0.137, max=-0.004\n",
      "1 vs 323: mean=0.045, max=0.145\n",
      "1 vs 324: mean=0.018, max=0.126\n",
      "1 vs 325: mean=-0.047, max=0.060\n",
      "1 vs 326: mean=-0.081, max=0.019\n",
      "1 vs 327: mean=-0.057, max=0.030\n",
      "1 vs 328: mean=0.046, max=0.211\n",
      "1 vs 329: mean=0.002, max=0.100\n",
      "1 vs 330: mean=-0.079, max=0.029\n",
      "1 vs 331: mean=-0.062, max=0.060\n",
      "1 vs 332: mean=-0.043, max=0.045\n",
      "1 vs 333: mean=0.018, max=0.175\n",
      "1 vs 334: mean=-0.055, max=0.061\n",
      "1 vs 335: mean=-0.111, max=-0.002\n",
      "1 vs 336: mean=-0.108, max=0.008\n",
      "1 vs 337: mean=-0.047, max=0.111\n",
      "1 vs 338: mean=-0.103, max=0.016\n",
      "1 vs 339: mean=-0.002, max=0.096\n",
      "1 vs 340: mean=-0.126, max=-0.044\n",
      "1 vs 341: mean=-0.022, max=0.072\n",
      "1 vs 342: mean=-0.017, max=0.119\n",
      "1 vs 343: mean=-0.039, max=0.075\n",
      "1 vs 344: mean=0.023, max=0.089\n",
      "1 vs 345: mean=-0.023, max=0.114\n",
      "1 vs 346: mean=0.032, max=0.118\n",
      "1 vs 347: mean=-0.026, max=0.084\n",
      "1 vs 348: mean=0.044, max=0.205\n",
      "1 vs 349: mean=0.060, max=0.184\n",
      "1 vs 350: mean=0.035, max=0.201\n",
      "1 vs 351: mean=-0.085, max=0.082\n",
      "1 vs 352: mean=-0.027, max=0.097\n",
      "1 vs 353: mean=0.041, max=0.234\n",
      "1 vs 354: mean=-0.034, max=0.081\n",
      "1 vs 355: mean=-0.039, max=0.073\n",
      "1 vs 356: mean=-0.089, max=0.055\n",
      "1 vs 357: mean=-0.047, max=0.057\n",
      "1 vs 358: mean=-0.049, max=0.044\n",
      "1 vs 359: mean=-0.046, max=0.089\n",
      "1 vs 360: mean=-0.071, max=0.031\n",
      "1 vs 361: mean=-0.031, max=0.072\n",
      "1 vs 362: mean=-0.023, max=0.070\n",
      "1 vs 363: mean=-0.032, max=0.150\n",
      "1 vs 364: mean=0.049, max=0.176\n",
      "1 vs 365: mean=0.093, max=0.210\n",
      "1 vs 366: mean=0.104, max=0.204\n",
      "1 vs 367: mean=-0.052, max=0.117\n",
      "1 vs 368: mean=-0.078, max=0.011\n",
      "1 vs 369: mean=-0.043, max=0.065\n",
      "1 vs 370: mean=-0.101, max=0.030\n",
      "1 vs 371: mean=-0.088, max=0.057\n",
      "1 vs 372: mean=0.001, max=0.174\n",
      "1 vs 373: mean=-0.089, max=0.168\n",
      "1 vs 374: mean=-0.023, max=0.239\n",
      "1 vs 375: mean=0.007, max=0.191\n",
      "1 vs 376: mean=-0.013, max=0.263\n",
      "1 vs 377: mean=-0.069, max=0.187\n",
      "1 vs 378: mean=0.002, max=0.200\n",
      "1 vs 379: mean=-0.098, max=0.099\n",
      "1 vs 380: mean=-0.087, max=0.036\n",
      "1 vs 381: mean=0.018, max=0.124\n",
      "1 vs 382: mean=-0.039, max=0.110\n",
      "1 vs 383: mean=-0.034, max=0.080\n",
      "1 vs 384: mean=-0.097, max=0.021\n",
      "1 vs 385: mean=-0.165, max=-0.008\n",
      "1 vs 386: mean=-0.078, max=0.042\n",
      "1 vs 387: mean=-0.066, max=0.055\n",
      "1 vs 388: mean=-0.044, max=0.189\n",
      "1 vs 389: mean=-0.082, max=0.076\n",
      "1 vs 390: mean=-0.016, max=0.067\n",
      "1 vs 391: mean=0.006, max=0.111\n",
      "1 vs 392: mean=-0.162, max=-0.034\n",
      "1 vs 393: mean=-0.133, max=-0.001\n",
      "1 vs 394: mean=-0.064, max=0.039\n",
      "1 vs 395: mean=-0.161, max=-0.035\n",
      "1 vs 396: mean=-0.050, max=0.041\n",
      "1 vs 397: mean=-0.060, max=0.097\n",
      "1 vs 398: mean=-0.076, max=0.068\n",
      "1 vs 399: mean=-0.076, max=0.086\n",
      "1 vs 400: mean=-0.011, max=0.113\n",
      "1 vs 401: mean=0.039, max=0.136\n",
      "1 vs 402: mean=-0.005, max=0.117\n",
      "1 vs 403: mean=-0.094, max=0.051\n",
      "1 vs 404: mean=-0.105, max=-0.024\n",
      "1 vs 405: mean=0.064, max=0.203\n",
      "1 vs 406: mean=-0.027, max=0.128\n",
      "1 vs 407: mean=-0.093, max=0.164\n",
      "1 vs 408: mean=-0.003, max=0.082\n",
      "1 vs 409: mean=-0.046, max=0.061\n",
      "1 vs 410: mean=-0.094, max=-0.006\n",
      "1 vs 411: mean=-0.136, max=-0.010\n",
      "1 vs 412: mean=0.001, max=0.073\n",
      "1 vs 413: mean=-0.093, max=0.032\n",
      "1 vs 414: mean=-0.071, max=0.072\n",
      "1 vs 415: mean=-0.053, max=0.029\n",
      "1 vs 416: mean=-0.054, max=0.020\n",
      "1 vs 417: mean=-0.089, max=-0.021\n",
      "1 vs 418: mean=0.010, max=0.080\n",
      "1 vs 419: mean=-0.062, max=0.061\n",
      "1 vs 420: mean=-0.036, max=0.085\n",
      "1 vs 421: mean=-0.088, max=0.034\n",
      "1 vs 422: mean=-0.021, max=0.064\n",
      "1 vs 423: mean=0.003, max=0.150\n",
      "1 vs 424: mean=-0.029, max=0.103\n",
      "1 vs 425: mean=0.072, max=0.172\n",
      "1 vs 426: mean=0.000, max=0.136\n",
      "1 vs 427: mean=-0.035, max=0.076\n",
      "1 vs 428: mean=0.030, max=0.183\n",
      "1 vs 429: mean=0.025, max=0.120\n",
      "1 vs 430: mean=-0.001, max=0.089\n",
      "1 vs 431: mean=-0.006, max=0.177\n",
      "1 vs 432: mean=-0.045, max=0.055\n",
      "1 vs 433: mean=-0.018, max=0.081\n",
      "1 vs 434: mean=-0.017, max=0.065\n",
      "1 vs 435: mean=-0.058, max=0.016\n",
      "1 vs 436: mean=0.010, max=0.114\n",
      "1 vs 437: mean=-0.066, max=0.065\n",
      "1 vs 438: mean=-0.034, max=0.058\n",
      "1 vs 439: mean=0.023, max=0.091\n",
      "1 vs 440: mean=-0.017, max=0.101\n",
      "1 vs 441: mean=-0.021, max=0.096\n",
      "1 vs 442: mean=-0.001, max=0.229\n",
      "1 vs 443: mean=-0.113, max=-0.032\n",
      "1 vs 444: mean=-0.053, max=0.022\n",
      "1 vs 445: mean=-0.031, max=0.028\n",
      "1 vs 446: mean=0.079, max=0.193\n",
      "1 vs 447: mean=0.039, max=0.149\n",
      "1 vs 448: mean=-0.050, max=0.053\n",
      "1 vs 449: mean=0.073, max=0.201\n",
      "1 vs 450: mean=-0.032, max=0.073\n",
      "1 vs 451: mean=0.012, max=0.122\n",
      "1 vs 452: mean=-0.118, max=-0.016\n",
      "1 vs 453: mean=0.020, max=0.116\n",
      "1 vs 454: mean=-0.118, max=0.040\n",
      "1 vs 455: mean=-0.003, max=0.206\n",
      "1 vs 456: mean=-0.074, max=0.066\n",
      "1 vs 457: mean=-0.041, max=0.077\n",
      "1 vs 458: mean=-0.071, max=0.021\n",
      "1 vs 459: mean=-0.043, max=0.024\n",
      "1 vs 460: mean=0.032, max=0.266\n",
      "1 vs 461: mean=0.010, max=0.219\n",
      "1 vs 462: mean=-0.147, max=-0.027\n",
      "1 vs 463: mean=-0.062, max=0.029\n",
      "1 vs 464: mean=-0.133, max=-0.018\n",
      "1 vs 465: mean=-0.152, max=-0.034\n",
      "1 vs 466: mean=-0.113, max=0.019\n",
      "1 vs 467: mean=-0.048, max=0.085\n",
      "1 vs 468: mean=-0.079, max=0.100\n",
      "1 vs 469: mean=-0.154, max=-0.039\n",
      "1 vs 470: mean=0.087, max=0.177\n",
      "1 vs 471: mean=-0.030, max=0.033\n",
      "1 vs 472: mean=0.060, max=0.159\n",
      "1 vs 473: mean=-0.037, max=0.036\n",
      "1 vs 474: mean=0.034, max=0.130\n",
      "1 vs 475: mean=0.052, max=0.130\n",
      "1 vs 476: mean=-0.010, max=0.046\n",
      "1 vs 477: mean=0.002, max=0.096\n",
      "1 vs 478: mean=-0.023, max=0.067\n",
      "1 vs 479: mean=-0.012, max=0.061\n",
      "1 vs 480: mean=-0.064, max=0.031\n",
      "1 vs 481: mean=0.057, max=0.175\n",
      "1 vs 482: mean=0.062, max=0.138\n",
      "1 vs 483: mean=0.042, max=0.140\n",
      "1 vs 484: mean=-0.033, max=0.076\n",
      "1 vs 485: mean=-0.008, max=0.113\n",
      "1 vs 486: mean=0.020, max=0.126\n",
      "1 vs 487: mean=0.019, max=0.139\n",
      "1 vs 488: mean=0.015, max=0.148\n",
      "1 vs 489: mean=-0.009, max=0.067\n",
      "1 vs 490: mean=0.103, max=0.258\n",
      "1 vs 491: mean=0.121, max=0.226\n",
      "1 vs 492: mean=-0.060, max=0.079\n",
      "1 vs 493: mean=-0.024, max=0.092\n",
      "1 vs 494: mean=-0.029, max=0.069\n",
      "1 vs 495: mean=-0.004, max=0.079\n",
      "1 vs 496: mean=-0.031, max=0.111\n",
      "1 vs 497: mean=-0.085, max=0.039\n",
      "1 vs 498: mean=-0.012, max=0.114\n",
      "1 vs 499: mean=-0.018, max=0.067\n",
      "1 vs 500: mean=-0.010, max=0.167\n",
      "1 vs 501: mean=-0.008, max=0.117\n",
      "1 vs 502: mean=0.066, max=0.167\n",
      "1 vs 503: mean=-0.012, max=0.087\n",
      "1 vs 504: mean=-0.054, max=0.058\n",
      "1 vs 505: mean=-0.014, max=0.087\n",
      "1 vs 506: mean=-0.077, max=0.030\n",
      "1 vs 507: mean=-0.014, max=0.119\n",
      "1 vs 508: mean=-0.008, max=0.150\n",
      "1 vs 509: mean=-0.053, max=0.036\n",
      "1 vs 510: mean=0.044, max=0.142\n",
      "1 vs 511: mean=0.023, max=0.159\n",
      "1 vs 512: mean=0.025, max=0.092\n",
      "1 vs 513: mean=0.032, max=0.171\n",
      "1 vs 514: mean=-0.069, max=0.046\n",
      "1 vs 515: mean=0.018, max=0.125\n",
      "1 vs 516: mean=0.048, max=0.131\n",
      "1 vs 517: mean=-0.012, max=0.080\n",
      "1 vs 518: mean=-0.071, max=0.105\n",
      "1 vs 519: mean=0.075, max=0.155\n",
      "1 vs 520: mean=-0.029, max=0.086\n",
      "1 vs 521: mean=-0.006, max=0.072\n",
      "1 vs 522: mean=-0.079, max=0.040\n",
      "1 vs 523: mean=-0.013, max=0.122\n",
      "1 vs 524: mean=-0.117, max=-0.027\n",
      "1 vs 525: mean=-0.046, max=0.069\n",
      "1 vs 526: mean=-0.052, max=0.072\n",
      "1 vs 527: mean=0.065, max=0.178\n",
      "1 vs 528: mean=-0.023, max=0.115\n",
      "1 vs 529: mean=-0.037, max=0.114\n",
      "1 vs 530: mean=0.033, max=0.106\n",
      "1 vs 531: mean=0.063, max=0.164\n",
      "1 vs 532: mean=0.006, max=0.123\n",
      "1 vs 533: mean=-0.065, max=0.070\n",
      "1 vs 534: mean=-0.010, max=0.115\n",
      "1 vs 535: mean=-0.046, max=0.075\n",
      "1 vs 536: mean=-0.019, max=0.134\n",
      "1 vs 537: mean=0.025, max=0.116\n",
      "1 vs 538: mean=0.031, max=0.122\n",
      "1 vs 539: mean=0.015, max=0.132\n",
      "1 vs 540: mean=0.049, max=0.118\n",
      "1 vs 541: mean=0.052, max=0.129\n",
      "1 vs 542: mean=-0.033, max=0.088\n",
      "1 vs 543: mean=0.009, max=0.133\n",
      "1 vs 544: mean=-0.056, max=0.039\n",
      "1 vs 545: mean=0.004, max=0.151\n",
      "1 vs 546: mean=-0.005, max=0.084\n",
      "1 vs 547: mean=0.056, max=0.129\n",
      "1 vs 548: mean=-0.034, max=0.087\n",
      "1 vs 549: mean=0.094, max=0.186\n",
      "1 vs 550: mean=-0.049, max=0.110\n",
      "1 vs 551: mean=-0.057, max=0.152\n",
      "1 vs 552: mean=0.018, max=0.151\n",
      "1 vs 553: mean=-0.053, max=0.083\n",
      "1 vs 554: mean=-0.023, max=0.060\n",
      "1 vs 555: mean=-0.077, max=0.072\n",
      "1 vs 556: mean=-0.016, max=0.100\n",
      "1 vs 557: mean=-0.021, max=0.199\n",
      "1 vs 558: mean=-0.022, max=0.114\n",
      "1 vs 559: mean=-0.067, max=0.091\n",
      "1 vs 560: mean=-0.012, max=0.140\n",
      "1 vs 561: mean=-0.053, max=0.076\n",
      "1 vs 562: mean=-0.069, max=0.029\n",
      "1 vs 563: mean=0.029, max=0.191\n",
      "1 vs 564: mean=-0.024, max=0.076\n",
      "1 vs 565: mean=-0.145, max=-0.033\n",
      "1 vs 566: mean=-0.075, max=0.056\n",
      "1 vs 567: mean=-0.055, max=0.085\n",
      "1 vs 568: mean=0.001, max=0.130\n",
      "1 vs 569: mean=-0.088, max=0.051\n",
      "1 vs 570: mean=0.001, max=0.101\n",
      "1 vs 571: mean=-0.038, max=0.094\n",
      "1 vs 572: mean=0.031, max=0.154\n",
      "1 vs 573: mean=-0.020, max=0.102\n",
      "1 vs 574: mean=0.033, max=0.198\n",
      "1 vs 575: mean=0.005, max=0.103\n",
      "1 vs 576: mean=-0.143, max=-0.027\n",
      "1 vs 577: mean=-0.029, max=0.220\n",
      "1 vs 578: mean=-0.024, max=0.083\n",
      "1 vs 579: mean=-0.042, max=0.063\n",
      "1 vs 580: mean=0.051, max=0.154\n",
      "1 vs 581: mean=-0.074, max=0.055\n",
      "1 vs 582: mean=-0.045, max=0.104\n",
      "1 vs 583: mean=0.008, max=0.168\n",
      "1 vs 584: mean=-0.092, max=0.028\n",
      "1 vs 585: mean=-0.018, max=0.111\n",
      "1 vs 586: mean=-0.058, max=0.045\n",
      "1 vs 587: mean=-0.049, max=0.068\n",
      "1 vs 588: mean=-0.047, max=0.078\n",
      "1 vs 589: mean=-0.169, max=0.033\n",
      "1 vs 590: mean=-0.013, max=0.121\n",
      "1 vs 591: mean=-0.076, max=0.058\n",
      "1 vs 592: mean=-0.020, max=0.105\n",
      "1 vs 593: mean=-0.080, max=0.099\n",
      "1 vs 594: mean=-0.049, max=0.119\n",
      "1 vs 595: mean=-0.045, max=0.112\n",
      "1 vs 596: mean=-0.021, max=0.153\n",
      "1 vs 597: mean=0.005, max=0.134\n",
      "1 vs 598: mean=0.012, max=0.174\n",
      "1 vs 599: mean=0.038, max=0.138\n",
      "1 vs 600: mean=-0.066, max=0.097\n",
      "1 vs 601: mean=-0.018, max=0.115\n",
      "1 vs 602: mean=0.032, max=0.177\n",
      "1 vs 603: mean=0.002, max=0.137\n",
      "1 vs 604: mean=0.003, max=0.162\n",
      "1 vs 605: mean=-0.015, max=0.110\n",
      "1 vs 606: mean=0.024, max=0.146\n",
      "1 vs 607: mean=-0.023, max=0.115\n",
      "1 vs 608: mean=0.023, max=0.143\n",
      "1 vs 609: mean=0.043, max=0.161\n",
      "1 vs 610: mean=-0.043, max=0.108\n",
      "1 vs 611: mean=0.002, max=0.128\n",
      "1 vs 612: mean=-0.078, max=0.104\n",
      "1 vs 613: mean=0.033, max=0.139\n",
      "1 vs 614: mean=-0.019, max=0.087\n",
      "1 vs 615: mean=0.039, max=0.123\n",
      "1 vs 616: mean=0.032, max=0.142\n",
      "1 vs 617: mean=-0.029, max=0.101\n",
      "1 vs 618: mean=0.036, max=0.171\n",
      "1 vs 619: mean=-0.068, max=0.070\n",
      "1 vs 620: mean=-0.054, max=0.094\n",
      "1 vs 621: mean=-0.027, max=0.070\n",
      "1 vs 622: mean=-0.032, max=0.112\n",
      "1 vs 623: mean=0.025, max=0.177\n",
      "1 vs 624: mean=-0.020, max=0.082\n",
      "1 vs 625: mean=-0.025, max=0.081\n",
      "1 vs 626: mean=0.067, max=0.183\n",
      "1 vs 627: mean=-0.051, max=0.073\n",
      "1 vs 628: mean=-0.019, max=0.083\n",
      "1 vs 629: mean=-0.010, max=0.075\n",
      "1 vs 630: mean=-0.038, max=0.119\n",
      "1 vs 631: mean=-0.040, max=0.061\n",
      "1 vs 632: mean=0.021, max=0.097\n",
      "1 vs 633: mean=-0.057, max=0.099\n",
      "1 vs 634: mean=0.041, max=0.113\n",
      "1 vs 635: mean=0.001, max=0.105\n",
      "1 vs 636: mean=-0.102, max=0.011\n",
      "1 vs 637: mean=-0.015, max=0.078\n",
      "1 vs 638: mean=-0.041, max=0.094\n",
      "1 vs 639: mean=-0.018, max=0.123\n",
      "1 vs 640: mean=-0.001, max=0.093\n",
      "1 vs 641: mean=-0.024, max=0.119\n",
      "1 vs 642: mean=-0.017, max=0.102\n",
      "1 vs 643: mean=0.036, max=0.169\n",
      "1 vs 644: mean=-0.021, max=0.102\n",
      "1 vs 645: mean=0.001, max=0.116\n",
      "1 vs 646: mean=-0.078, max=0.107\n",
      "1 vs 647: mean=-0.073, max=0.074\n",
      "1 vs 648: mean=-0.043, max=0.053\n",
      "1 vs 649: mean=-0.019, max=0.089\n",
      "1 vs 650: mean=-0.055, max=0.084\n",
      "1 vs 651: mean=0.041, max=0.117\n",
      "1 vs 652: mean=-0.037, max=0.073\n",
      "1 vs 653: mean=-0.058, max=0.048\n",
      "1 vs 654: mean=-0.071, max=0.036\n",
      "1 vs 655: mean=-0.116, max=0.074\n",
      "1 vs 656: mean=0.008, max=0.117\n",
      "1 vs 657: mean=-0.082, max=0.019\n",
      "1 vs 658: mean=-0.082, max=0.032\n",
      "1 vs 659: mean=-0.020, max=0.136\n",
      "1 vs 660: mean=-0.093, max=0.026\n",
      "1 vs 661: mean=-0.083, max=0.025\n",
      "1 vs 662: mean=0.047, max=0.104\n",
      "1 vs 663: mean=0.017, max=0.130\n",
      "1 vs 664: mean=0.003, max=0.167\n",
      "1 vs 665: mean=0.006, max=0.145\n",
      "1 vs 666: mean=-0.020, max=0.089\n",
      "1 vs 667: mean=-0.033, max=0.059\n",
      "1 vs 668: mean=-0.026, max=0.067\n",
      "1 vs 669: mean=-0.118, max=0.042\n",
      "1 vs 670: mean=-0.017, max=0.152\n",
      "1 vs 671: mean=-0.034, max=0.115\n",
      "1 vs 672: mean=0.003, max=0.130\n",
      "1 vs 673: mean=0.050, max=0.158\n",
      "1 vs 674: mean=-0.044, max=0.064\n",
      "1 vs 675: mean=-0.023, max=0.140\n",
      "1 vs 676: mean=-0.067, max=0.044\n",
      "1 vs 677: mean=0.012, max=0.151\n",
      "1 vs 678: mean=-0.036, max=0.168\n",
      "1 vs 679: mean=-0.078, max=0.066\n",
      "1 vs 680: mean=-0.066, max=0.053\n",
      "1 vs 681: mean=-0.096, max=0.129\n",
      "1 vs 682: mean=-0.057, max=0.023\n",
      "1 vs 683: mean=0.031, max=0.122\n",
      "1 vs 684: mean=0.046, max=0.147\n",
      "1 vs 685: mean=0.044, max=0.178\n",
      "1 vs 686: mean=-0.095, max=0.036\n",
      "1 vs 687: mean=0.038, max=0.144\n",
      "1 vs 688: mean=0.002, max=0.132\n",
      "1 vs 689: mean=-0.084, max=0.053\n",
      "1 vs 690: mean=0.024, max=0.158\n",
      "1 vs 691: mean=0.070, max=0.163\n",
      "1 vs 692: mean=0.074, max=0.181\n",
      "1 vs 693: mean=-0.000, max=0.077\n",
      "1 vs 694: mean=0.034, max=0.126\n",
      "1 vs 695: mean=-0.097, max=0.029\n",
      "1 vs 696: mean=0.022, max=0.113\n",
      "1 vs 697: mean=0.046, max=0.147\n",
      "1 vs 698: mean=0.045, max=0.124\n",
      "1 vs 699: mean=0.002, max=0.114\n",
      "1 vs 700: mean=-0.076, max=0.026\n",
      "1 vs 701: mean=0.046, max=0.153\n",
      "1 vs 702: mean=0.104, max=0.216\n",
      "1 vs 703: mean=0.068, max=0.159\n",
      "1 vs 704: mean=0.006, max=0.089\n",
      "1 vs 705: mean=-0.043, max=0.076\n",
      "1 vs 706: mean=0.030, max=0.127\n",
      "1 vs 707: mean=0.073, max=0.198\n",
      "1 vs 708: mean=0.018, max=0.104\n",
      "1 vs 709: mean=0.032, max=0.167\n",
      "1 vs 710: mean=-0.029, max=0.141\n",
      "1 vs 711: mean=-0.029, max=0.110\n",
      "1 vs 712: mean=-0.073, max=0.026\n",
      "1 vs 713: mean=-0.076, max=0.165\n",
      "1 vs 714: mean=-0.020, max=0.089\n",
      "1 vs 715: mean=0.003, max=0.123\n",
      "1 vs 716: mean=-0.012, max=0.063\n",
      "1 vs 717: mean=0.009, max=0.122\n",
      "1 vs 718: mean=0.047, max=0.136\n",
      "1 vs 719: mean=-0.003, max=0.102\n",
      "1 vs 720: mean=-0.018, max=0.097\n",
      "1 vs 721: mean=0.024, max=0.159\n",
      "1 vs 722: mean=0.016, max=0.153\n",
      "1 vs 723: mean=-0.067, max=0.045\n",
      "1 vs 724: mean=0.009, max=0.124\n",
      "1 vs 725: mean=-0.015, max=0.083\n",
      "1 vs 726: mean=0.009, max=0.136\n",
      "1 vs 727: mean=-0.075, max=0.065\n",
      "1 vs 728: mean=0.074, max=0.169\n",
      "1 vs 729: mean=0.057, max=0.211\n",
      "1 vs 730: mean=0.041, max=0.181\n",
      "1 vs 731: mean=0.038, max=0.140\n",
      "1 vs 732: mean=0.063, max=0.113\n",
      "1 vs 733: mean=0.011, max=0.119\n",
      "1 vs 734: mean=0.014, max=0.098\n",
      "1 vs 735: mean=-0.017, max=0.076\n",
      "1 vs 736: mean=0.024, max=0.144\n",
      "1 vs 737: mean=-0.034, max=0.051\n",
      "1 vs 738: mean=0.064, max=0.192\n",
      "1 vs 739: mean=0.055, max=0.159\n",
      "1 vs 740: mean=-0.109, max=0.000\n",
      "1 vs 741: mean=0.005, max=0.106\n",
      "1 vs 742: mean=-0.039, max=0.106\n",
      "1 vs 743: mean=0.015, max=0.130\n",
      "1 vs 744: mean=-0.011, max=0.141\n",
      "1 vs 745: mean=0.042, max=0.150\n",
      "1 vs 746: mean=0.126, max=0.189\n",
      "1 vs 747: mean=-0.053, max=0.069\n",
      "1 vs 748: mean=0.027, max=0.152\n",
      "1 vs 749: mean=0.011, max=0.102\n",
      "1 vs 750: mean=0.188, max=0.317\n",
      "1 vs 751: mean=0.104, max=0.207\n",
      "1 vs 752: mean=0.178, max=0.284\n",
      "1 vs 753: mean=0.124, max=0.220\n",
      "1 vs 754: mean=0.074, max=0.238\n",
      "1 vs 755: mean=0.040, max=0.163\n",
      "1 vs 756: mean=0.008, max=0.156\n",
      "1 vs 757: mean=0.048, max=0.138\n",
      "1 vs 758: mean=0.123, max=0.188\n",
      "1 vs 759: mean=0.068, max=0.153\n",
      "1 vs 760: mean=0.148, max=0.250\n",
      "1 vs 761: mean=0.118, max=0.206\n",
      "1 vs 762: mean=0.177, max=0.265\n",
      "1 vs 763: mean=0.111, max=0.222\n",
      "1 vs 764: mean=0.148, max=0.282\n",
      "1 vs 765: mean=0.105, max=0.199\n",
      "1 vs 766: mean=0.160, max=0.286\n",
      "1 vs 767: mean=0.032, max=0.141\n",
      "1 vs 768: mean=0.110, max=0.219\n",
      "1 vs 769: mean=0.112, max=0.183\n",
      "1 vs 770: mean=0.116, max=0.222\n",
      "1 vs 771: mean=0.131, max=0.254\n",
      "1 vs 772: mean=-0.020, max=0.056\n",
      "1 vs 773: mean=0.120, max=0.206\n",
      "1 vs 774: mean=0.001, max=0.133\n",
      "1 vs 775: mean=0.019, max=0.089\n",
      "1 vs 776: mean=0.091, max=0.189\n",
      "1 vs 777: mean=-0.064, max=0.068\n",
      "1 vs 778: mean=0.019, max=0.098\n",
      "1 vs 779: mean=0.063, max=0.183\n",
      "1 vs 780: mean=0.054, max=0.182\n",
      "1 vs 781: mean=0.033, max=0.125\n",
      "1 vs 782: mean=0.025, max=0.132\n",
      "1 vs 783: mean=0.057, max=0.143\n",
      "1 vs 784: mean=-0.040, max=0.079\n",
      "1 vs 785: mean=0.078, max=0.201\n",
      "1 vs 786: mean=0.121, max=0.259\n",
      "1 vs 787: mean=0.058, max=0.212\n",
      "1 vs 788: mean=-0.024, max=0.135\n",
      "1 vs 789: mean=0.072, max=0.181\n",
      "1 vs 790: mean=0.026, max=0.133\n",
      "1 vs 791: mean=-0.001, max=0.131\n",
      "1 vs 792: mean=0.127, max=0.221\n",
      "1 vs 793: mean=0.010, max=0.093\n",
      "1 vs 794: mean=0.042, max=0.131\n",
      "1 vs 795: mean=0.097, max=0.188\n",
      "1 vs 796: mean=0.015, max=0.143\n",
      "1 vs 797: mean=0.067, max=0.179\n",
      "1 vs 798: mean=0.188, max=0.293\n",
      "1 vs 799: mean=0.199, max=0.273\n",
      "1 vs 800: mean=0.076, max=0.220\n",
      "1 vs 801: mean=0.017, max=0.160\n",
      "1 vs 802: mean=0.015, max=0.116\n",
      "1 vs 803: mean=0.084, max=0.141\n",
      "1 vs 804: mean=0.080, max=0.169\n",
      "1 vs 805: mean=0.046, max=0.158\n",
      "1 vs 806: mean=0.035, max=0.147\n",
      "1 vs 807: mean=0.062, max=0.179\n",
      "1 vs 808: mean=0.030, max=0.143\n",
      "1 vs 809: mean=0.059, max=0.171\n",
      "1 vs 810: mean=0.034, max=0.121\n",
      "1 vs 811: mean=0.034, max=0.120\n",
      "1 vs 812: mean=0.000, max=0.091\n",
      "1 vs 813: mean=-0.045, max=0.058\n",
      "1 vs 814: mean=0.059, max=0.144\n",
      "1 vs 815: mean=0.073, max=0.181\n",
      "1 vs 816: mean=0.087, max=0.188\n",
      "1 vs 817: mean=0.014, max=0.106\n",
      "1 vs 818: mean=0.036, max=0.144\n",
      "1 vs 819: mean=0.038, max=0.128\n",
      "1 vs 820: mean=0.105, max=0.249\n",
      "1 vs 821: mean=0.115, max=0.204\n",
      "1 vs 822: mean=0.038, max=0.195\n",
      "1 vs 823: mean=0.087, max=0.170\n",
      "1 vs 824: mean=0.131, max=0.249\n",
      "1 vs 825: mean=-0.025, max=0.075\n",
      "1 vs 826: mean=-0.098, max=-0.009\n",
      "1 vs 827: mean=0.055, max=0.171\n",
      "1 vs 828: mean=0.037, max=0.122\n",
      "1 vs 829: mean=0.101, max=0.194\n",
      "1 vs 830: mean=0.093, max=0.213\n",
      "1 vs 831: mean=0.029, max=0.197\n",
      "1 vs 832: mean=0.067, max=0.200\n",
      "1 vs 833: mean=0.118, max=0.232\n",
      "1 vs 834: mean=0.089, max=0.176\n",
      "1 vs 835: mean=0.085, max=0.221\n",
      "1 vs 836: mean=0.101, max=0.186\n",
      "1 vs 837: mean=-0.044, max=0.092\n",
      "1 vs 838: mean=0.122, max=0.267\n",
      "1 vs 839: mean=0.108, max=0.202\n",
      "1 vs 840: mean=0.084, max=0.230\n",
      "1 vs 841: mean=0.000, max=0.120\n",
      "1 vs 842: mean=0.033, max=0.220\n",
      "1 vs 843: mean=-0.033, max=0.028\n",
      "1 vs 844: mean=0.021, max=0.145\n",
      "1 vs 845: mean=0.141, max=0.257\n",
      "1 vs 846: mean=-0.071, max=0.097\n",
      "1 vs 847: mean=0.181, max=0.264\n",
      "1 vs 848: mean=0.049, max=0.143\n",
      "1 vs 849: mean=0.180, max=0.261\n",
      "1 vs 850: mean=0.179, max=0.278\n",
      "1 vs 851: mean=0.079, max=0.144\n",
      "1 vs 852: mean=0.102, max=0.193\n",
      "1 vs 853: mean=0.020, max=0.133\n",
      "1 vs 854: mean=0.114, max=0.253\n",
      "1 vs 855: mean=0.006, max=0.086\n",
      "1 vs 856: mean=0.138, max=0.211\n",
      "1 vs 857: mean=0.125, max=0.198\n",
      "1 vs 858: mean=-0.008, max=0.072\n",
      "1 vs 859: mean=-0.069, max=0.038\n",
      "1 vs 860: mean=0.176, max=0.278\n",
      "1 vs 861: mean=0.116, max=0.215\n",
      "1 vs 862: mean=-0.014, max=0.065\n",
      "1 vs 863: mean=0.035, max=0.127\n",
      "1 vs 864: mean=0.021, max=0.110\n",
      "1 vs 865: mean=0.027, max=0.148\n",
      "1 vs 866: mean=0.030, max=0.126\n",
      "1 vs 867: mean=0.101, max=0.172\n",
      "1 vs 868: mean=0.051, max=0.173\n",
      "1 vs 869: mean=0.030, max=0.130\n",
      "1 vs 870: mean=0.061, max=0.199\n",
      "1 vs 871: mean=0.078, max=0.215\n",
      "1 vs 872: mean=0.075, max=0.206\n",
      "1 vs 873: mean=0.058, max=0.139\n",
      "1 vs 874: mean=0.140, max=0.225\n",
      "1 vs 875: mean=0.030, max=0.110\n",
      "1 vs 876: mean=0.047, max=0.189\n",
      "1 vs 877: mean=0.031, max=0.119\n",
      "1 vs 878: mean=0.079, max=0.162\n",
      "1 vs 879: mean=0.087, max=0.171\n",
      "1 vs 880: mean=0.034, max=0.144\n",
      "1 vs 881: mean=0.035, max=0.085\n",
      "1 vs 882: mean=-0.025, max=0.089\n",
      "1 vs 883: mean=0.128, max=0.300\n",
      "1 vs 884: mean=0.026, max=0.165\n",
      "1 vs 885: mean=-0.066, max=0.015\n",
      "1 vs 886: mean=-0.065, max=0.071\n",
      "1 vs 887: mean=0.020, max=0.179\n",
      "1 vs 888: mean=0.126, max=0.261\n",
      "1 vs 889: mean=0.069, max=0.171\n",
      "1 vs 890: mean=0.071, max=0.191\n",
      "1 vs 891: mean=0.112, max=0.242\n",
      "1 vs 892: mean=0.071, max=0.153\n",
      "1 vs 893: mean=0.060, max=0.131\n",
      "1 vs 894: mean=0.090, max=0.167\n",
      "1 vs 895: mean=0.037, max=0.115\n",
      "1 vs 896: mean=0.044, max=0.135\n",
      "1 vs 897: mean=0.110, max=0.207\n",
      "1 vs 898: mean=-0.076, max=0.031\n",
      "1 vs 899: mean=0.052, max=0.128\n",
      "1 vs 900: mean=0.040, max=0.154\n",
      "1 vs 901: mean=0.111, max=0.235\n",
      "1 vs 902: mean=0.070, max=0.141\n",
      "1 vs 903: mean=0.053, max=0.116\n",
      "1 vs 904: mean=0.045, max=0.128\n",
      "1 vs 905: mean=-0.032, max=0.040\n",
      "1 vs 906: mean=0.131, max=0.252\n",
      "1 vs 907: mean=0.041, max=0.178\n",
      "1 vs 908: mean=-0.015, max=0.125\n",
      "1 vs 909: mean=0.070, max=0.206\n",
      "1 vs 910: mean=0.103, max=0.159\n",
      "1 vs 911: mean=0.055, max=0.188\n",
      "1 vs 912: mean=-0.058, max=0.020\n",
      "1 vs 913: mean=0.109, max=0.188\n",
      "1 vs 914: mean=0.104, max=0.195\n",
      "1 vs 915: mean=0.143, max=0.227\n",
      "1 vs 916: mean=-0.056, max=0.010\n",
      "1 vs 917: mean=0.078, max=0.155\n",
      "1 vs 918: mean=0.035, max=0.164\n",
      "1 vs 919: mean=0.080, max=0.158\n",
      "1 vs 920: mean=-0.011, max=0.104\n",
      "1 vs 921: mean=0.014, max=0.145\n",
      "1 vs 922: mean=0.066, max=0.214\n",
      "1 vs 923: mean=0.035, max=0.221\n",
      "1 vs 924: mean=0.021, max=0.138\n",
      "1 vs 925: mean=-0.043, max=0.050\n",
      "1 vs 926: mean=0.124, max=0.206\n",
      "1 vs 927: mean=0.132, max=0.236\n",
      "1 vs 928: mean=0.065, max=0.152\n",
      "1 vs 929: mean=0.055, max=0.147\n",
      "1 vs 930: mean=0.103, max=0.199\n",
      "1 vs 931: mean=0.089, max=0.234\n",
      "1 vs 932: mean=0.117, max=0.213\n",
      "1 vs 933: mean=-0.058, max=0.009\n",
      "1 vs 934: mean=0.073, max=0.156\n",
      "1 vs 935: mean=0.001, max=0.085\n",
      "1 vs 936: mean=0.103, max=0.189\n",
      "1 vs 937: mean=0.092, max=0.231\n",
      "1 vs 938: mean=0.099, max=0.178\n",
      "1 vs 939: mean=-0.024, max=0.152\n",
      "1 vs 940: mean=0.058, max=0.131\n",
      "1 vs 941: mean=0.049, max=0.190\n",
      "1 vs 942: mean=0.063, max=0.141\n",
      "1 vs 943: mean=-0.000, max=0.056\n",
      "1 vs 944: mean=0.128, max=0.212\n",
      "1 vs 945: mean=0.036, max=0.105\n",
      "1 vs 946: mean=0.153, max=0.230\n",
      "1 vs 947: mean=0.033, max=0.131\n",
      "1 vs 948: mean=0.159, max=0.263\n",
      "1 vs 949: mean=0.051, max=0.153\n",
      "1 vs 950: mean=0.024, max=0.122\n",
      "1 vs 951: mean=0.118, max=0.270\n",
      "1 vs 952: mean=0.089, max=0.218\n",
      "1 vs 953: mean=0.020, max=0.106\n",
      "1 vs 954: mean=0.113, max=0.201\n",
      "1 vs 955: mean=0.113, max=0.255\n",
      "1 vs 956: mean=0.066, max=0.180\n",
      "1 vs 957: mean=-0.002, max=0.133\n",
      "1 vs 958: mean=0.087, max=0.158\n",
      "1 vs 959: mean=0.070, max=0.148\n",
      "1 vs 960: mean=0.044, max=0.140\n",
      "1 vs 961: mean=-0.032, max=0.071\n",
      "1 vs 962: mean=0.190, max=0.269\n",
      "1 vs 963: mean=0.086, max=0.199\n",
      "1 vs 964: mean=0.060, max=0.118\n",
      "1 vs 965: mean=0.040, max=0.150\n",
      "1 vs 966: mean=0.058, max=0.170\n",
      "1 vs 967: mean=0.138, max=0.236\n",
      "1 vs 968: mean=0.045, max=0.129\n",
      "1 vs 969: mean=0.102, max=0.241\n",
      "1 vs 970: mean=0.091, max=0.245\n",
      "1 vs 971: mean=-0.074, max=0.071\n",
      "1 vs 972: mean=-0.057, max=0.096\n",
      "1 vs 973: mean=0.024, max=0.157\n",
      "1 vs 974: mean=0.097, max=0.253\n",
      "1 vs 975: mean=0.019, max=0.170\n",
      "1 vs 976: mean=-0.001, max=0.077\n",
      "1 vs 977: mean=-0.006, max=0.095\n",
      "1 vs 978: mean=0.127, max=0.239\n",
      "1 vs 979: mean=-0.022, max=0.152\n",
      "1 vs 980: mean=0.056, max=0.245\n",
      "1 vs 981: mean=0.121, max=0.222\n",
      "1 vs 982: mean=0.086, max=0.150\n",
      "1 vs 983: mean=0.042, max=0.182\n",
      "1 vs 984: mean=-0.115, max=0.021\n",
      "1 vs 985: mean=0.106, max=0.203\n",
      "1 vs 986: mean=0.031, max=0.124\n",
      "1 vs 987: mean=-0.024, max=0.072\n",
      "1 vs 988: mean=0.092, max=0.226\n",
      "1 vs 989: mean=0.038, max=0.154\n",
      "1 vs 990: mean=0.084, max=0.170\n",
      "1 vs 991: mean=0.056, max=0.159\n",
      "1 vs 992: mean=0.031, max=0.123\n",
      "1 vs 993: mean=0.045, max=0.102\n",
      "1 vs 994: mean=0.083, max=0.172\n",
      "1 vs 995: mean=0.073, max=0.158\n",
      "1 vs 996: mean=0.105, max=0.219\n",
      "1 vs 997: mean=0.070, max=0.217\n",
      "1 vs 998: mean=-0.048, max=0.061\n",
      "1 vs 999: mean=0.119, max=0.257\n",
      "1 vs 1000: mean=0.061, max=0.160\n",
      "1 vs 1001: mean=0.050, max=0.155\n",
      "1 vs 1002: mean=0.043, max=0.156\n",
      "1 vs 1003: mean=-0.031, max=0.141\n",
      "1 vs 1004: mean=0.082, max=0.148\n",
      "1 vs 1005: mean=0.130, max=0.223\n",
      "1 vs 1006: mean=0.121, max=0.213\n",
      "1 vs 1007: mean=0.110, max=0.208\n",
      "1 vs 1008: mean=0.039, max=0.159\n",
      "1 vs 1009: mean=0.125, max=0.218\n",
      "1 vs 1010: mean=0.122, max=0.194\n",
      "1 vs 1011: mean=-0.013, max=0.064\n",
      "1 vs 1012: mean=0.052, max=0.169\n",
      "1 vs 1013: mean=0.122, max=0.225\n",
      "1 vs 1014: mean=-0.027, max=0.085\n",
      "1 vs 1015: mean=0.037, max=0.138\n",
      "1 vs 1016: mean=0.039, max=0.166\n",
      "1 vs 1017: mean=-0.073, max=0.000\n",
      "1 vs 1018: mean=0.173, max=0.252\n",
      "1 vs 1019: mean=0.101, max=0.187\n",
      "1 vs 1020: mean=-0.018, max=0.121\n",
      "1 vs 1021: mean=0.045, max=0.122\n",
      "1 vs 1022: mean=0.016, max=0.147\n",
      "1 vs 1023: mean=-0.035, max=0.103\n",
      "1 vs 1024: mean=0.108, max=0.259\n",
      "1 vs 1025: mean=0.035, max=0.135\n",
      "1 vs 1026: mean=-0.019, max=0.090\n",
      "1 vs 1027: mean=-0.069, max=0.018\n",
      "1 vs 1028: mean=-0.041, max=0.062\n",
      "1 vs 1029: mean=-0.004, max=0.108\n",
      "1 vs 1030: mean=0.081, max=0.259\n",
      "1 vs 1031: mean=0.157, max=0.267\n",
      "1 vs 1032: mean=0.071, max=0.166\n",
      "1 vs 1033: mean=0.035, max=0.158\n",
      "1 vs 1034: mean=0.050, max=0.141\n",
      "1 vs 1035: mean=0.120, max=0.188\n",
      "1 vs 1036: mean=0.184, max=0.321\n",
      "1 vs 1037: mean=0.075, max=0.180\n",
      "1 vs 1038: mean=-0.047, max=0.060\n",
      "1 vs 1039: mean=0.053, max=0.138\n",
      "1 vs 1040: mean=0.157, max=0.258\n",
      "1 vs 1041: mean=0.041, max=0.110\n",
      "1 vs 1042: mean=0.109, max=0.186\n",
      "1 vs 1043: mean=0.069, max=0.240\n",
      "1 vs 1044: mean=0.150, max=0.273\n",
      "1 vs 1045: mean=0.080, max=0.166\n",
      "1 vs 1046: mean=0.167, max=0.289\n",
      "1 vs 1047: mean=0.037, max=0.167\n",
      "1 vs 1048: mean=0.011, max=0.114\n",
      "1 vs 1049: mean=-0.046, max=0.037\n",
      "1 vs 1050: mean=0.057, max=0.154\n",
      "1 vs 1051: mean=0.147, max=0.346\n",
      "1 vs 1052: mean=-0.001, max=0.131\n",
      "1 vs 1053: mean=0.009, max=0.084\n",
      "1 vs 1054: mean=0.108, max=0.191\n",
      "1 vs 1055: mean=0.003, max=0.123\n",
      "1 vs 1056: mean=0.013, max=0.104\n",
      "1 vs 1057: mean=0.002, max=0.116\n",
      "1 vs 1058: mean=0.050, max=0.151\n",
      "1 vs 1059: mean=0.101, max=0.192\n",
      "1 vs 1060: mean=0.101, max=0.194\n",
      "1 vs 1061: mean=0.046, max=0.160\n",
      "1 vs 1062: mean=0.028, max=0.119\n",
      "1 vs 1063: mean=-0.019, max=0.077\n",
      "1 vs 1064: mean=-0.022, max=0.105\n",
      "1 vs 1065: mean=-0.042, max=0.083\n",
      "1 vs 1066: mean=0.014, max=0.122\n",
      "1 vs 1067: mean=0.145, max=0.269\n",
      "1 vs 1068: mean=0.024, max=0.106\n",
      "1 vs 1069: mean=0.006, max=0.124\n",
      "1 vs 1070: mean=0.064, max=0.154\n",
      "1 vs 1071: mean=0.048, max=0.133\n",
      "1 vs 1072: mean=0.026, max=0.168\n",
      "1 vs 1073: mean=-0.001, max=0.117\n",
      "1 vs 1074: mean=0.020, max=0.171\n",
      "1 vs 1075: mean=-0.014, max=0.087\n",
      "1 vs 1076: mean=0.073, max=0.159\n",
      "1 vs 1077: mean=0.029, max=0.166\n",
      "1 vs 1078: mean=0.040, max=0.105\n",
      "1 vs 1079: mean=0.036, max=0.188\n",
      "1 vs 1080: mean=0.107, max=0.191\n",
      "1 vs 1081: mean=-0.008, max=0.104\n",
      "1 vs 1082: mean=0.013, max=0.088\n",
      "1 vs 1083: mean=0.012, max=0.154\n",
      "1 vs 1084: mean=0.087, max=0.207\n",
      "1 vs 1085: mean=0.029, max=0.168\n",
      "1 vs 1086: mean=0.055, max=0.186\n",
      "1 vs 1087: mean=-0.021, max=0.083\n",
      "1 vs 1088: mean=0.011, max=0.131\n",
      "1 vs 1089: mean=-0.071, max=0.026\n",
      "1 vs 1090: mean=0.075, max=0.179\n",
      "1 vs 1091: mean=0.053, max=0.140\n",
      "1 vs 1092: mean=0.122, max=0.205\n",
      "1 vs 1093: mean=-0.061, max=0.076\n",
      "1 vs 1094: mean=0.019, max=0.109\n",
      "1 vs 1095: mean=0.053, max=0.191\n",
      "1 vs 1096: mean=0.080, max=0.171\n",
      "1 vs 1097: mean=0.057, max=0.168\n",
      "1 vs 1098: mean=0.043, max=0.160\n",
      "1 vs 1099: mean=-0.016, max=0.090\n",
      "1 vs 1100: mean=0.043, max=0.139\n",
      "1 vs 1101: mean=-0.027, max=0.068\n",
      "1 vs 1102: mean=0.063, max=0.217\n",
      "1 vs 1103: mean=-0.051, max=0.032\n",
      "1 vs 1104: mean=0.069, max=0.179\n",
      "1 vs 1105: mean=0.027, max=0.103\n",
      "1 vs 1106: mean=0.090, max=0.171\n",
      "1 vs 1107: mean=0.133, max=0.263\n",
      "1 vs 1108: mean=0.070, max=0.179\n",
      "1 vs 1109: mean=0.033, max=0.144\n",
      "1 vs 1110: mean=0.015, max=0.159\n",
      "1 vs 1111: mean=-0.038, max=0.049\n",
      "1 vs 1112: mean=-0.053, max=0.036\n",
      "1 vs 1113: mean=-0.018, max=0.074\n",
      "1 vs 1114: mean=-0.048, max=0.071\n",
      "1 vs 1115: mean=-0.093, max=-0.007\n",
      "1 vs 1116: mean=-0.124, max=-0.014\n",
      "1 vs 1117: mean=0.022, max=0.125\n",
      "1 vs 1118: mean=0.003, max=0.133\n",
      "1 vs 1119: mean=-0.010, max=0.070\n",
      "1 vs 1120: mean=-0.036, max=0.080\n",
      "1 vs 1121: mean=-0.007, max=0.073\n",
      "1 vs 1122: mean=-0.048, max=0.026\n",
      "1 vs 1123: mean=0.010, max=0.084\n",
      "1 vs 1124: mean=-0.072, max=0.056\n",
      "1 vs 1125: mean=0.002, max=0.136\n",
      "1 vs 1126: mean=0.066, max=0.184\n",
      "1 vs 1127: mean=-0.034, max=0.134\n",
      "1 vs 1128: mean=-0.074, max=0.012\n",
      "1 vs 1129: mean=-0.064, max=0.021\n",
      "1 vs 1130: mean=-0.017, max=0.087\n",
      "1 vs 1131: mean=-0.057, max=0.029\n",
      "1 vs 1132: mean=-0.008, max=0.118\n",
      "1 vs 1133: mean=0.054, max=0.185\n",
      "1 vs 1134: mean=0.076, max=0.159\n",
      "1 vs 1135: mean=0.016, max=0.150\n",
      "1 vs 1136: mean=0.018, max=0.119\n",
      "1 vs 1137: mean=0.034, max=0.134\n",
      "1 vs 1138: mean=0.049, max=0.138\n",
      "1 vs 1139: mean=0.021, max=0.120\n",
      "1 vs 1140: mean=0.131, max=0.253\n",
      "1 vs 1141: mean=0.085, max=0.142\n",
      "1 vs 1142: mean=0.050, max=0.127\n",
      "1 vs 1143: mean=0.082, max=0.208\n",
      "1 vs 1144: mean=0.106, max=0.259\n",
      "1 vs 1145: mean=0.068, max=0.134\n",
      "1 vs 1146: mean=0.007, max=0.132\n",
      "1 vs 1147: mean=0.017, max=0.131\n",
      "1 vs 1148: mean=-0.075, max=0.017\n",
      "1 vs 1149: mean=0.056, max=0.175\n",
      "1 vs 1150: mean=0.031, max=0.200\n",
      "1 vs 1151: mean=0.122, max=0.244\n",
      "1 vs 1152: mean=0.077, max=0.191\n",
      "1 vs 1153: mean=0.011, max=0.101\n",
      "1 vs 1154: mean=0.018, max=0.153\n",
      "1 vs 1155: mean=0.044, max=0.135\n",
      "1 vs 1156: mean=-0.041, max=0.141\n",
      "1 vs 1157: mean=0.028, max=0.134\n",
      "1 vs 1158: mean=0.025, max=0.138\n",
      "1 vs 1159: mean=0.037, max=0.139\n",
      "1 vs 1160: mean=0.086, max=0.208\n",
      "1 vs 1161: mean=0.012, max=0.123\n",
      "1 vs 1162: mean=0.050, max=0.153\n",
      "1 vs 1163: mean=0.084, max=0.192\n",
      "1 vs 1164: mean=0.010, max=0.116\n",
      "1 vs 1165: mean=-0.029, max=0.086\n",
      "1 vs 1166: mean=0.046, max=0.117\n",
      "1 vs 1167: mean=0.034, max=0.166\n",
      "1 vs 1168: mean=-0.034, max=0.080\n",
      "1 vs 1169: mean=0.039, max=0.151\n",
      "1 vs 1170: mean=0.021, max=0.144\n",
      "1 vs 1171: mean=0.138, max=0.211\n",
      "1 vs 1172: mean=0.038, max=0.132\n",
      "1 vs 1173: mean=0.147, max=0.278\n",
      "1 vs 1174: mean=0.026, max=0.128\n",
      "1 vs 1175: mean=0.051, max=0.131\n",
      "1 vs 1176: mean=0.024, max=0.096\n",
      "1 vs 1177: mean=0.104, max=0.210\n",
      "1 vs 1178: mean=0.030, max=0.159\n",
      "1 vs 1179: mean=0.081, max=0.165\n",
      "1 vs 1180: mean=0.139, max=0.264\n",
      "1 vs 1181: mean=0.063, max=0.175\n",
      "1 vs 1182: mean=0.065, max=0.162\n",
      "1 vs 1183: mean=-0.004, max=0.102\n",
      "1 vs 1184: mean=0.021, max=0.126\n",
      "1 vs 1185: mean=0.033, max=0.147\n",
      "1 vs 1186: mean=0.119, max=0.195\n",
      "1 vs 1187: mean=0.110, max=0.208\n",
      "1 vs 1188: mean=0.060, max=0.182\n",
      "1 vs 1189: mean=0.025, max=0.120\n",
      "1 vs 1190: mean=0.071, max=0.183\n",
      "1 vs 1191: mean=0.150, max=0.324\n",
      "1 vs 1192: mean=0.077, max=0.167\n",
      "1 vs 1193: mean=0.013, max=0.131\n",
      "1 vs 1194: mean=0.010, max=0.166\n",
      "1 vs 1195: mean=0.038, max=0.151\n",
      "1 vs 1196: mean=0.043, max=0.128\n",
      "1 vs 1197: mean=-0.002, max=0.103\n",
      "1 vs 1198: mean=0.064, max=0.161\n",
      "1 vs 1199: mean=0.061, max=0.174\n",
      "1 vs 1200: mean=0.122, max=0.205\n",
      "1 vs 1201: mean=0.058, max=0.142\n",
      "1 vs 1202: mean=0.037, max=0.134\n",
      "1 vs 1203: mean=-0.037, max=0.053\n",
      "1 vs 1204: mean=0.027, max=0.121\n",
      "1 vs 1205: mean=0.077, max=0.172\n",
      "1 vs 1206: mean=0.069, max=0.149\n",
      "1 vs 1207: mean=0.103, max=0.198\n",
      "1 vs 1208: mean=0.074, max=0.182\n",
      "1 vs 1209: mean=0.035, max=0.130\n",
      "1 vs 1210: mean=0.016, max=0.184\n",
      "1 vs 1211: mean=0.033, max=0.158\n",
      "1 vs 1212: mean=0.052, max=0.169\n",
      "1 vs 1213: mean=-0.049, max=0.112\n",
      "1 vs 1214: mean=0.080, max=0.201\n",
      "1 vs 1215: mean=0.012, max=0.132\n",
      "1 vs 1216: mean=0.016, max=0.167\n",
      "1 vs 1217: mean=0.007, max=0.121\n",
      "1 vs 1218: mean=0.025, max=0.139\n",
      "1 vs 1219: mean=-0.007, max=0.121\n",
      "1 vs 1220: mean=0.150, max=0.237\n",
      "1 vs 1221: mean=0.017, max=0.129\n",
      "1 vs 1222: mean=0.004, max=0.083\n",
      "1 vs 1223: mean=0.037, max=0.193\n",
      "1 vs 1224: mean=0.134, max=0.233\n",
      "1 vs 1225: mean=0.106, max=0.236\n",
      "1 vs 1226: mean=-0.020, max=0.054\n",
      "1 vs 1227: mean=0.086, max=0.172\n",
      "1 vs 1228: mean=0.006, max=0.112\n",
      "1 vs 1229: mean=0.019, max=0.135\n",
      "1 vs 1230: mean=0.051, max=0.153\n",
      "1 vs 1231: mean=0.014, max=0.126\n",
      "1 vs 1232: mean=0.194, max=0.309\n",
      "1 vs 1233: mean=0.035, max=0.112\n",
      "1 vs 1234: mean=0.093, max=0.175\n",
      "1 vs 1235: mean=0.110, max=0.199\n",
      "1 vs 1236: mean=0.049, max=0.132\n",
      "1 vs 1237: mean=0.076, max=0.183\n",
      "1 vs 1238: mean=0.055, max=0.130\n",
      "1 vs 1239: mean=0.047, max=0.198\n",
      "1 vs 1240: mean=-0.004, max=0.107\n",
      "1 vs 1241: mean=-0.003, max=0.137\n",
      "1 vs 1242: mean=0.062, max=0.187\n",
      "1 vs 1243: mean=0.081, max=0.173\n",
      "1 vs 1244: mean=0.071, max=0.202\n",
      "1 vs 1245: mean=0.024, max=0.166\n",
      "1 vs 1246: mean=0.015, max=0.096\n",
      "1 vs 1247: mean=-0.067, max=0.109\n",
      "1 vs 1248: mean=0.066, max=0.149\n",
      "1 vs 1249: mean=0.059, max=0.137\n",
      "1 vs 1250: mean=0.038, max=0.140\n",
      "1 vs 1251: mean=0.059, max=0.138\n",
      "1 vs 1252: mean=0.040, max=0.098\n",
      "1 vs 1253: mean=0.010, max=0.083\n",
      "1 vs 1254: mean=0.047, max=0.148\n",
      "1 vs 1255: mean=0.044, max=0.112\n",
      "1 vs 1256: mean=-0.043, max=0.026\n",
      "1 vs 1257: mean=0.123, max=0.251\n",
      "1 vs 1258: mean=0.085, max=0.193\n",
      "1 vs 1259: mean=0.023, max=0.097\n",
      "1 vs 1260: mean=0.078, max=0.191\n",
      "1 vs 1261: mean=0.088, max=0.226\n",
      "1 vs 1262: mean=0.095, max=0.195\n",
      "1 vs 1263: mean=0.101, max=0.213\n",
      "1 vs 1264: mean=0.069, max=0.163\n",
      "1 vs 1265: mean=0.071, max=0.161\n",
      "1 vs 1266: mean=0.085, max=0.181\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1535722315.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n Inter-global overlap:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_b\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructured_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmean_sim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minter_global_overlap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{obj_a['id']} vs {obj_b['id']}: mean={mean_sim:.3f}, max={max_sim:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-1631729693.py\u001b[0m in \u001b[0;36minter_global_overlap\u001b[0;34m(model, obj_a, obj_b)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minter_global_overlap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0memb_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"small_tasks\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0memb_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"small_tasks\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m                 \u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"hpu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m                     \u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule_kwarg_keys\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"forward_kwargs\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m                 }\n\u001b[0;32m-> 1175\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mtrans_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrans_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mtoken_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_embeddings\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    998\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1001\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mlayer_head_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhead_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    651\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mcache_position\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     ) -> tuple[torch.Tensor]:\n\u001b[0;32m--> 558\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mcache_position\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     ) -> tuple[torch.Tensor]:\n\u001b[0;32m--> 488\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    390\u001b[0m             )\n\u001b[1;32m    391\u001b[0m             value_layer = (\n\u001b[0;32m--> 392\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mRuns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "#  Calcul et affichage des mesures\n",
    "# -----------------------------\n",
    "# Intra-global similarity\n",
    "intra_results = intra_global_similarity(model, structured_dataset)\n",
    "print(\" Intra-global similarity:\")\n",
    "for r in intra_results:\n",
    "    print(f\"ID {r['id']}: mean={r['mean']:.3f}, min={r['min']:.3f}, max={r['max']:.3f}, std={r['std']:.3f}\")\n",
    "\n",
    "# Inter-global overlap\n",
    "print(\"\\n Inter-global overlap:\")\n",
    "for obj_a, obj_b in combinations(structured_dataset, 2):\n",
    "    mean_sim, max_sim = inter_global_overlap(model, obj_a, obj_b)\n",
    "    print(f\"{obj_a['id']} vs {obj_b['id']}: mean={mean_sim:.3f}, max={max_sim:.3f}\")\n",
    "\n",
    "# Retrieval accuracy\n",
    "acc = retrieval_accuracy(model, structured_dataset)\n",
    "print(f\"\\n Retrieval accuracy: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MI71hOatyqk5"
   },
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sZb206U4fcY"
   },
   "source": [
    "- Lors de l’inférence, le processus de clustering sémantique est réalisé en plusieurs étapes successives afin d’obtenir des groupes cohérents, interprétables et robustes.\n",
    "\n",
    "- À partir des embeddings normalisés des tâches, une première segmentation globale est effectuée par clustering hiérarchique agglomératif.\n",
    "\n",
    "- Cette segmentation est ensuite raffinée par un mécanisme de reclustering itératif basé sur la cohésion interne des clusters. Les éléments isolés (singletons) sont traités séparément afin d’éviter une fragmentation excessive.\n",
    "\n",
    "- Enfin, un dernier passage de reclustering adaptatif est appliqué aux clusters trop hétérogènes afin d’assurer que chaque cluster final représente une tâche globale cohérente, potentiellement composée de sous-tâches connexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\n",
    "    \"steam, application, launched Steam and logged in\",\n",
    "    \"steam://rungameid/570, URL, Steam, launched Dota 2 via Steam game ID\",\n",
    "    \"dota2.log, LOG file, /home/user/.steam/steam/logs, Cat, reviewed Dota 2 launch logs\",\n",
    "    \"dota2_screenshots.zip, ZIP file, /home/user/Videos/Dota2, Archive Manager, compressed game screenshots\",\n",
    "    \"dota2_match_2026-01-18.dem, DEM replay file, /home/user/Videos/Dota2/Replays, Game client, watched match replay\",\n",
    "\n",
    "    \"steam://rungameid/730, URL, Steam, launched CS:GO\",\n",
    "    \"csgo_config.cfg, CFG file, /home/user/.steam/steam/steamapps/common/Counter-Strike Global Offensive/csgo/cfg, VS Code, edited game settings (crosshair, sensitivity)\",\n",
    "    \"obs, application, started recording CS:GO gameplay\",\n",
    "    \"obs_recording_01.mkv, MKV file, /home/user/Videos/CSGO, VLC, played recorded gameplay\",\n",
    "\n",
    "    \"lutris, application, launched a Windows game through Wine\",\n",
    "    \"winecfg, command, configured Wine settings for game compatibility\",\n",
    "    \"protontricks, command, applied compatibility fixes to Steam game\",\n",
    "\n",
    "    \"steam_screenshot_001.png, PNG file, /home/user/.steam/steam/userdata/123456789/screenshots, Image Viewer, viewed screenshot\",\n",
    "    \"steam_screenshot_002.png, PNG file, /home/user/.steam/steam/userdata/123456789/screenshots, Image Viewer, viewed screenshot\",\n",
    "    \"game_updates.txt, TXT file, /home/user/Downloads, Gedit, read patch notes for latest update\",\n",
    "\n",
    "    \"discord, application, joined a gaming voice channel\",\n",
    "    \"discord_chat_log.txt, TXT file, /home/user/Documents/DiscordLogs, Gedit, read chat messages\",\n",
    "    \"twitch.tv, web page, Firefox, watched a live gaming stream\",\n",
    "    \"https://store.steampowered.com/app/570/Dota_2/, web page, Firefox, checked Dota 2 store page\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize_task(text):\n",
    "#     \"\"\"\n",
    "#     Nettoyage minimal d'un task_item ou global_task\n",
    "#     \"\"\"\n",
    "#     # enlever les guillemets et les backslashes\n",
    "#     text = text.replace('\\\\\"', '').replace('\"', '')\n",
    "#     # passer en minuscules et strip\n",
    "#     text = text.lower().strip()\n",
    "#     return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sewwPrfmGoK"
   },
   "source": [
    "## Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game_updates.txt, TXT file, /home/user/Downloads, Gedit, read patch notes for latest update\n",
      "steam_screenshot_002.png, PNG file, /home/user/.steam/steam/userdata/123456789/screenshots, Image Viewer, viewed screenshot\n",
      "dota2_match_2026-01-18.dem, DEM replay file, /home/user/Videos/Dota2/Replays, Game client, watched match replay\n",
      "lutris, application, launched a Windows game through Wine\n",
      "steam://rungameid/730, URL, Steam, launched CS:GO\n",
      "discord, application, joined a gaming voice channel\n",
      "twitch.tv, web page, Firefox, watched a live gaming stream\n",
      "csgo_config.cfg, CFG file, /home/user/.steam/steam/steamapps/common/Counter-Strike Global Offensive/csgo/cfg, VS Code, edited game settings (crosshair, sensitivity)\n",
      "steam_screenshot_001.png, PNG file, /home/user/.steam/steam/userdata/123456789/screenshots, Image Viewer, viewed screenshot\n",
      "discord_chat_log.txt, TXT file, /home/user/Documents/DiscordLogs, Gedit, read chat messages\n",
      "winecfg, command, configured Wine settings for game compatibility\n",
      "steam://rungameid/570, URL, Steam, launched Dota 2 via Steam game ID\n",
      "protontricks, command, applied compatibility fixes to Steam game\n",
      "dota2.log, LOG file, /home/user/.steam/steam/logs, Cat, reviewed Dota 2 launch logs\n",
      "https://store.steampowered.com/app/570/Dota_2/, web page, Firefox, checked Dota 2 store page\n",
      "obs, application, started recording CS:GO gameplay\n",
      "obs_recording_01.mkv, MKV file, /home/user/Videos/CSGO, VLC, played recorded gameplay\n",
      "steam, application, launched Steam and logged in\n",
      "dota2_screenshots.zip, ZIP file, /home/user/Videos/Dota2, Archive Manager, compressed game screenshots\n"
     ]
    }
   ],
   "source": [
    "for t in tasks:\n",
    "  print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abmzmOIAmUJ9"
   },
   "source": [
    "## Encoder les tâches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "embeddings = model.encode(\n",
    "    tasks,\n",
    "    convert_to_tensor=True,\n",
    "    normalize_embeddings=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOjarORNmcHF"
   },
   "source": [
    "## Construire la distance cosinus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sim = util.cos_sim(embeddings, embeddings).cpu().numpy()\n",
    "dist = 1 - sim\n",
    "dist = np.clip(dist, 0, None)  # CRUCIAL (corrige l’erreur silhouette)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPAjGVP04xHh"
   },
   "source": [
    "# Step 1 — Clustering global initial par similarité sémantique\n",
    "\n",
    "- structuration globale\n",
    "\n",
    "- détection automatique du nombre de clusters\n",
    "\n",
    "- base stable pour les étapes suivantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoHUVWvApl8E"
   },
   "source": [
    "## Fonctions d’évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from collections import defaultdict\n",
    "\n",
    "def cluster_cohesion(dist, labels):\n",
    "    clusters = defaultdict(list)\n",
    "    for i, c in enumerate(labels):\n",
    "        clusters[c].append(i)\n",
    "\n",
    "    cohesions = {}\n",
    "    for c, idxs in clusters.items():\n",
    "        if len(idxs) < 2:\n",
    "            cohesions[c] = 0.0\n",
    "            continue\n",
    "        sub = dist[np.ix_(idxs, idxs)]\n",
    "        cohesions[c] = sub.mean()\n",
    "\n",
    "    return cohesions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdGhGs-Qmi1t"
   },
   "source": [
    "## Clustering hiérarchique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "thresholds = np.arange(0.45, 0.85, 0.01)\n",
    "\n",
    "best = {\n",
    "    \"th\": None,\n",
    "    \"silhouette\": -1,\n",
    "    \"labels\": None,\n",
    "    \"cohesion\": None\n",
    "}\n",
    "\n",
    "for th in thresholds:\n",
    "    clustering = AgglomerativeClustering(\n",
    "        n_clusters=None,\n",
    "        metric=\"precomputed\",\n",
    "        linkage=\"average\",\n",
    "        distance_threshold=th\n",
    "    )\n",
    "\n",
    "    labels = clustering.fit_predict(dist)\n",
    "    n_clusters = len(set(labels))\n",
    "\n",
    "    # Rejets intelligents\n",
    "    if n_clusters <= 1 or n_clusters > len(tasks) // 2:\n",
    "        continue\n",
    "\n",
    "    sil = silhouette_score(dist, labels, metric=\"precomputed\")\n",
    "    cohesion = cluster_cohesion(dist, labels)\n",
    "\n",
    "    if sil > best[\"silhouette\"]:\n",
    "        best.update({\n",
    "            \"th\": th,\n",
    "            \"silhouette\": sil,\n",
    "            \"labels\": labels,\n",
    "            \"cohesion\": cohesion\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur threshold : 0.730\n",
      "Silhouette score : 0.278\n",
      "Clusters détectés : 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Meilleur threshold : {best['th']:.3f}\")\n",
    "print(f\"Silhouette score : {best['silhouette']:.3f}\")\n",
    "print(f\"Clusters détectés : {len(set(best['labels']))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gb5o_VszmoUo"
   },
   "source": [
    "## Afficher les clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0\n",
      " - game_updates.txt, TXT file, /home/user/Downloads, Gedit, read patch notes for latest update\n",
      " - steam_screenshot_002.png, PNG file, /home/user/.steam/steam/userdata/123456789/screenshots, Image Viewer, viewed screenshot\n",
      " - dota2_match_2026-01-18.dem, DEM replay file, /home/user/Videos/Dota2/Replays, Game client, watched match replay\n",
      " - lutris, application, launched a Windows game through Wine\n",
      " - steam://rungameid/730, URL, Steam, launched CS:GO\n",
      " - discord, application, joined a gaming voice channel\n",
      " - twitch.tv, web page, Firefox, watched a live gaming stream\n",
      " - csgo_config.cfg, CFG file, /home/user/.steam/steam/steamapps/common/Counter-Strike Global Offensive/csgo/cfg, VS Code, edited game settings (crosshair, sensitivity)\n",
      " - steam_screenshot_001.png, PNG file, /home/user/.steam/steam/userdata/123456789/screenshots, Image Viewer, viewed screenshot\n",
      " - winecfg, command, configured Wine settings for game compatibility\n",
      " - steam://rungameid/570, URL, Steam, launched Dota 2 via Steam game ID\n",
      " - protontricks, command, applied compatibility fixes to Steam game\n",
      " - dota2.log, LOG file, /home/user/.steam/steam/logs, Cat, reviewed Dota 2 launch logs\n",
      " - https://store.steampowered.com/app/570/Dota_2/, web page, Firefox, checked Dota 2 store page\n",
      " - obs, application, started recording CS:GO gameplay\n",
      " - obs_recording_01.mkv, MKV file, /home/user/Videos/CSGO, VLC, played recorded gameplay\n",
      " - steam, application, launched Steam and logged in\n",
      " - dota2_screenshots.zip, ZIP file, /home/user/Videos/Dota2, Archive Manager, compressed game screenshots\n",
      "\n",
      "Cluster 1\n",
      " - discord_chat_log.txt, TXT file, /home/user/Documents/DiscordLogs, Gedit, read chat messages\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "groups = defaultdict(list)\n",
    "for task, cid in zip(tasks, best[\"labels\"]):\n",
    "    groups[cid].append(task)\n",
    "\n",
    "for cid, ts in groups.items():\n",
    "    print(f\"\\nCluster {cid}\")\n",
    "    for t in ts:\n",
    "        print(\" -\", t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuLZ438SmxiL"
   },
   "source": [
    "## Évaluer le clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFyLo5ENnQtu"
   },
   "source": [
    "### Cohésion intra-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cohésion par cluster ===\n",
      "Cluster 0 | cohésion = 0.635\n",
      "\n",
      "=== Cohésion moyenne (clusters ≥ 2) ===\n",
      "Cohésion moyenne = 0.635\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Cohésion par cluster ===\")\n",
    "\n",
    "cluster_cohesions = []\n",
    "\n",
    "for c, items in groups.items():\n",
    "    idxs = [tasks.index(t) for t in items]\n",
    "\n",
    "    # on ignore les singletons\n",
    "    if len(idxs) > 1:\n",
    "        d = dist[np.ix_(idxs, idxs)]\n",
    "        cohesion = d[np.triu_indices_from(d, 1)].mean()\n",
    "        cluster_cohesions.append(cohesion)\n",
    "        print(f\"Cluster {c} | cohésion = {cohesion:.3f}\")\n",
    "\n",
    "#Moyenne des cohésions (clusters de taille ≥ 2 uniquement)\n",
    "mean_cohesion = np.mean(cluster_cohesions) if cluster_cohesions else 0.0\n",
    "\n",
    "print(\"\\n=== Cohésion moyenne (clusters ≥ 2) ===\")\n",
    "print(f\"Cohésion moyenne = {mean_cohesion:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfaukOZ15HKc"
   },
   "source": [
    "# Step 2 — Reclustering itératif basé sur la cohésion interne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0ePiT1N5Lnc"
   },
   "source": [
    "- éliminer les clusters trop larges\n",
    "\n",
    "- affiner localement la structure\n",
    "\n",
    "- préserver les singletons significatifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tJxBnZ6JmwU"
   },
   "source": [
    "### Fonction pour recluster un sous-ensemble de tâches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recluster_subset(tasks_subset, dist_matrix_subset, thresholds=np.arange(0.45, 0.85, 0.01)):\n",
    "    n = len(tasks_subset)\n",
    "\n",
    "    # Cas 1 élément → impossible à diviser\n",
    "    if n < 2:\n",
    "        return {0: tasks_subset}, None, 0.0\n",
    "\n",
    "    # Cas EXACTEMENT 2 éléments → division forcée\n",
    "    if n == 2:\n",
    "        return {0: [tasks_subset[0]], 1: [tasks_subset[1]]}, None, 0.0\n",
    "\n",
    "    # Cas EXACTEMENT 3 éléments → division forcée en 2 clusters (2+1)\n",
    "    if n == 3:\n",
    "        return {0: [tasks_subset[0], tasks_subset[1]], 1: [tasks_subset[2]]}, None, 0.0\n",
    "\n",
    "    # Cas général n >= 4\n",
    "    results = {2: {\"sil\": -1, \"th\": None, \"labels\": None},\n",
    "               3: {\"sil\": -1, \"th\": None, \"labels\": None}}\n",
    "\n",
    "    for th in thresholds:\n",
    "        clustering = AgglomerativeClustering(\n",
    "            n_clusters=None,\n",
    "            metric=\"precomputed\",\n",
    "            linkage=\"average\",\n",
    "            distance_threshold=th\n",
    "        )\n",
    "        labels = clustering.fit_predict(dist_matrix_subset)\n",
    "        n_clusters = len(set(labels))\n",
    "        if n_clusters not in (2,3):\n",
    "            continue\n",
    "        try:\n",
    "            sil = silhouette_score(dist_matrix_subset, labels, metric=\"precomputed\")\n",
    "        except ValueError:\n",
    "            sil = 0.0\n",
    "        if sil > results[n_clusters][\"sil\"] or (np.isclose(sil, results[n_clusters][\"sil\"]) and (results[n_clusters][\"th\"] is None or th > results[n_clusters][\"th\"])):\n",
    "            results[n_clusters].update({\"sil\": sil, \"th\": th, \"labels\": labels})\n",
    "\n",
    "    # Choisir 3 clusters si silhouette >= 2 clusters\n",
    "    chosen_k = 3 if results[3][\"sil\"] >= results[2][\"sil\"] else 2\n",
    "    chosen = results[chosen_k]\n",
    "\n",
    "    if chosen[\"labels\"] is None:\n",
    "        # Si aucun résultat, forcer division 2 clusters (cas par défaut)\n",
    "        return {0: tasks_subset[:n//2], 1: tasks_subset[n//2:]}, None, 0.0\n",
    "\n",
    "    new_groups = defaultdict(list)\n",
    "    for i, lbl in enumerate(chosen[\"labels\"]):\n",
    "        new_groups[lbl].append(tasks_subset[i])\n",
    "    return new_groups, chosen[\"th\"], chosen[\"sil\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNwQCcJfJwaw"
   },
   "source": [
    "### Pipeline principal avec reclustering conditionnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th: 0.8400000000000003 n_clusters: 2 labels: [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "best_threshold_global = best[\"th\"]\n",
    "\n",
    "clustering = AgglomerativeClustering(\n",
    "    n_clusters=None,\n",
    "    metric=\"precomputed\",\n",
    "    linkage=\"average\",\n",
    "    distance_threshold=best_threshold_global\n",
    ")\n",
    "labels = clustering.fit_predict(dist)\n",
    "n_clusters = len(set(labels))\n",
    "print(\"th:\", th, \"n_clusters:\", n_clusters, \"labels:\", labels)\n",
    "\n",
    "groups = defaultdict(list)\n",
    "for task, lbl in zip(tasks, labels):\n",
    "    groups[lbl].append(task)\n",
    "\n",
    "COHESION_THRESHOLD = 0.39\n",
    "final_groups = {}\n",
    "new_label_counter = 0\n",
    "\n",
    "clusters_to_check = list(groups.values())\n",
    "\n",
    "while clusters_to_check:\n",
    "    current = clusters_to_check.pop(0)\n",
    "    n = len(current)\n",
    "\n",
    "    # Cas 1 élément → terminal\n",
    "    if n < 2:\n",
    "        final_groups[new_label_counter] = current\n",
    "        new_label_counter += 1\n",
    "        continue\n",
    "\n",
    "    idxs = [tasks.index(t) for t in current]\n",
    "    sub_dist = dist[np.ix_(idxs, idxs)]\n",
    "    mean_cohesion = sub_dist[np.triu_indices_from(sub_dist, 1)].mean()\n",
    "\n",
    "    if mean_cohesion > COHESION_THRESHOLD:\n",
    "        new_sub_groups, sub_th, sub_sil = recluster_subset(current, sub_dist)\n",
    "\n",
    "        # Si aucune vraie division\n",
    "        if len(new_sub_groups) == 1:\n",
    "            final_groups[new_label_counter] = current\n",
    "            new_label_counter += 1\n",
    "        else:\n",
    "            for sub_items in new_sub_groups.values():\n",
    "                clusters_to_check.append(sub_items)\n",
    "    else:\n",
    "        final_groups[new_label_counter] = current\n",
    "        new_label_counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Clusters finaux après reclustering itératif ===\n",
      "\n",
      "Cluster 0 | 1 tâches\n",
      " - discord_chat_log.txt, TXT file, /home/user/Documents/DiscordLogs, Gedit, read chat messages\n",
      "\n",
      "Cluster 1 | 1 tâches\n",
      " - steam, application, launched Steam and logged in\n",
      "\n",
      "Cluster 2 | 1 tâches\n",
      " - game_updates.txt, TXT file, /home/user/Downloads, Gedit, read patch notes for latest update\n",
      "\n",
      "Cluster 3 | 4 tâches\n",
      " - steam_screenshot_002.png, PNG file, /home/user/.steam/steam/userdata/123456789/screenshots, Image Viewer, viewed screenshot\n",
      " - csgo_config.cfg, CFG file, /home/user/.steam/steam/steamapps/common/Counter-Strike Global Offensive/csgo/cfg, VS Code, edited game settings (crosshair, sensitivity)\n",
      " - steam_screenshot_001.png, PNG file, /home/user/.steam/steam/userdata/123456789/screenshots, Image Viewer, viewed screenshot\n",
      " - dota2_screenshots.zip, ZIP file, /home/user/Videos/Dota2, Archive Manager, compressed game screenshots\n",
      "\n",
      "Cluster 4 | 2 tâches\n",
      " - dota2.log, LOG file, /home/user/.steam/steam/logs, Cat, reviewed Dota 2 launch logs\n",
      " - https://store.steampowered.com/app/570/Dota_2/, web page, Firefox, checked Dota 2 store page\n",
      "\n",
      "Cluster 5 | 1 tâches\n",
      " - discord, application, joined a gaming voice channel\n",
      "\n",
      "Cluster 6 | 3 tâches\n",
      " - lutris, application, launched a Windows game through Wine\n",
      " - winecfg, command, configured Wine settings for game compatibility\n",
      " - protontricks, command, applied compatibility fixes to Steam game\n",
      "\n",
      "Cluster 7 | 1 tâches\n",
      " - dota2_match_2026-01-18.dem, DEM replay file, /home/user/Videos/Dota2/Replays, Game client, watched match replay\n",
      "\n",
      "Cluster 8 | 3 tâches\n",
      " - twitch.tv, web page, Firefox, watched a live gaming stream\n",
      " - obs, application, started recording CS:GO gameplay\n",
      " - obs_recording_01.mkv, MKV file, /home/user/Videos/CSGO, VLC, played recorded gameplay\n",
      "\n",
      "Cluster 9 | 1 tâches\n",
      " - steam://rungameid/730, URL, Steam, launched CS:GO\n",
      "\n",
      "Cluster 10 | 1 tâches\n",
      " - steam://rungameid/570, URL, Steam, launched Dota 2 via Steam game ID\n"
     ]
    }
   ],
   "source": [
    "# --- Affichage final des clusters après reclustering itératif ---\n",
    "print(\"\\n=== Clusters finaux après reclustering itératif ===\")\n",
    "for c, items in final_groups.items():\n",
    "    print(f\"\\nCluster {c} | {len(items)} tâches\")\n",
    "    for t in items:\n",
    "        print(\" -\", t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score final après reclustering: 0.161\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "# Construire les labels finaux pour silhouette\n",
    "final_labels = np.zeros(len(tasks), dtype=int)\n",
    "for c, items in final_groups.items():\n",
    "    for t in items:\n",
    "        idx = tasks.index(t)\n",
    "        final_labels[idx] = c\n",
    "\n",
    "sil_final = silhouette_score(dist, final_labels, metric=\"precomputed\")\n",
    "print(\"Silhouette score final après reclustering:\", round(sil_final, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cohésion finale par cluster ===\n",
      "Cluster 0 | cohésion = 0.000\n",
      "Cluster 1 | cohésion = 0.000\n",
      "Cluster 2 | cohésion = 0.000\n",
      "Cluster 3 | cohésion = 0.310\n",
      "Cluster 4 | cohésion = 0.383\n",
      "Cluster 5 | cohésion = 0.000\n",
      "Cluster 6 | cohésion = 0.369\n",
      "Cluster 7 | cohésion = 0.000\n",
      "Cluster 8 | cohésion = 0.334\n",
      "Cluster 9 | cohésion = 0.000\n",
      "Cluster 10 | cohésion = 0.000\n",
      "\n",
      "=== Cohésion moyenne finale (clusters ≥ 2) ===\n",
      "Cohésion moyenne finale = 0.349\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Cohésion finale par cluster ===\")\n",
    "\n",
    "final_cluster_cohesions = []\n",
    "\n",
    "for c, items in final_groups.items():\n",
    "    idxs = [tasks.index(t) for t in items]\n",
    "\n",
    "    if len(idxs) < 2:\n",
    "        mean_d = 0.0\n",
    "    else:\n",
    "        d = dist[np.ix_(idxs, idxs)]\n",
    "        mean_d = d[np.triu_indices_from(d, 1)].mean()\n",
    "        final_cluster_cohesions.append(mean_d)\n",
    "\n",
    "    print(f\"Cluster {c} | cohésion = {mean_d:.3f}\")\n",
    "\n",
    "# Moyenne des cohésions (clusters de taille ≥ 2 uniquement)\n",
    "mean_final_cohesion = (\n",
    "    np.mean(final_cluster_cohesions)\n",
    "    if final_cluster_cohesions else 0.0\n",
    ")\n",
    "\n",
    "print(\"\\n=== Cohésion moyenne finale (clusters ≥ 2) ===\")\n",
    "print(f\"Cohésion moyenne finale = {mean_final_cohesion:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R13RtRBP5W-q"
   },
   "source": [
    "# Step 3 — Gestion explicite des singletons et reclustering ciblé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRicwsMD5YS7"
   },
   "source": [
    "- éviter la sur-fragmentation\n",
    "\n",
    "- préserver les tâches réellement indépendantes\n",
    "\n",
    "- détecter des regroupements faibles mais pertinents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epOcNa91-fdj"
   },
   "source": [
    "## Extraire les singletons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 singletons extraits sur 19 tâches\n"
     ]
    }
   ],
   "source": [
    "# --- Extraction des singletons ---\n",
    "singletons = []\n",
    "non_singleton_groups = {}\n",
    "\n",
    "for cid, items in final_groups.items():\n",
    "    if len(items) == 1:\n",
    "        singletons.append(items[0])\n",
    "    else:\n",
    "        non_singleton_groups[cid] = items\n",
    "\n",
    "print(f\"{len(singletons)} singletons extraits sur {len(tasks)} tâches\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IR6ZIqN7-mbz"
   },
   "source": [
    "## Condition de proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reclustering global des singletons activé\n"
     ]
    }
   ],
   "source": [
    "SINGLETON_RATIO_THRESHOLD = 0.2\n",
    "\n",
    "if len(singletons) / len(tasks) < SINGLETON_RATIO_THRESHOLD:\n",
    "    print(\"Pas assez de singletons → pas de reclustering global\")\n",
    "    new_tasks = []\n",
    "else:\n",
    "    new_tasks = singletons\n",
    "    print(\"Reclustering global des singletons activé\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8t25plgu-vJ4"
   },
   "source": [
    "## Reclustering NORMAL appliqué à new_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "if new_tasks:\n",
    "    # Embeddings\n",
    "    new_embeddings = model.encode(\n",
    "        new_tasks,\n",
    "        convert_to_tensor=True,\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "\n",
    "    new_sim = util.cos_sim(new_embeddings, new_embeddings).cpu().numpy()\n",
    "    new_dist = 1 - new_sim\n",
    "    new_dist = np.clip(new_dist, 0, None)\n",
    "\n",
    "    # Recherche du meilleur threshold\n",
    "    best_singleton = {\n",
    "        \"th\": None,\n",
    "        \"silhouette\": -1,\n",
    "        \"labels\": None\n",
    "    }\n",
    "\n",
    "    for th in thresholds:\n",
    "        clustering = AgglomerativeClustering(\n",
    "            n_clusters=None,\n",
    "            metric=\"precomputed\",\n",
    "            linkage=\"average\",\n",
    "            distance_threshold=th\n",
    "        )\n",
    "\n",
    "        labels = clustering.fit_predict(new_dist)\n",
    "        n_clusters = len(set(labels))\n",
    "\n",
    "\n",
    "        if n_clusters <= 1 or n_clusters > len(new_tasks) // 2:\n",
    "            continue\n",
    "\n",
    "        sil = silhouette_score(new_dist, labels, metric=\"precomputed\")\n",
    "\n",
    "        if sil > best_singleton[\"silhouette\"]:\n",
    "            best_singleton.update({\n",
    "                \"th\": th,\n",
    "                \"silhouette\": sil,\n",
    "                \"labels\": labels\n",
    "            })\n",
    "\n",
    "    # Construction des nouveaux clusters issus des singletons\n",
    "    singleton_clusters = defaultdict(list)\n",
    "\n",
    "    singleton_clusters = defaultdict(list)\n",
    "\n",
    "    if best_singleton[\"labels\"] is None:\n",
    "        # Aucun reclustering valide → on garde les singletons tels quels\n",
    "        for t in new_tasks:\n",
    "            singleton_clusters[len(singleton_clusters)] = [t]\n",
    "    else:\n",
    "        for task, lbl in zip(new_tasks, best_singleton[\"labels\"]):\n",
    "            singleton_clusters[lbl].append(task)\n",
    "else:\n",
    "    singleton_clusters = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joy6hnSC-3mM"
   },
   "source": [
    "## Fusion finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fusion finale ---\n",
    "final_merged_groups = {}\n",
    "cid = 0\n",
    "\n",
    "# Clusters non-singletons\n",
    "for items in non_singleton_groups.values():\n",
    "    final_merged_groups[cid] = items\n",
    "    cid += 1\n",
    "\n",
    "# Nouveaux clusters issus des singletons\n",
    "for items in singleton_clusters.values():\n",
    "    final_merged_groups[cid] = items\n",
    "    cid += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Clusters finaux après reclustering des singletons ===\n",
      "\n",
      "Cluster 0 | 4 tâches\n",
      " - steam_screenshot_002.png, PNG file, /home/user/.steam/steam/userdata/123456789/screenshots, Image Viewer, viewed screenshot\n",
      " - csgo_config.cfg, CFG file, /home/user/.steam/steam/steamapps/common/Counter-Strike Global Offensive/csgo/cfg, VS Code, edited game settings (crosshair, sensitivity)\n",
      " - steam_screenshot_001.png, PNG file, /home/user/.steam/steam/userdata/123456789/screenshots, Image Viewer, viewed screenshot\n",
      " - dota2_screenshots.zip, ZIP file, /home/user/Videos/Dota2, Archive Manager, compressed game screenshots\n",
      "\n",
      "Cluster 1 | 2 tâches\n",
      " - dota2.log, LOG file, /home/user/.steam/steam/logs, Cat, reviewed Dota 2 launch logs\n",
      " - https://store.steampowered.com/app/570/Dota_2/, web page, Firefox, checked Dota 2 store page\n",
      "\n",
      "Cluster 2 | 3 tâches\n",
      " - lutris, application, launched a Windows game through Wine\n",
      " - winecfg, command, configured Wine settings for game compatibility\n",
      " - protontricks, command, applied compatibility fixes to Steam game\n",
      "\n",
      "Cluster 3 | 3 tâches\n",
      " - twitch.tv, web page, Firefox, watched a live gaming stream\n",
      " - obs, application, started recording CS:GO gameplay\n",
      " - obs_recording_01.mkv, MKV file, /home/user/Videos/CSGO, VLC, played recorded gameplay\n",
      "\n",
      "Cluster 4 | 1 tâches\n",
      " - discord_chat_log.txt, TXT file, /home/user/Documents/DiscordLogs, Gedit, read chat messages\n",
      "\n",
      "Cluster 5 | 6 tâches\n",
      " - steam, application, launched Steam and logged in\n",
      " - game_updates.txt, TXT file, /home/user/Downloads, Gedit, read patch notes for latest update\n",
      " - discord, application, joined a gaming voice channel\n",
      " - dota2_match_2026-01-18.dem, DEM replay file, /home/user/Videos/Dota2/Replays, Game client, watched match replay\n",
      " - steam://rungameid/730, URL, Steam, launched CS:GO\n",
      " - steam://rungameid/570, URL, Steam, launched Dota 2 via Steam game ID\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Clusters finaux après reclustering des singletons ===\")\n",
    "for c, items in final_merged_groups.items():\n",
    "    print(f\"\\nCluster {c} | {len(items)} tâches\")\n",
    "    for t in items:\n",
    "        print(\" -\", t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reconstruction des labels finaux ---\n",
    "task_to_index = {t: i for i, t in enumerate(tasks)}\n",
    "\n",
    "labels_final = np.full(len(tasks), -1, dtype=int)\n",
    "\n",
    "for cid, items in final_merged_groups.items():\n",
    "    for t in items:\n",
    "        labels_final[task_to_index[t]] = cid\n",
    "\n",
    "# Sécurité\n",
    "assert np.all(labels_final != -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette finale : 0.14388137\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Compter les clusters non-singletons\n",
    "cluster_sizes = {}\n",
    "for cid in labels_final:\n",
    "    cluster_sizes[cid] = cluster_sizes.get(cid, 0) + 1\n",
    "\n",
    "valid_clusters = [cid for cid, sz in cluster_sizes.items() if sz >= 2]\n",
    "\n",
    "if len(valid_clusters) >= 2:\n",
    "    sil_final = silhouette_score(dist, labels_final, metric=\"precomputed\")\n",
    "else:\n",
    "    sil_final = None\n",
    "\n",
    "print(\"Silhouette finale :\", sil_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cohésion par cluster :\n",
      "Cluster 5 | cohésion = 0.724\n",
      "Cluster 0 | cohésion = 0.310\n",
      "Cluster 2 | cohésion = 0.369\n",
      "Cluster 3 | cohésion = 0.334\n",
      "Cluster 4 | cohésion = 0.000\n",
      "Cluster 1 | cohésion = 0.383\n",
      "\n",
      "Cohésion moyenne finale : 0.42416897\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def cluster_cohesion(dist, labels):\n",
    "    clusters = defaultdict(list)\n",
    "    for i, c in enumerate(labels):\n",
    "        clusters[c].append(i)\n",
    "\n",
    "    cohesions = {}\n",
    "    for c, idxs in clusters.items():\n",
    "        if len(idxs) < 2:\n",
    "            cohesions[c] = 0.0\n",
    "            continue\n",
    "        sub = dist[np.ix_(idxs, idxs)]\n",
    "        cohesions[c] = sub[np.triu_indices_from(sub, 1)].mean()\n",
    "\n",
    "    return cohesions\n",
    "\n",
    "\n",
    "cohesions_final = cluster_cohesion(dist, labels_final)\n",
    "\n",
    "print(\"\\nCohésion par cluster :\")\n",
    "for cid, coh in cohesions_final.items():\n",
    "    print(f\"Cluster {cid} | cohésion = {coh:.3f}\")\n",
    "\n",
    "# Cohésion moyenne (clusters >= 2)\n",
    "valid_cohesions = [c for cid, c in cohesions_final.items()\n",
    "                   if sum(labels_final == cid) >= 2]\n",
    "\n",
    "mean_cohesion_final = np.mean(valid_cohesions) if valid_cohesions else None\n",
    "\n",
    "print(\"\\nCohésion moyenne finale :\", mean_cohesion_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbq4Ec1jC-f8"
   },
   "source": [
    "# Step 4 — Reclustering adaptatif final des clusters hétérogènes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTXiRpz_5lWg"
   },
   "source": [
    "- correction finale des clusters trop larges\n",
    "\n",
    "- contrôle fin de la granularité\n",
    "\n",
    "- alignement avec des tâches globales interprétables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "COHESION_THRESHOLD = 0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkqjxqZFDF9E"
   },
   "source": [
    "## COmputer cohesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cohesion(sub_dist):\n",
    "    n = sub_dist.shape[0]\n",
    "    if n < 2:\n",
    "        return 0.0\n",
    "    return sub_dist[np.triu_indices_from(sub_dist, 1)].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split_by_k(tasks_subset, dist_matrix_subset):\n",
    "    n = len(tasks_subset)\n",
    "\n",
    "    for k in range(2, n + 1):\n",
    "        clustering = AgglomerativeClustering(\n",
    "            n_clusters=k,\n",
    "            metric=\"precomputed\",\n",
    "            linkage=\"average\"\n",
    "        )\n",
    "        labels = clustering.fit_predict(dist_matrix_subset)\n",
    "\n",
    "        total_cohesion = 0.0\n",
    "        for lbl in set(labels):\n",
    "            idxs = np.where(labels == lbl)[0]\n",
    "            sub_d = dist_matrix_subset[np.ix_(idxs, idxs)]\n",
    "            total_cohesion += compute_cohesion(sub_d)\n",
    "\n",
    "        avg_cohesion = total_cohesion / k\n",
    "\n",
    "        print(f\"  -> k={k} | avg_cohesion={avg_cohesion:.3f}\")\n",
    "\n",
    "        # VALIDATION : on accepte le premier k qui passe le seuil\n",
    "        if avg_cohesion <= 0.5:\n",
    "            print(f\"  => split VALIDÉ: k={k} | avg_cohesion={avg_cohesion:.3f}\\n\")\n",
    "            return {\n",
    "                \"k\": k,\n",
    "                \"labels\": labels,\n",
    "                \"avg_cohesion\": avg_cohesion\n",
    "            }\n",
    "\n",
    "    # si aucun k n'est valide\n",
    "    print(\"  => aucun split valide (avg_cohesion > 0.5 pour tous les k)\\n\")\n",
    "    return {\"k\": None, \"labels\": None, \"avg_cohesion\": None}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2p6hiI8EQNqV"
   },
   "source": [
    "## calculer les clusters à partir de labels_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# reconstruction clusters depuis labels_final\n",
    "clusters_from_labels = defaultdict(list)\n",
    "for idx, c in enumerate(labels_final):\n",
    "    clusters_from_labels[c].append(tasks[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXqV3GaLQXNk"
   },
   "source": [
    "## sélectionner les clusters à reclusteriser (cohésion > 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_to_recluster = []\n",
    "clusters_kept = {}\n",
    "\n",
    "for cid, items in clusters_from_labels.items():\n",
    "    idxs = [tasks.index(t) for t in items]\n",
    "    if len(idxs) < 2:\n",
    "        clusters_kept[cid] = items\n",
    "        continue\n",
    "    sub_dist = dist[np.ix_(idxs, idxs)]\n",
    "    coh = compute_cohesion(sub_dist)\n",
    "\n",
    "    if coh > COHESION_THRESHOLD:  # 0.7\n",
    "        clusters_to_recluster.append((cid, items))\n",
    "    else:\n",
    "        clusters_kept[cid] = items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VeT3ysHEQd26"
   },
   "source": [
    "## reclusteriser les clusters > 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Reclustering du cluster 5 (taille=6) ---\n",
      "\n",
      "Cluster actuel (taille=6) - cohésion = 0.724\n",
      "  - game_updates.txt, TXT file, /home/user/Downloads, Gedit, read patch notes for latest update\n",
      "  - dota2_match_2026-01-18.dem, DEM replay file, /home/user/Videos/Dota2/Replays, Game client, watched match replay\n",
      "  - steam://rungameid/730, URL, Steam, launched CS:GO\n",
      "  - discord, application, joined a gaming voice channel\n",
      "  - steam://rungameid/570, URL, Steam, launched Dota 2 via Steam game ID\n",
      "  - steam, application, launched Steam and logged in\n",
      "  -> k=2 | avg_cohesion=0.643\n",
      "  -> k=3 | avg_cohesion=0.408\n",
      "  => split VALIDÉ: k=3 | avg_cohesion=0.408\n",
      "\n",
      " -> Division en 3 sous-clusters (avg cohésion = 0.408)\n",
      "    Sous-cluster (taille=2) - cohésion = 0.646\n",
      "      - game_updates.txt, TXT file, /home/user/Downloads, Gedit, read patch notes for latest update\n",
      "      - dota2_match_2026-01-18.dem, DEM replay file, /home/user/Videos/Dota2/Replays, Game client, watched match replay\n",
      "      -> cohésion > 0.5 : on reclusterise encore\n",
      "    Sous-cluster (taille=3) - cohésion = 0.577\n",
      "      - steam://rungameid/730, URL, Steam, launched CS:GO\n",
      "      - steam://rungameid/570, URL, Steam, launched Dota 2 via Steam game ID\n",
      "      - steam, application, launched Steam and logged in\n",
      "      -> cohésion > 0.5 : on reclusterise encore\n",
      "    Sous-cluster (taille=1) - cohésion = 0.000\n",
      "      - discord, application, joined a gaming voice channel\n",
      "      -> cohésion <= 0.5 : cluster final\n",
      "\n",
      "Cluster actuel (taille=2) - cohésion = 0.646\n",
      "  - game_updates.txt, TXT file, /home/user/Downloads, Gedit, read patch notes for latest update\n",
      "  - dota2_match_2026-01-18.dem, DEM replay file, /home/user/Videos/Dota2/Replays, Game client, watched match replay\n",
      "  -> k=2 | avg_cohesion=0.000\n",
      "  => split VALIDÉ: k=2 | avg_cohesion=0.000\n",
      "\n",
      " -> Division en 2 sous-clusters (avg cohésion = 0.000)\n",
      "    Sous-cluster (taille=1) - cohésion = 0.000\n",
      "      - game_updates.txt, TXT file, /home/user/Downloads, Gedit, read patch notes for latest update\n",
      "      -> cohésion <= 0.5 : cluster final\n",
      "    Sous-cluster (taille=1) - cohésion = 0.000\n",
      "      - dota2_match_2026-01-18.dem, DEM replay file, /home/user/Videos/Dota2/Replays, Game client, watched match replay\n",
      "      -> cohésion <= 0.5 : cluster final\n",
      "\n",
      "Cluster actuel (taille=3) - cohésion = 0.577\n",
      "  - steam://rungameid/730, URL, Steam, launched CS:GO\n",
      "  - steam://rungameid/570, URL, Steam, launched Dota 2 via Steam game ID\n",
      "  - steam, application, launched Steam and logged in\n",
      "  -> k=2 | avg_cohesion=0.231\n",
      "  => split VALIDÉ: k=2 | avg_cohesion=0.231\n",
      "\n",
      " -> Division en 2 sous-clusters (avg cohésion = 0.231)\n",
      "    Sous-cluster (taille=2) - cohésion = 0.462\n",
      "      - steam://rungameid/730, URL, Steam, launched CS:GO\n",
      "      - steam://rungameid/570, URL, Steam, launched Dota 2 via Steam game ID\n",
      "      -> cohésion <= 0.5 : cluster final\n",
      "    Sous-cluster (taille=1) - cohésion = 0.000\n",
      "      - steam, application, launched Steam and logged in\n",
      "      -> cohésion <= 0.5 : cluster final\n"
     ]
    }
   ],
   "source": [
    "final_reclustered = {}\n",
    "new_cid = 0\n",
    "assigned_tasks = set()\n",
    "\n",
    "# 1) Reclustering des clusters à traiter\n",
    "for cid, items in clusters_to_recluster:\n",
    "    print(f\"\\n--- Reclustering du cluster {cid} (taille={len(items)}) ---\")\n",
    "    clusters_to_check = [items]\n",
    "\n",
    "    while clusters_to_check:\n",
    "        current = clusters_to_check.pop(0)\n",
    "        idxs = [tasks.index(t) for t in current]\n",
    "        sub_dist = dist[np.ix_(idxs, idxs)]\n",
    "        mean_cohesion = compute_cohesion(sub_dist)\n",
    "\n",
    "        print(f\"\\nCluster actuel (taille={len(current)}) - cohésion = {mean_cohesion:.3f}\")\n",
    "        for t in current:\n",
    "            print(\"  -\", t)\n",
    "\n",
    "        if mean_cohesion > 0.5:\n",
    "            best_split = best_split_by_k(current, sub_dist)\n",
    "\n",
    "            if best_split[\"labels\"] is None:\n",
    "                print(\" -> Pas de division utile. On garde ce cluster.\")\n",
    "                final_reclustered[new_cid] = current\n",
    "                new_cid += 1\n",
    "                assigned_tasks.update(current)\n",
    "\n",
    "            else:\n",
    "                new_groups = defaultdict(list)\n",
    "                for i, lbl in enumerate(best_split[\"labels\"]):\n",
    "                    new_groups[lbl].append(current[i])\n",
    "\n",
    "                print(f\" -> Division en {len(new_groups)} sous-clusters (avg cohésion = {best_split['avg_cohesion']:.3f})\")\n",
    "\n",
    "                for sub_items in new_groups.values():\n",
    "                    idxs2 = [tasks.index(t) for t in sub_items]\n",
    "                    sub_dist2 = dist[np.ix_(idxs2, idxs2)]\n",
    "                    coh2 = compute_cohesion(sub_dist2)\n",
    "\n",
    "                    print(f\"    Sous-cluster (taille={len(sub_items)}) - cohésion = {coh2:.3f}\")\n",
    "                    for t in sub_items:\n",
    "                        print(\"      -\", t)\n",
    "\n",
    "                    # IMPORTANT : pas de double ajout\n",
    "                    if coh2 > 0.5:\n",
    "                        print(\"      -> cohésion > 0.5 : on reclusterise encore\")\n",
    "                        clusters_to_check.append(sub_items)\n",
    "                    else:\n",
    "                        print(\"      -> cohésion <= 0.5 : cluster final\")\n",
    "                        final_reclustered[new_cid] = sub_items\n",
    "                        new_cid += 1\n",
    "                        assigned_tasks.update(sub_items)\n",
    "\n",
    "        else:\n",
    "            print(\" -> cohésion <= 0.7 : cluster final\")\n",
    "            final_reclustered[new_cid] = current\n",
    "            new_cid += 1\n",
    "            assigned_tasks.update(current)\n",
    "\n",
    "# 2) Ajouter les clusters non-reclusterisés (kept)\n",
    "for cid, items in clusters_kept.items():\n",
    "    # Ajout uniquement si aucun élément n'a déjà été assigné\n",
    "    if not any(t in assigned_tasks for t in items):\n",
    "        final_reclustered[new_cid] = items\n",
    "        new_cid += 1\n",
    "        assigned_tasks.update(items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pDgrlFZQjqR"
   },
   "source": [
    "## ajouter les clusters non touchés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Clusters finaux ===\n",
      "\n",
      "Cluster 0 | 1 tâches\n",
      " - discord, application, joined a gaming voice channel\n",
      "\n",
      "Cluster 1 | 1 tâches\n",
      " - game_updates.txt, TXT file, /home/user/Downloads, Gedit, read patch notes for latest update\n",
      "\n",
      "Cluster 2 | 1 tâches\n",
      " - dota2_match_2026-01-18.dem, DEM replay file, /home/user/Videos/Dota2/Replays, Game client, watched match replay\n",
      "\n",
      "Cluster 3 | 2 tâches\n",
      " - steam://rungameid/730, URL, Steam, launched CS:GO\n",
      " - steam://rungameid/570, URL, Steam, launched Dota 2 via Steam game ID\n",
      "\n",
      "Cluster 4 | 1 tâches\n",
      " - steam, application, launched Steam and logged in\n",
      "\n",
      "Cluster 5 | 4 tâches\n",
      " - steam_screenshot_002.png, PNG file, /home/user/.steam/steam/userdata/123456789/screenshots, Image Viewer, viewed screenshot\n",
      " - csgo_config.cfg, CFG file, /home/user/.steam/steam/steamapps/common/Counter-Strike Global Offensive/csgo/cfg, VS Code, edited game settings (crosshair, sensitivity)\n",
      " - steam_screenshot_001.png, PNG file, /home/user/.steam/steam/userdata/123456789/screenshots, Image Viewer, viewed screenshot\n",
      " - dota2_screenshots.zip, ZIP file, /home/user/Videos/Dota2, Archive Manager, compressed game screenshots\n",
      "\n",
      "Cluster 6 | 3 tâches\n",
      " - lutris, application, launched a Windows game through Wine\n",
      " - winecfg, command, configured Wine settings for game compatibility\n",
      " - protontricks, command, applied compatibility fixes to Steam game\n",
      "\n",
      "Cluster 7 | 3 tâches\n",
      " - twitch.tv, web page, Firefox, watched a live gaming stream\n",
      " - obs, application, started recording CS:GO gameplay\n",
      " - obs_recording_01.mkv, MKV file, /home/user/Videos/CSGO, VLC, played recorded gameplay\n",
      "\n",
      "Cluster 8 | 1 tâches\n",
      " - discord_chat_log.txt, TXT file, /home/user/Documents/DiscordLogs, Gedit, read chat messages\n",
      "\n",
      "Cluster 9 | 2 tâches\n",
      " - dota2.log, LOG file, /home/user/.steam/steam/logs, Cat, reviewed Dota 2 launch logs\n",
      " - https://store.steampowered.com/app/570/Dota_2/, web page, Firefox, checked Dota 2 store page\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Clusters finaux ===\")\n",
    "for c, items in final_reclustered.items():\n",
    "    print(f\"\\nCluster {c} | {len(items)} tâches\")\n",
    "    for t in items:\n",
    "        print(\" -\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre final de clusters = 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "# 1) Reconstruction des labels globaux\n",
    "labels_final = np.full(len(tasks), -1)\n",
    "\n",
    "for cid, items in final_reclustered.items():\n",
    "    for t in items:\n",
    "        labels_final[tasks.index(t)] = cid\n",
    "\n",
    "# Vérification\n",
    "n_clusters_final = len(set(labels_final))\n",
    "print(f\"\\nNombre final de clusters = {n_clusters_final}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette finale = 0.188\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2) Silhouette score global (si valide)\n",
    "if n_clusters_final > 1 and n_clusters_final < len(tasks):\n",
    "    sil_final = silhouette_score(dist, labels_final, metric=\"precomputed\")\n",
    "else:\n",
    "    sil_final = 0.0\n",
    "\n",
    "print(f\"Silhouette finale = {sil_final:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cohésion par cluster ===\n",
      "Cluster 0 | cohésion = 0.000\n",
      "Cluster 1 | cohésion = 0.000\n",
      "Cluster 2 | cohésion = 0.000\n",
      "Cluster 3 | cohésion = 0.462\n",
      "Cluster 4 | cohésion = 0.000\n",
      "Cluster 5 | cohésion = 0.310\n",
      "Cluster 6 | cohésion = 0.369\n",
      "Cluster 7 | cohésion = 0.334\n",
      "Cluster 8 | cohésion = 0.000\n",
      "Cluster 9 | cohésion = 0.383\n",
      "\n",
      "=== Métriques finales ===\n",
      "Cohésion moyenne finale = 0.372\n",
      "Silhouette finale       = 0.188\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3) Cohésion par cluster + moyenne\n",
    "print(\"\\n=== Cohésion par cluster ===\")\n",
    "\n",
    "cluster_cohesions = []\n",
    "\n",
    "for c, items in final_reclustered.items():\n",
    "    idxs = [tasks.index(t) for t in items]\n",
    "\n",
    "    if len(idxs) < 2:\n",
    "        coh = 0.0\n",
    "    else:\n",
    "        d = dist[np.ix_(idxs, idxs)]\n",
    "        coh = compute_cohesion(d)\n",
    "        cluster_cohesions.append(coh)\n",
    "\n",
    "    print(f\"Cluster {c} | cohésion = {coh:.3f}\")\n",
    "\n",
    "# Moyenne des cohésions (clusters de taille ≥ 2 uniquement)\n",
    "mean_cohesion_final = (\n",
    "    np.mean(cluster_cohesions)\n",
    "    if cluster_cohesions else 0.0\n",
    ")\n",
    "\n",
    "print(\"\\n=== Métriques finales ===\")\n",
    "print(f\"Cohésion moyenne finale = {mean_cohesion_final:.3f}\")\n",
    "print(f\"Silhouette finale       = {sil_final:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
